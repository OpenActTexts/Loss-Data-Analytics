<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Experience Rating Using Credibility Theory | Loss Data Analytics</title>
  <meta name="description" content="Chapter 9 Experience Rating Using Credibility Theory | Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience." />
  <meta name="generator" content="bookdown 0.25 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Experience Rating Using Credibility Theory | Loss Data Analytics" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Chapter 9 Experience Rating Using Credibility Theory | Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience." />
  <meta name="github-repo" content="https://github.com/openacttexts/Loss-Data-Analytics" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Experience Rating Using Credibility Theory | Loss Data Analytics" />
  
  <meta name="twitter:description" content="Chapter 9 Experience Rating Using Credibility Theory | Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience." />
  

<meta name="author" content="An open text authored by the Actuarial Community" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ChapRiskClass.html"/>
<link rel="next" href="ChapPortMgt.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>

<!-- Mathjax Version 2-->
<script type='text/x-mathjax-config'>
		MathJax.Hub.Config({
			extensions: ['tex2jax.js'],
			jax: ['input/TeX', 'output/HTML-CSS'],
			tex2jax: {
				inlineMath: [ ['$','$'], ['\\(','\\)'] ],
				displayMath: [ ['$$','$$'], ['\\[','\\]'] ],
				processEscapes: true
			},
			'HTML-CSS': { availableFonts: ['TeX'] }
		});
</script>

<script type="text/javascript"  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js"> </script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script type="text/javascript" src="https://unpkg.com/survey-jquery/survey.jquery.min.js"></script>
<link href="https://unpkg.com/survey-jquery/modern.min.css" type="text/css" rel="stylesheet">
<script src="https://unpkg.com/showdown/dist/showdown.min.js"></script>


<script>
function markdownConverterEWF() {  
//Create showdown markdown converter
var converter = new showdown.Converter();
converter.setOption('ghCompatibleHeaderId', true);
survey
    .onTextMarkdown
    .add(function (survey, options) {
        //convert the markdown text to html
        var str = converter.makeHtml(options.text);
        //remove root paragraphs <p></p>
        str = str.substring(3);
        str = str.substring(0, str.length - 4);
        //set html
        options.html = str;
        MathJax.Hub.Queue(['Typeset',MathJax.Hub, 'options']);
    });  
};

// Quiz Header info
const jsonHeader = { 
    showProgressBar: "bottom",
    showTimerPanel: "none",
    maxTimeToFinishPage: 10000,
    maxTimeToFinish: 25000,
    firstPageIsStarted: true,
    startSurveyText: "Start Quiz" //,
//    title: "Does This Make Sense?"
}


// One and Two question quizzes
function jsonSummary1EWF(json) {  
let jsonEnd1 = { 
completedHtml: 
json["pages"][1]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][1]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][1]["questions"][0]["correctAnswer"]
};  
return jsonEnd1;
};


function jsonSummary2EWF(json) {  
let jsonEnd2 = { 
completedHtml: 
json["pages"][1]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][1]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][1]["questions"][0]["correctAnswer"]
+"<br>"+
json["pages"][2]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][2]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][2]["questions"][0]["correctAnswer"]
};  
return jsonEnd2;
};

// Three, four, and five question quizzes
function jsonSummary3EWF(json) {  
let jsonEnd3 = { 
completedHtml: 
json["pages"][1]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][1]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][1]["questions"][0]["correctAnswer"]
+"<br>"+
json["pages"][2]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][2]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][2]["questions"][0]["correctAnswer"]
+"<br>"+
json["pages"][3]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][3]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][3]["questions"][0]["correctAnswer"]
};  
return jsonEnd3;
};

function jsonSummary4EWF(json) {  
jsonEnd4 = jsonSummary3EWF(json);
jsonEnd4.completedHtml = jsonEnd4.completedHtml +  
"<br>"+
json["pages"][4]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][4]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][4]["questions"][0]["correctAnswer"]
;  
return jsonEnd4;
};

function jsonSummary5EWF(json) {  
jsonEnd5 = jsonSummary4EWF(json);
jsonEnd5.completedHtml = jsonEnd5.completedHtml +  
"<br>"+
json["pages"][5]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][5]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][5]["questions"][0]["correctAnswer"]
;  
return jsonEnd5;
};

function jsonSummary6EWF(json) {  
jsonEnd6 = jsonSummary5EWF(json);
jsonEnd6.completedHtml = jsonEnd6.completedHtml +  
"<br>"+
json["pages"][6]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][6]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][6]["questions"][0]["correctAnswer"]
;  
return jsonEnd6;
};

function jsonSummary7EWF(json) {  
jsonEnd7 = jsonSummary6EWF(json);
jsonEnd7.completedHtml = jsonEnd7.completedHtml +  
"<br>"+
json["pages"][7]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][7]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][7]["questions"][0]["correctAnswer"]
;  
return jsonEnd7;
};

function jsonSummary8EWF(json) {  
jsonEnd8 = jsonSummary7EWF(json);
jsonEnd8.completedHtml = jsonEnd8.completedHtml +  
"<br>"+
json["pages"][8]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][8]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][8]["questions"][0]["correctAnswer"]
;  
return jsonEnd8;
};

function jsonSummary9EWF(json) {  
jsonEnd9 = jsonSummary8EWF(json);
jsonEnd9.completedHtml = jsonEnd9.completedHtml +  
"<br>"+
json["pages"][9]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][9]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][9]["questions"][0]["correctAnswer"]
;  
return jsonEnd9;
};


function jsonSummary10EWF(json) {  
jsonEnd10 = jsonSummary9EWF(json);
jsonEnd10.completedHtml = jsonEnd10.completedHtml +  
"<br>"+
json["pages"][10]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][10]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][10]["questions"][0]["correctAnswer"]
;  
return jsonEnd10;
};


function jsonSummary11EWF(json) {  
jsonEnd11 = jsonSummary10EWF(json);
jsonEnd11.completedHtml = jsonEnd11.completedHtml +  
"<br>"+
json["pages"][11]["questions"][0]["name"]+ "<br>"+
"<i>Question: </i>"+json["pages"][11]["questions"][0]["title"]+"<br>"+
"<i>Answer: </i>"+json["pages"][11]["questions"][0]["correctAnswer"]
;  
return jsonEnd11;
};

Survey.StylesManager.applyTheme("modern");

</script>  
<!-- This completes the code for the quizzes -->

<!-- Various toggle functions used throughout --> 
<script language="javascript">
function toggle(id1,id2) {
	var ele = document.getElementById(id1); var text = document.getElementById(id2);
	if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
		else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}
function togglecode(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show R Code";}
      else {ele.style.display = "block"; text.innerHTML = "Hide R Code";}}
function toggleEX(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Example";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Example";}}
function toggleTheory(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Theory";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Theory";}}
function toggleQuiz(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Quiz Solution";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Quiz Solution";}}      
</script>

<!-- A few functions for revealing definitions -->
<script language="javascript">
<!--   $( function() {
    $("#tabs").tabs();
  } ); -->

$(document).ready(function(){
    $('[data-toggle="tooltip"]').tooltip();
});

$(document).ready(function(){
    $('[data-toggle="popover"]').popover(); 
});
</script>

<script language="javascript">
function openTab(evt, tabName) {
    var i, tabcontent, tablinks;
    tabcontent = document.getElementsByClassName("tabcontent");
    for (i = 0; i < tabcontent.length; i++) {
        tabcontent[i].style.display = "none";
    }
    tablinks = document.getElementsByClassName("tablinks");
    for (i = 0; i < tablinks.length; i++) {
        tablinks[i].className = tablinks[i].className.replace(" active", "");
    }
    document.getElementById(tabName).style.display = "block";
    evt.currentTarget.className += " active";
}

// Get the element with id="defaultOpen" and click on it
document.getElementById("defaultOpen").click();
</script>



<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Loss Data Analytics</a></li>

<li class="divider"></li>
<li><a href="index.html#preface">Preface<span></span></a>
<ul>
<li><a href="index.html#acknowledgements">Acknowledgements<span></span></a></li>
<li><a href="index.html#contributors">Contributors<span></span></a></li>
<li><a href="index.html#reviewers">Reviewers<span></span></a>
<ul>
<li><a href="index.html#other-collaborators">Other Collaborators<span></span></a></li>
</ul></li>
<li><a href="index.html#version">Version<span></span></a></li>
<li><a href="index.html#for-our-readers">For our Readers<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="ChapIntro.html"><a href="ChapIntro.html"><i class="fa fa-check"></i><b>1</b> Introduction to Loss Data Analytics<span></span></a>
<ul>
<li class="chapter" data-level="1.1" data-path="ChapIntro.html"><a href="ChapIntro.html#S:Intro"><i class="fa fa-check"></i><b>1.1</b> Relevance of Analytics to Insurance Activities<span></span></a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="ChapIntro.html"><a href="ChapIntro.html#nature-and-relevance-of-insurance"><i class="fa fa-check"></i><b>1.1.1</b> Nature and Relevance of Insurance<span></span></a></li>
<li class="chapter" data-level="1.1.2" data-path="ChapIntro.html"><a href="ChapIntro.html#what-is-analytics"><i class="fa fa-check"></i><b>1.1.2</b> What is Analytics?<span></span></a></li>
<li class="chapter" data-level="1.1.3" data-path="ChapIntro.html"><a href="ChapIntro.html#S:InsProcesses"><i class="fa fa-check"></i><b>1.1.3</b> Insurance Processes<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="ChapIntro.html"><a href="ChapIntro.html#S:PredModApps"><i class="fa fa-check"></i><b>1.2</b> Insurance Company Operations<span></span></a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="ChapIntro.html"><a href="ChapIntro.html#initiating-insurance"><i class="fa fa-check"></i><b>1.2.1</b> Initiating Insurance<span></span></a></li>
<li class="chapter" data-level="1.2.2" data-path="ChapIntro.html"><a href="ChapIntro.html#renewing-insurance"><i class="fa fa-check"></i><b>1.2.2</b> Renewing Insurance<span></span></a></li>
<li class="chapter" data-level="1.2.3" data-path="ChapIntro.html"><a href="ChapIntro.html#claims-and-product-management"><i class="fa fa-check"></i><b>1.2.3</b> Claims and Product Management<span></span></a></li>
<li class="chapter" data-level="1.2.4" data-path="ChapIntro.html"><a href="ChapIntro.html#S:Reserving"><i class="fa fa-check"></i><b>1.2.4</b> Loss Reserving<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="ChapIntro.html"><a href="ChapIntro.html#S:LGPIF"><i class="fa fa-check"></i><b>1.3</b> Case Study: Wisconsin Property Fund<span></span></a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="ChapIntro.html"><a href="ChapIntro.html#S:OutComes"><i class="fa fa-check"></i><b>1.3.1</b> Fund Claims Variables: Frequency and Severity<span></span></a></li>
<li class="chapter" data-level="1.3.2" data-path="ChapIntro.html"><a href="ChapIntro.html#S:FundVariables"><i class="fa fa-check"></i><b>1.3.2</b> Fund Rating Variables<span></span></a></li>
<li class="chapter" data-level="1.3.3" data-path="ChapIntro.html"><a href="ChapIntro.html#fund-operations"><i class="fa fa-check"></i><b>1.3.3</b> Fund Operations<span></span></a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="ChapIntro.html"><a href="ChapIntro.html#Intro-further-reading-and-resources"><i class="fa fa-check"></i><b>1.4</b> Further Resources and Contributors<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html"><i class="fa fa-check"></i><b>2</b> Frequency Modeling<span></span></a>
<ul>
<li class="chapter" data-level="2.1" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:frequency-distributions"><i class="fa fa-check"></i><b>2.1</b> Frequency Distributions<span></span></a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:how-frequency-augments-severity-information"><i class="fa fa-check"></i><b>2.1.1</b> How Frequency Augments Severity Information<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:basic-frequency-distributions"><i class="fa fa-check"></i><b>2.2</b> Basic Frequency Distributions<span></span></a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:foundations"><i class="fa fa-check"></i><b>2.2.1</b> Foundations<span></span></a></li>
<li class="chapter" data-level="2.2.2" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:generating-functions"><i class="fa fa-check"></i><b>2.2.2</b> Moment and Probability Generating Functions<span></span></a></li>
<li class="chapter" data-level="2.2.3" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:important-frequency-distributions"><i class="fa fa-check"></i><b>2.2.3</b> Important Frequency Distributions<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:the-a-b-0-class"><i class="fa fa-check"></i><b>2.3</b> The (<em>a</em>, <em>b</em>, 0) Class<span></span></a></li>
<li class="chapter" data-level="2.4" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:estimating-frequency-distributions"><i class="fa fa-check"></i><b>2.4</b> Estimating Frequency Distributions<span></span></a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:parameter-estimation"><i class="fa fa-check"></i><b>2.4.1</b> Parameter Estimation<span></span></a></li>
<li class="chapter" data-level="2.4.2" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:frequency-distributions-mle"><i class="fa fa-check"></i><b>2.4.2</b> Frequency Distributions MLE<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:other-frequency-distributions"><i class="fa fa-check"></i><b>2.5</b> Other Frequency Distributions<span></span></a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:zero-truncation-or-modification"><i class="fa fa-check"></i><b>2.5.1</b> Zero Truncation or Modification<span></span></a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:mixture-distributions"><i class="fa fa-check"></i><b>2.6</b> Mixture Distributions<span></span></a></li>
<li class="chapter" data-level="2.7" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:goodness-of-fit"><i class="fa fa-check"></i><b>2.7</b> Goodness of Fit<span></span></a></li>
<li class="chapter" data-level="2.8" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:exercises"><i class="fa fa-check"></i><b>2.8</b> Exercises<span></span></a></li>
<li class="chapter" data-level="2.9" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#Freq-further-reading-and-resources"><i class="fa fa-check"></i><b>2.9</b> Further Resources and Contributors<span></span></a>
<ul>
<li class="chapter" data-level="2.9.1" data-path="ChapFrequency-Modeling.html"><a href="ChapFrequency-Modeling.html#S:rcode"><i class="fa fa-check"></i><b>2.9.1</b> TS 2.A. R Code for Plots<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ChapSeverity.html"><a href="ChapSeverity.html"><i class="fa fa-check"></i><b>3</b> Modeling Loss Severity<span></span></a>
<ul>
<li class="chapter" data-level="3.1" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:BasicQuantities"><i class="fa fa-check"></i><b>3.1</b> Basic Distributional Quantities<span></span></a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:Chap3Moments"><i class="fa fa-check"></i><b>3.1.1</b> Moments<span></span></a></li>
<li class="chapter" data-level="3.1.2" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:LS:Quantiles"><i class="fa fa-check"></i><b>3.1.2</b> Quantiles<span></span></a></li>
<li class="chapter" data-level="3.1.3" data-path="ChapSeverity.html"><a href="ChapSeverity.html#moment-generating-function"><i class="fa fa-check"></i><b>3.1.3</b> Moment Generating Function<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:ContinuousDistn"><i class="fa fa-check"></i><b>3.2</b> Continuous Distributions for Modeling Loss Severity<span></span></a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:Loss:Gamma"><i class="fa fa-check"></i><b>3.2.1</b> Gamma Distribution<span></span></a></li>
<li class="chapter" data-level="3.2.2" data-path="ChapSeverity.html"><a href="ChapSeverity.html#pareto-distribution"><i class="fa fa-check"></i><b>3.2.2</b> Pareto Distribution<span></span></a></li>
<li class="chapter" data-level="3.2.3" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:LS:Weibull"><i class="fa fa-check"></i><b>3.2.3</b> Weibull Distribution<span></span></a></li>
<li class="chapter" data-level="3.2.4" data-path="ChapSeverity.html"><a href="ChapSeverity.html#the-generalized-beta-distribution-of-the-second-kind"><i class="fa fa-check"></i><b>3.2.4</b> The Generalized Beta Distribution of the Second Kind<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="ChapSeverity.html"><a href="ChapSeverity.html#MethodsCreation"><i class="fa fa-check"></i><b>3.3</b> Methods of Creating New Distributions<span></span></a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="ChapSeverity.html"><a href="ChapSeverity.html#functions-of-random-variables-and-their-distributions"><i class="fa fa-check"></i><b>3.3.1</b> Functions of Random Variables and their Distributions<span></span></a></li>
<li class="chapter" data-level="3.3.2" data-path="ChapSeverity.html"><a href="ChapSeverity.html#multiplication-by-a-constant"><i class="fa fa-check"></i><b>3.3.2</b> Multiplication by a Constant<span></span></a></li>
<li class="chapter" data-level="3.3.3" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:LossSev:Raising"><i class="fa fa-check"></i><b>3.3.3</b> Raising to a Power<span></span></a></li>
<li class="chapter" data-level="3.3.4" data-path="ChapSeverity.html"><a href="ChapSeverity.html#exponentiation"><i class="fa fa-check"></i><b>3.3.4</b> Exponentiation<span></span></a></li>
<li class="chapter" data-level="3.3.5" data-path="ChapSeverity.html"><a href="ChapSeverity.html#finite-mixtures"><i class="fa fa-check"></i><b>3.3.5</b> Finite Mixtures<span></span></a></li>
<li class="chapter" data-level="3.3.6" data-path="ChapSeverity.html"><a href="ChapSeverity.html#continuous-mixtures"><i class="fa fa-check"></i><b>3.3.6</b> Continuous Mixtures<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:CoverageModifications"><i class="fa fa-check"></i><b>3.4</b> Coverage Modifications<span></span></a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:PolicyDeduct"><i class="fa fa-check"></i><b>3.4.1</b> Policy Deductibles<span></span></a></li>
<li class="chapter" data-level="3.4.2" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:PolicyLimits"><i class="fa fa-check"></i><b>3.4.2</b> Policy Limits<span></span></a></li>
<li class="chapter" data-level="3.4.3" data-path="ChapSeverity.html"><a href="ChapSeverity.html#coinsurance-and-inflation"><i class="fa fa-check"></i><b>3.4.3</b> Coinsurance and Inflation<span></span></a></li>
<li class="chapter" data-level="3.4.4" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:Chap3Reinsurance"><i class="fa fa-check"></i><b>3.4.4</b> Reinsurance<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:MaxLikeEstimation"><i class="fa fa-check"></i><b>3.5</b> Maximum Likelihood Estimation<span></span></a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="ChapSeverity.html"><a href="ChapSeverity.html#maximum-likelihood-estimators-for-complete-data"><i class="fa fa-check"></i><b>3.5.1</b> Maximum Likelihood Estimators for Complete Data<span></span></a></li>
<li class="chapter" data-level="3.5.2" data-path="ChapSeverity.html"><a href="ChapSeverity.html#S:Loss:MLEModified"><i class="fa fa-check"></i><b>3.5.2</b> Maximum Likelihood Estimators using Modified Data<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="ChapSeverity.html"><a href="ChapSeverity.html#LM-further-reading-and-resources"><i class="fa fa-check"></i><b>3.6</b> Further Resources and Contributors<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html"><i class="fa fa-check"></i><b>4</b> Model Selection and Estimation<span></span></a>
<ul>
<li class="chapter" data-level="4.1" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:NonParInf"><i class="fa fa-check"></i><b>4.1</b> Nonparametric Inference<span></span></a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:NonParEst"><i class="fa fa-check"></i><b>4.1.1</b> Nonparametric Estimation<span></span></a></li>
<li class="chapter" data-level="4.1.2" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:ToolsModelSelection"><i class="fa fa-check"></i><b>4.1.2</b> Tools for Model Selection and Diagnostics<span></span></a></li>
<li class="chapter" data-level="4.1.3" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#starting-values"><i class="fa fa-check"></i><b>4.1.3</b> Starting Values<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:ModelSelection"><i class="fa fa-check"></i><b>4.2</b> Model Selection<span></span></a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#iterative-model-selection"><i class="fa fa-check"></i><b>4.2.1</b> Iterative Model Selection<span></span></a></li>
<li class="chapter" data-level="4.2.2" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#model-selection-based-on-a-training-dataset"><i class="fa fa-check"></i><b>4.2.2</b> Model Selection Based on a Training Dataset<span></span></a></li>
<li class="chapter" data-level="4.2.3" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#model-selection-based-on-a-test-dataset"><i class="fa fa-check"></i><b>4.2.3</b> Model Selection Based on a Test Dataset<span></span></a></li>
<li class="chapter" data-level="4.2.4" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:Cross-Validation"><i class="fa fa-check"></i><b>4.2.4</b> Model Selection Based on Cross-Validation<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:ModifiedData"><i class="fa fa-check"></i><b>4.3</b> Estimation using Modified Data<span></span></a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:ModifiedData1"><i class="fa fa-check"></i><b>4.3.1</b> Parametric Estimation using Modified Data<span></span></a></li>
<li class="chapter" data-level="4.3.2" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#nonparametric-estimation-using-modified-data"><i class="fa fa-check"></i><b>4.3.2</b> Nonparametric Estimation using Modified Data<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:MS:BayesInference"><i class="fa fa-check"></i><b>4.4</b> Bayesian Inference<span></span></a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:IntroBayes"><i class="fa fa-check"></i><b>4.4.1</b> Introduction to Bayesian Inference<span></span></a></li>
<li class="chapter" data-level="4.4.2" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#bayesian-model"><i class="fa fa-check"></i><b>4.4.2</b> Bayesian Model<span></span></a></li>
<li class="chapter" data-level="4.4.3" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#bayesian-inference"><i class="fa fa-check"></i><b>4.4.3</b> Bayesian Inference<span></span></a></li>
<li class="chapter" data-level="4.4.4" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#S:ConjugateDistributions"><i class="fa fa-check"></i><b>4.4.4</b> Conjugate Distributions<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="ChapModelSelection.html"><a href="ChapModelSelection.html#MS:further-reading-and-resources"><i class="fa fa-check"></i><b>4.5</b> Further Resources and Contributors<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html"><i class="fa fa-check"></i><b>5</b> Aggregate Loss Models<span></span></a>
<ul>
<li class="chapter" data-level="5.1" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#introduction"><i class="fa fa-check"></i><b>5.1</b> Introduction<span></span></a></li>
<li class="chapter" data-level="5.2" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#individual-risk-model"><i class="fa fa-check"></i><b>5.2</b> Individual Risk Model<span></span></a></li>
<li class="chapter" data-level="5.3" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#S:AggLoss:CRM"><i class="fa fa-check"></i><b>5.3</b> Collective Risk Model<span></span></a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#moments-and-distribution"><i class="fa fa-check"></i><b>5.3.1</b> Moments and Distribution<span></span></a></li>
<li class="chapter" data-level="5.3.2" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#stop-loss-insurance"><i class="fa fa-check"></i><b>5.3.2</b> Stop-loss Insurance<span></span></a></li>
<li class="chapter" data-level="5.3.3" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#analytic-results"><i class="fa fa-check"></i><b>5.3.3</b> Analytic Results<span></span></a></li>
<li class="chapter" data-level="5.3.4" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#S:AggLoss:Tweedie"><i class="fa fa-check"></i><b>5.3.4</b> Tweedie Distribution<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#computing-the-aggregate-claims-distribution"><i class="fa fa-check"></i><b>5.4</b> Computing the Aggregate Claims Distribution<span></span></a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#recursive-method"><i class="fa fa-check"></i><b>5.4.1</b> Recursive Method<span></span></a></li>
<li class="chapter" data-level="5.4.2" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#simulation"><i class="fa fa-check"></i><b>5.4.2</b> Simulation<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#effects-of-coverage-modifications"><i class="fa fa-check"></i><b>5.5</b> Effects of Coverage Modifications<span></span></a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#impact-of-exposure-on-frequency"><i class="fa fa-check"></i><b>5.5.1</b> Impact of Exposure on Frequency<span></span></a></li>
<li class="chapter" data-level="5.5.2" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#S:MS:DedImpactClmFreq"><i class="fa fa-check"></i><b>5.5.2</b> Impact of Deductibles on Claim Frequency<span></span></a></li>
<li class="chapter" data-level="5.5.3" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#impact-of-policy-modifications-on-aggregate-claims"><i class="fa fa-check"></i><b>5.5.3</b> Impact of Policy Modifications on Aggregate Claims<span></span></a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="ChapAggLossModels.html"><a href="ChapAggLossModels.html#AL-further-reading-and-resources"><i class="fa fa-check"></i><b>5.6</b> Further Resources and Contributors<span></span></a>
<ul>
<li><a href="ChapAggLossModels.html#ts-5.a.1.-individual-risk-model-properties">TS 5.A.1. Individual Risk Model Properties<span></span></a></li>
<li><a href="ChapAggLossModels.html#ts-5.a.2.-relationship-between-probability-generating-functions-of-x_i-and-x_it">TS 5.A.2. Relationship Between Probability Generating Functions of <span class="math inline">\(X_i\)</span> and <span class="math inline">\(X_i^T\)</span><span></span></a></li>
<li><a href="ChapAggLossModels.html#ts-5.a.3.-example-5.3.8-moment-generating-function-of-aggregate-loss-s_n">TS 5.A.3. Example 5.3.8 Moment Generating Function of Aggregate Loss <span class="math inline">\(S_N\)</span><span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ChapSimulation.html"><a href="ChapSimulation.html"><i class="fa fa-check"></i><b>6</b> Simulation and Resampling<span></span></a>
<ul>
<li class="chapter" data-level="6.1" data-path="ChapSimulation.html"><a href="ChapSimulation.html#S:SimulationFundamentals"><i class="fa fa-check"></i><b>6.1</b> Simulation Fundamentals<span></span></a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="ChapSimulation.html"><a href="ChapSimulation.html#generating-independent-uniform-observations"><i class="fa fa-check"></i><b>6.1.1</b> Generating Independent Uniform Observations<span></span></a></li>
<li class="chapter" data-level="6.1.2" data-path="ChapSimulation.html"><a href="ChapSimulation.html#S:InverseTransform"><i class="fa fa-check"></i><b>6.1.2</b> Inverse Transform Method<span></span></a></li>
<li class="chapter" data-level="6.1.3" data-path="ChapSimulation.html"><a href="ChapSimulation.html#simulation-precision"><i class="fa fa-check"></i><b>6.1.3</b> Simulation Precision<span></span></a></li>
<li class="chapter" data-level="6.1.4" data-path="ChapSimulation.html"><a href="ChapSimulation.html#S:SimulationStatInference"><i class="fa fa-check"></i><b>6.1.4</b> Simulation and Statistical Inference<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="ChapSimulation.html"><a href="ChapSimulation.html#S:Bootstrap"><i class="fa fa-check"></i><b>6.2</b> Bootstrapping and Resampling<span></span></a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="ChapSimulation.html"><a href="ChapSimulation.html#bootstrap-foundations"><i class="fa fa-check"></i><b>6.2.1</b> Bootstrap Foundations<span></span></a></li>
<li class="chapter" data-level="6.2.2" data-path="ChapSimulation.html"><a href="ChapSimulation.html#S:Sim:Precision"><i class="fa fa-check"></i><b>6.2.2</b> Bootstrap Precision: Bias, Standard Deviation, and Mean Square Error<span></span></a></li>
<li class="chapter" data-level="6.2.3" data-path="ChapSimulation.html"><a href="ChapSimulation.html#confidence-intervals"><i class="fa fa-check"></i><b>6.2.3</b> Confidence Intervals<span></span></a></li>
<li class="chapter" data-level="6.2.4" data-path="ChapSimulation.html"><a href="ChapSimulation.html#S:ParametricBootStrap"><i class="fa fa-check"></i><b>6.2.4</b> Parametric Bootstrap<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="ChapSimulation.html"><a href="ChapSimulation.html#S:CrossValidation"><i class="fa fa-check"></i><b>6.3</b> Cross-Validation<span></span></a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="ChapSimulation.html"><a href="ChapSimulation.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>6.3.1</b> k-Fold Cross-Validation<span></span></a></li>
<li class="chapter" data-level="6.3.2" data-path="ChapSimulation.html"><a href="ChapSimulation.html#leave-one-out-cross-validation"><i class="fa fa-check"></i><b>6.3.2</b> Leave-One-Out Cross-Validation<span></span></a></li>
<li class="chapter" data-level="6.3.3" data-path="ChapSimulation.html"><a href="ChapSimulation.html#cross-validation-and-bootstrap"><i class="fa fa-check"></i><b>6.3.3</b> Cross-Validation and Bootstrap<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="ChapSimulation.html"><a href="ChapSimulation.html#S:ImportanceSampling"><i class="fa fa-check"></i><b>6.4</b> Importance Sampling<span></span></a></li>
<li class="chapter" data-level="6.5" data-path="ChapSimulation.html"><a href="ChapSimulation.html#S:MCMC"><i class="fa fa-check"></i><b>6.5</b> Monte Carlo Markov Chain (MCMC)<span></span></a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="ChapSimulation.html"><a href="ChapSimulation.html#metropolis-hastings"><i class="fa fa-check"></i><b>6.5.1</b> Metropolis Hastings<span></span></a></li>
<li class="chapter" data-level="6.5.2" data-path="ChapSimulation.html"><a href="ChapSimulation.html#gibbs-sampler"><i class="fa fa-check"></i><b>6.5.2</b> Gibbs Sampler<span></span></a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="ChapSimulation.html"><a href="ChapSimulation.html#Simulation:further-reading-and-resources"><i class="fa fa-check"></i><b>6.6</b> Further Resources and Contributors<span></span></a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="ChapSimulation.html"><a href="ChapSimulation.html#ts-6.a.-bootstrap-applications-in-predictive-modeling"><i class="fa fa-check"></i><b>6.6.1</b> TS 6.A. Bootstrap Applications in Predictive Modeling<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html"><i class="fa fa-check"></i><b>7</b> Premium Foundations<span></span></a>
<ul>
<li class="chapter" data-level="7.1" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:IntroductionRatemaking"><i class="fa fa-check"></i><b>7.1</b> Introduction to Ratemaking<span></span></a></li>
<li class="chapter" data-level="7.2" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:AggRateMaking"><i class="fa fa-check"></i><b>7.2</b> Aggregate Ratemaking Methods<span></span></a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:PurePremium"><i class="fa fa-check"></i><b>7.2.1</b> Pure Premium Method<span></span></a></li>
<li class="chapter" data-level="7.2.2" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:LossRatio"><i class="fa fa-check"></i><b>7.2.2</b> Loss Ratio Method<span></span></a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:PricingPrinciples"><i class="fa fa-check"></i><b>7.3</b> Pricing Principles<span></span></a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#premium-principles"><i class="fa fa-check"></i><b>7.3.1</b> Premium Principles<span></span></a></li>
<li class="chapter" data-level="7.3.2" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#properties-of-premium-principles"><i class="fa fa-check"></i><b>7.3.2</b> Properties of Premium Principles<span></span></a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:HeterogeneousRisks"><i class="fa fa-check"></i><b>7.4</b> Heterogeneous Risks<span></span></a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:ExposureToRisk"><i class="fa fa-check"></i><b>7.4.1</b> Exposure to Risk<span></span></a></li>
<li class="chapter" data-level="7.4.2" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:RatingFactors"><i class="fa fa-check"></i><b>7.4.2</b> Rating Factors<span></span></a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:TrendDevelopment"><i class="fa fa-check"></i><b>7.5</b> Development and Trending<span></span></a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#exposures-and-premiums"><i class="fa fa-check"></i><b>7.5.1</b> Exposures and Premiums<span></span></a></li>
<li class="chapter" data-level="7.5.2" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#losses-claims-and-payments"><i class="fa fa-check"></i><b>7.5.2</b> Losses, Claims, and Payments<span></span></a></li>
<li class="chapter" data-level="7.5.3" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:CompareMethods"><i class="fa fa-check"></i><b>7.5.3</b> Comparing Pure Premium and Loss Ratio Methods<span></span></a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#S:GiniStatistic"><i class="fa fa-check"></i><b>7.6</b> Selecting a Premium<span></span></a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#classic-lorenz-curve"><i class="fa fa-check"></i><b>7.6.1</b> Classic Lorenz Curve<span></span></a></li>
<li class="chapter" data-level="7.6.2" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#performance-curve-and-a-gini-statistic"><i class="fa fa-check"></i><b>7.6.2</b> Performance Curve and a Gini Statistic<span></span></a></li>
<li class="chapter" data-level="7.6.3" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#out-of-sample-validation"><i class="fa fa-check"></i><b>7.6.3</b> Out-of-Sample Validation<span></span></a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="ChapPremiumFoundations.html"><a href="ChapPremiumFoundations.html#further-resources-and-contributors"><i class="fa fa-check"></i><b>7.7</b> Further Resources and Contributors<span></span></a>
<ul>
<li><a href="ChapPremiumFoundations.html#ts-7.a.-rate-regulation">TS 7.A. Rate Regulation<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html"><i class="fa fa-check"></i><b>8</b> Risk Classification<span></span></a>
<ul>
<li class="chapter" data-level="8.1" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#S:RC:Introduction"><i class="fa fa-check"></i><b>8.1</b> Introduction<span></span></a></li>
<li class="chapter" data-level="8.2" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#S:RC:PoissonRegression"><i class="fa fa-check"></i><b>8.2</b> Poisson Regression Model<span></span></a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#S:RC:Need.Poi.reg"><i class="fa fa-check"></i><b>8.2.1</b> Need for Poisson Regression<span></span></a></li>
<li class="chapter" data-level="8.2.2" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#poisson-regression"><i class="fa fa-check"></i><b>8.2.2</b> Poisson Regression<span></span></a></li>
<li class="chapter" data-level="8.2.3" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#incorporating-exposure"><i class="fa fa-check"></i><b>8.2.3</b> Incorporating Exposure<span></span></a></li>
<li class="chapter" data-level="8.2.4" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#exercises-3"><i class="fa fa-check"></i><b>8.2.4</b> Exercises<span></span></a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#S:CatVarMultiTarriff"><i class="fa fa-check"></i><b>8.3</b> Categorical Variables and Multiplicative Tariff<span></span></a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#rating-factors-and-tariff"><i class="fa fa-check"></i><b>8.3.1</b> Rating Factors and Tariff<span></span></a></li>
<li class="chapter" data-level="8.3.2" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#multiplicative-tariff-model"><i class="fa fa-check"></i><b>8.3.2</b> Multiplicative Tariff Model<span></span></a></li>
<li class="chapter" data-level="8.3.3" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#poisson-regression-for-multiplicative-tariff"><i class="fa fa-check"></i><b>8.3.3</b> Poisson Regression for Multiplicative Tariff<span></span></a></li>
<li class="chapter" data-level="8.3.4" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#numerical-examples"><i class="fa fa-check"></i><b>8.3.4</b> Numerical Examples<span></span></a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="ChapRiskClass.html"><a href="ChapRiskClass.html#RC:further-reading-and-resources"><i class="fa fa-check"></i><b>8.4</b> Further Resources and Contributors<span></span></a>
<ul>
<li><a href="ChapRiskClass.html#ts-8.a.-estimating-poisson-regression-models">TS 8.A. Estimating Poisson Regression Models<span></span></a></li>
<li><a href="ChapRiskClass.html#ts-8.b.-selecting-rating-factors">TS 8.B. Selecting Rating Factors<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ChapCredibility.html"><a href="ChapCredibility.html"><i class="fa fa-check"></i><b>9</b> Experience Rating Using Credibility Theory<span></span></a>
<ul>
<li class="chapter" data-level="9.1" data-path="ChapCredibility.html"><a href="ChapCredibility.html#introduction-to-applications-of-credibility-theory"><i class="fa fa-check"></i><b>9.1</b> Introduction to Applications of Credibility Theory<span></span></a></li>
<li class="chapter" data-level="9.2" data-path="ChapCredibility.html"><a href="ChapCredibility.html#limited-fluctuation-credibility"><i class="fa fa-check"></i><b>9.2</b> Limited Fluctuation Credibility<span></span></a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="ChapCredibility.html"><a href="ChapCredibility.html#S:frequency"><i class="fa fa-check"></i><b>9.2.1</b> Full Credibility for Claim Frequency<span></span></a></li>
<li class="chapter" data-level="9.2.2" data-path="ChapCredibility.html"><a href="ChapCredibility.html#full-credibility-for-aggregate-losses-and-pure-premium"><i class="fa fa-check"></i><b>9.2.2</b> Full Credibility for Aggregate Losses and Pure Premium<span></span></a></li>
<li class="chapter" data-level="9.2.3" data-path="ChapCredibility.html"><a href="ChapCredibility.html#full-credibility-for-severity"><i class="fa fa-check"></i><b>9.2.3</b> Full Credibility for Severity<span></span></a></li>
<li class="chapter" data-level="9.2.4" data-path="ChapCredibility.html"><a href="ChapCredibility.html#partial-credibility"><i class="fa fa-check"></i><b>9.2.4</b> Partial Credibility<span></span></a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="ChapCredibility.html"><a href="ChapCredibility.html#S:Cred:Buhlmann"><i class="fa fa-check"></i><b>9.3</b> Bhlmann Credibility<span></span></a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="ChapCredibility.html"><a href="ChapCredibility.html#S:EPV-VHM-Z"><i class="fa fa-check"></i><b>9.3.1</b> Credibility <em>Z</em>, <em>EPV</em>, and <em>VHM</em><span></span></a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="ChapCredibility.html"><a href="ChapCredibility.html#bhlmann-straub-credibility"><i class="fa fa-check"></i><b>9.4</b> Bhlmann-Straub Credibility<span></span></a></li>
<li class="chapter" data-level="9.5" data-path="ChapCredibility.html"><a href="ChapCredibility.html#S:Cred:BayesInf"><i class="fa fa-check"></i><b>9.5</b> Bayesian Inference and Bhlmann Credibility<span></span></a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="ChapCredibility.html"><a href="ChapCredibility.html#Sec:Cred:gammaPoisson"><i class="fa fa-check"></i><b>9.5.1</b> Gamma-Poisson Model<span></span></a></li>
<li class="chapter" data-level="9.5.2" data-path="ChapCredibility.html"><a href="ChapCredibility.html#beta-binomial-model"><i class="fa fa-check"></i><b>9.5.2</b> Beta-Binomial Model<span></span></a></li>
<li class="chapter" data-level="9.5.3" data-path="ChapCredibility.html"><a href="ChapCredibility.html#exact-credibility"><i class="fa fa-check"></i><b>9.5.3</b> Exact Credibility<span></span></a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="ChapCredibility.html"><a href="ChapCredibility.html#estimating-credibility-parameters"><i class="fa fa-check"></i><b>9.6</b> Estimating Credibility Parameters<span></span></a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="ChapCredibility.html"><a href="ChapCredibility.html#full-credibility-standard-for-limited-fluctuation-credibility"><i class="fa fa-check"></i><b>9.6.1</b> Full Credibility Standard for Limited Fluctuation Credibility<span></span></a></li>
<li class="chapter" data-level="9.6.2" data-path="ChapCredibility.html"><a href="ChapCredibility.html#nonparametric-estimation-for-bhlmann-and-bhlmann-straub-models"><i class="fa fa-check"></i><b>9.6.2</b> Nonparametric Estimation for Bhlmann and Bhlmann-Straub Models<span></span></a></li>
<li class="chapter" data-level="9.6.3" data-path="ChapCredibility.html"><a href="ChapCredibility.html#semiparametric-estimation-for-bhlmann-and-bhlmann-straub-models"><i class="fa fa-check"></i><b>9.6.3</b> Semiparametric Estimation for Bhlmann and Bhlmann-Straub Models<span></span></a></li>
<li class="chapter" data-level="9.6.4" data-path="ChapCredibility.html"><a href="ChapCredibility.html#balancing-credibility-estimators"><i class="fa fa-check"></i><b>9.6.4</b> Balancing Credibility Estimators<span></span></a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="ChapCredibility.html"><a href="ChapCredibility.html#Cred-further-reading-and-resources"><i class="fa fa-check"></i><b>9.7</b> Further Resources and Contributors<span></span></a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html"><i class="fa fa-check"></i><b>10</b> Insurance Portfolio Management including Reinsurance<span></span></a>
<ul>
<li class="chapter" data-level="10.1" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#introduction-to-insurance-portfolios"><i class="fa fa-check"></i><b>10.1</b> Introduction to Insurance Portfolios<span></span></a></li>
<li class="chapter" data-level="10.2" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#S:Tails"><i class="fa fa-check"></i><b>10.2</b> Tails of Distributions<span></span></a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#classification-based-on-moments"><i class="fa fa-check"></i><b>10.2.1</b> Classification Based on Moments<span></span></a></li>
<li class="chapter" data-level="10.2.2" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#comparison-based-on-limiting-tail-behavior"><i class="fa fa-check"></i><b>10.2.2</b> Comparison Based on Limiting Tail Behavior<span></span></a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#S:RiskMeasure"><i class="fa fa-check"></i><b>10.3</b> Risk Measures<span></span></a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#coherent-risk-measures"><i class="fa fa-check"></i><b>10.3.1</b> Coherent Risk Measures<span></span></a></li>
<li class="chapter" data-level="10.3.2" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#value-at-risk"><i class="fa fa-check"></i><b>10.3.2</b> Value-at-Risk<span></span></a></li>
<li class="chapter" data-level="10.3.3" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#tail-value-at-risk"><i class="fa fa-check"></i><b>10.3.3</b> Tail Value-at-Risk<span></span></a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#S:Reinsurance"><i class="fa fa-check"></i><b>10.4</b> Reinsurance<span></span></a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#S:ProportionalRe"><i class="fa fa-check"></i><b>10.4.1</b> Proportional Reinsurance<span></span></a></li>
<li class="chapter" data-level="10.4.2" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#S:NonProportionalRe"><i class="fa fa-check"></i><b>10.4.2</b> Non-Proportional Reinsurance<span></span></a></li>
<li class="chapter" data-level="10.4.3" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#S:AdditionalRe"><i class="fa fa-check"></i><b>10.4.3</b> Additional Reinsurance Treaties<span></span></a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="ChapPortMgt.html"><a href="ChapPortMgt.html#further-resources-and-contributors-1"><i class="fa fa-check"></i><b>10.5</b> Further Resources and Contributors<span></span></a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html"><i class="fa fa-check"></i><b>11</b> Loss Reserving<span></span></a>
<ul>
<li class="chapter" data-level="11.1" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#S:motivation"><i class="fa fa-check"></i><b>11.1</b> Motivation<span></span></a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#S:claim-types"><i class="fa fa-check"></i><b>11.1.1</b> Closed, IBNR, and RBNS Claims<span></span></a></li>
<li class="chapter" data-level="11.1.2" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#why-reserving"><i class="fa fa-check"></i><b>11.1.2</b> Why Reserving?<span></span></a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#S:Data"><i class="fa fa-check"></i><b>11.2</b> Loss Reserve Data<span></span></a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#from-micro-to-macro"><i class="fa fa-check"></i><b>11.2.1</b> From Micro to Macro<span></span></a></li>
<li class="chapter" data-level="11.2.2" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#run-off-triangles"><i class="fa fa-check"></i><b>11.2.2</b> Run-off Triangles<span></span></a></li>
<li class="chapter" data-level="11.2.3" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#loss-reserve-notation"><i class="fa fa-check"></i><b>11.2.3</b> Loss Reserve Notation<span></span></a></li>
<li class="chapter" data-level="11.2.4" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#S:Rcode"><i class="fa fa-check"></i><b>11.2.4</b> R Code to Summarize Loss Reserve Data<span></span></a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#S:Chain-ladder"><i class="fa fa-check"></i><b>11.3</b> The Chain-Ladder Method<span></span></a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#S:DeterministicCL"><i class="fa fa-check"></i><b>11.3.1</b> The Deterministic Chain-Ladder<span></span></a></li>
<li class="chapter" data-level="11.3.2" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#macks-distribution-free-chain-ladder-model"><i class="fa fa-check"></i><b>11.3.2</b> Macks Distribution-Free Chain-Ladder Model<span></span></a></li>
<li class="chapter" data-level="11.3.3" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#r-code-for-chain-ladder-predictions"><i class="fa fa-check"></i><b>11.3.3</b> R code for Chain-Ladder Predictions<span></span></a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#S:GLMs"><i class="fa fa-check"></i><b>11.4</b> GLMs and Bootstrap for Loss Reserves<span></span></a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#model-specification"><i class="fa fa-check"></i><b>11.4.1</b> Model Specification<span></span></a></li>
<li class="chapter" data-level="11.4.2" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#model-estimation-and-prediction"><i class="fa fa-check"></i><b>11.4.2</b> Model Estimation and Prediction<span></span></a></li>
<li class="chapter" data-level="11.4.3" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#bootstrap"><i class="fa fa-check"></i><b>11.4.3</b> Bootstrap<span></span></a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="ChapLossReserves.html"><a href="ChapLossReserves.html#LossRe:further-reading-and-resources"><i class="fa fa-check"></i><b>11.5</b> Further Resources and Contributors<span></span></a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html"><i class="fa fa-check"></i><b>12</b> Experience Rating using Bonus-Malus<span></span></a>
<ul>
<li class="chapter" data-level="12.1" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#S:ERBM:Intro"><i class="fa fa-check"></i><b>12.1</b> Introduction<span></span></a></li>
<li class="chapter" data-level="12.2" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#S:ERBM:NCD"><i class="fa fa-check"></i><b>12.2</b> <em>NCD</em> System in Several Countries<span></span></a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#ncd-system-in-malaysia"><i class="fa fa-check"></i><b>12.2.1</b> <em>NCD</em> System in Malaysia<span></span></a></li>
<li class="chapter" data-level="12.2.2" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#ncd-systems-in-other-countries"><i class="fa fa-check"></i><b>12.2.2</b> NCD Systems in Other Countries<span></span></a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#S:ERBM:BMS"><i class="fa fa-check"></i><b>12.3</b> <em>BMS</em> and Markov Chain Model<span></span></a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#transition-probability"><i class="fa fa-check"></i><b>12.3.1</b> Transition Probability<span></span></a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#S:ERBM:StatDist"><i class="fa fa-check"></i><b>12.4</b> <em>BMS</em> and Stationary Distribution<span></span></a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#stationary-distribution"><i class="fa fa-check"></i><b>12.4.1</b> Stationary Distribution<span></span></a></li>
<li class="chapter" data-level="12.4.2" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#r-code-for-a-stationary-distribution"><i class="fa fa-check"></i><b>12.4.2</b> <code>R</code> Code for a Stationary Distribution<span></span></a></li>
<li class="chapter" data-level="12.4.3" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#premium-evolution"><i class="fa fa-check"></i><b>12.4.3</b> Premium Evolution<span></span></a></li>
<li class="chapter" data-level="12.4.4" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#r-program-for-premium-evolution"><i class="fa fa-check"></i><b>12.4.4</b> <code>R</code> Program for Premium Evolution<span></span></a></li>
<li class="chapter" data-level="12.4.5" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#convergence-rate"><i class="fa fa-check"></i><b>12.4.5</b> Convergence Rate<span></span></a></li>
<li class="chapter" data-level="12.4.6" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#r-program-for-convergence-rate"><i class="fa fa-check"></i><b>12.4.6</b> <code>R</code> Program for Convergence Rate<span></span></a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#S:PremRtg"><i class="fa fa-check"></i><b>12.5</b> <em>BMS</em> and Premium Rating<span></span></a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#premium-rating"><i class="fa fa-check"></i><b>12.5.1</b> Premium Rating<span></span></a></li>
<li class="chapter" data-level="12.5.2" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#a-priori-risk-classification"><i class="fa fa-check"></i><b>12.5.2</b> A Priori Risk Classification<span></span></a></li>
<li class="chapter" data-level="12.5.3" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#modelling-of-residual-heterogeneity"><i class="fa fa-check"></i><b>12.5.3</b> Modelling of Residual Heterogeneity<span></span></a></li>
<li class="chapter" data-level="12.5.4" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#stationary-distribution-allowing-for-residual-heterogeneity"><i class="fa fa-check"></i><b>12.5.4</b> Stationary Distribution Allowing for Residual Heterogeneity<span></span></a></li>
<li class="chapter" data-level="12.5.5" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#determination-of-optimal-relativities"><i class="fa fa-check"></i><b>12.5.5</b> Determination of Optimal Relativities<span></span></a></li>
<li class="chapter" data-level="12.5.6" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#numerical-illustrations"><i class="fa fa-check"></i><b>12.5.6</b> Numerical Illustrations<span></span></a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#S:Further"><i class="fa fa-check"></i><b>12.6</b> Further Resources and Contributors<span></span></a>
<ul>
<li class="chapter" data-level="12.6.1" data-path="ChapBonusMalus.html"><a href="ChapBonusMalus.html#further-reading-and-references-1"><i class="fa fa-check"></i><b>12.6.1</b> Further Reading and References<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="ChapDataSystems.html"><a href="ChapDataSystems.html"><i class="fa fa-check"></i><b>13</b> Data and Systems<span></span></a>
<ul>
<li class="chapter" data-level="13.1" data-path="ChapDataSystems.html"><a href="ChapDataSystems.html#data"><i class="fa fa-check"></i><b>13.1</b> Data<span></span></a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="ChapDataSystems.html"><a href="ChapDataSystems.html#data-types-and-sources"><i class="fa fa-check"></i><b>13.1.1</b> Data Types and Sources<span></span></a></li>
<li class="chapter" data-level="13.1.2" data-path="ChapDataSystems.html"><a href="ChapDataSystems.html#data-structures-and-storage"><i class="fa fa-check"></i><b>13.1.2</b> Data Structures and Storage<span></span></a></li>
<li class="chapter" data-level="13.1.3" data-path="ChapDataSystems.html"><a href="ChapDataSystems.html#data-quality"><i class="fa fa-check"></i><b>13.1.3</b> Data Quality<span></span></a></li>
<li class="chapter" data-level="13.1.4" data-path="ChapDataSystems.html"><a href="ChapDataSystems.html#data-cleaning"><i class="fa fa-check"></i><b>13.1.4</b> Data Cleaning<span></span></a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="ChapDataSystems.html"><a href="ChapDataSystems.html#data-analysis-preliminaries"><i class="fa fa-check"></i><b>13.2</b> Data Analysis Preliminaries<span></span></a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="ChapDataSystems.html"><a href="ChapDataSystems.html#S:process"><i class="fa fa-check"></i><b>13.2.1</b> Data Analysis Process<span></span></a></li>
<li class="chapter" data-level="13.2.2" data-path="ChapDataSystems.html"><a href="ChapDataSystems.html#exploratory-versus-confirmatory"><i class="fa fa-check"></i><b>13.2.2</b> Exploratory versus Confirmatory<span></span></a></li>
<li class="chapter" data-level="13.2.3" data-path="ChapDataSystems.html"><a href="ChapDataSystems.html#supervised-versus-unsupervised"><i class="fa fa-check"></i><b>13.2.3</b> Supervised versus Unsupervised<span></span></a></li>
<li class="chapter" data-level="13.2.4" data-path="ChapDataSystems.html"><a href="ChapDataSystems.html#parametric-versus-nonparametric"><i class="fa fa-check"></i><b>13.2.4</b> Parametric versus Nonparametric<span></span></a></li>
<li class="chapter" data-level="13.2.5" data-path="ChapDataSystems.html"><a href="ChapDataSystems.html#S:expred"><i class="fa fa-check"></i><b>13.2.5</b> Explanation versus Prediction<span></span></a></li>
<li class="chapter" data-level="13.2.6" data-path="ChapDataSystems.html"><a href="ChapDataSystems.html#data-modeling-versus-algorithmic-modeling"><i class="fa fa-check"></i><b>13.2.6</b> Data Modeling versus Algorithmic Modeling<span></span></a></li>
<li class="chapter" data-level="13.2.7" data-path="ChapDataSystems.html"><a href="ChapDataSystems.html#big-data-analysis"><i class="fa fa-check"></i><b>13.2.7</b> Big Data Analysis<span></span></a></li>
<li class="chapter" data-level="13.2.8" data-path="ChapDataSystems.html"><a href="ChapDataSystems.html#reproducible-analysis"><i class="fa fa-check"></i><b>13.2.8</b> Reproducible Analysis<span></span></a></li>
<li class="chapter" data-level="13.2.9" data-path="ChapDataSystems.html"><a href="ChapDataSystems.html#ethical-issues"><i class="fa fa-check"></i><b>13.2.9</b> Ethical Issues<span></span></a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="ChapDataSystems.html"><a href="ChapDataSystems.html#data-analysis-techniques"><i class="fa fa-check"></i><b>13.3</b> Data Analysis Techniques<span></span></a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="ChapDataSystems.html"><a href="ChapDataSystems.html#exploratory-techniques"><i class="fa fa-check"></i><b>13.3.1</b> Exploratory Techniques<span></span></a></li>
<li class="chapter" data-level="13.3.2" data-path="ChapDataSystems.html"><a href="ChapDataSystems.html#confirmatory-techniques"><i class="fa fa-check"></i><b>13.3.2</b> Confirmatory Techniques<span></span></a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="ChapDataSystems.html"><a href="ChapDataSystems.html#some-r-functions"><i class="fa fa-check"></i><b>13.4</b> Some R Functions<span></span></a></li>
<li class="chapter" data-level="13.5" data-path="ChapDataSystems.html"><a href="ChapDataSystems.html#summary"><i class="fa fa-check"></i><b>13.5</b> Summary<span></span></a></li>
<li class="chapter" data-level="13.6" data-path="ChapDataSystems.html"><a href="ChapDataSystems.html#DS:further-reading-and-resources"><i class="fa fa-check"></i><b>13.6</b> Further Resources and Contributors<span></span></a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html"><i class="fa fa-check"></i><b>14</b> Dependence Modeling<span></span></a>
<ul>
<li class="chapter" data-level="14.1" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#S:VarTypes"><i class="fa fa-check"></i><b>14.1</b> Variable Types<span></span></a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#S:QuaVar"><i class="fa fa-check"></i><b>14.1.1</b> Qualitative Variables<span></span></a></li>
<li class="chapter" data-level="14.1.2" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#S:QuanVar"><i class="fa fa-check"></i><b>14.1.2</b> Quantitative Variables<span></span></a></li>
<li class="chapter" data-level="14.1.3" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#multivariate-variables"><i class="fa fa-check"></i><b>14.1.3</b> Multivariate Variables<span></span></a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#S:Measures"><i class="fa fa-check"></i><b>14.2</b> Classic Measures of Scalar Associations<span></span></a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#association-measures-for-quantitative-variables"><i class="fa fa-check"></i><b>14.2.1</b> Association Measures for Quantitative Variables<span></span></a></li>
<li class="chapter" data-level="14.2.2" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#rank-based-measures"><i class="fa fa-check"></i><b>14.2.2</b> Rank Based Measures<span></span></a></li>
<li class="chapter" data-level="14.2.3" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#nominal-variables"><i class="fa fa-check"></i><b>14.2.3</b> Nominal Variables<span></span></a></li>
<li class="chapter" data-level="14.2.4" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#ordinal-variables"><i class="fa fa-check"></i><b>14.2.4</b> Ordinal Variables<span></span></a></li>
<li class="chapter" data-level="14.2.5" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#interval-variables"><i class="fa fa-check"></i><b>14.2.5</b> Interval Variables<span></span></a></li>
<li class="chapter" data-level="14.2.6" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#discrete-and-continuous-variables"><i class="fa fa-check"></i><b>14.2.6</b> Discrete and Continuous Variables<span></span></a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#S:Copula"><i class="fa fa-check"></i><b>14.3</b> Introduction to Copulas<span></span></a></li>
<li class="chapter" data-level="14.4" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#S:CopAppl"><i class="fa fa-check"></i><b>14.4</b> Application Using Copulas<span></span></a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#data-description"><i class="fa fa-check"></i><b>14.4.1</b> Data Description<span></span></a></li>
<li class="chapter" data-level="14.4.2" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#marginal-models"><i class="fa fa-check"></i><b>14.4.2</b> Marginal Models<span></span></a></li>
<li class="chapter" data-level="14.4.3" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#probability-integral-transformation"><i class="fa fa-check"></i><b>14.4.3</b> Probability Integral Transformation<span></span></a></li>
<li class="chapter" data-level="14.4.4" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#joint-modeling-with-copula-function"><i class="fa fa-check"></i><b>14.4.4</b> Joint Modeling with Copula Function<span></span></a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#S:CopTyp"><i class="fa fa-check"></i><b>14.5</b> Types of Copulas<span></span></a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#normal-gaussian-copulas"><i class="fa fa-check"></i><b>14.5.1</b> Normal (Gaussian) Copulas<span></span></a></li>
<li class="chapter" data-level="14.5.2" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#t--and-elliptical-copulas"><i class="fa fa-check"></i><b>14.5.2</b> <em>t</em>- and Elliptical Copulas<span></span></a></li>
<li class="chapter" data-level="14.5.3" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#archimedean-copulas"><i class="fa fa-check"></i><b>14.5.3</b> Archimedean Copulas<span></span></a></li>
<li class="chapter" data-level="14.5.4" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#properties-of-copulas"><i class="fa fa-check"></i><b>14.5.4</b> Properties of Copulas<span></span></a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#S:CopImp"><i class="fa fa-check"></i><b>14.6</b> Why is Dependence Modeling Important?<span></span></a></li>
<li class="chapter" data-level="14.7" data-path="ChapDependenceModel.html"><a href="ChapDependenceModel.html#Dep:further-reading-and-resources"><i class="fa fa-check"></i><b>14.7</b> Further Resources and Contributors<span></span></a>
<ul>
<li><a href="ChapDependenceModel.html#ts-14.a.-other-classic-measures-of-scalar-associations">TS 14.A. Other Classic Measures of Scalar Associations<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="CAppA.html"><a href="CAppA.html"><i class="fa fa-check"></i><b>15</b> Appendix A: Review of Statistical Inference<span></span></a>
<ul>
<li class="chapter" data-level="15.1" data-path="CAppA.html"><a href="CAppA.html#S:AppA:BASIC"><i class="fa fa-check"></i><b>15.1</b> Basic Concepts<span></span></a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="CAppA.html"><a href="CAppA.html#random-sampling"><i class="fa fa-check"></i><b>15.1.1</b> Random Sampling<span></span></a></li>
<li class="chapter" data-level="15.1.2" data-path="CAppA.html"><a href="CAppA.html#sampling-distribution"><i class="fa fa-check"></i><b>15.1.2</b> Sampling Distribution<span></span></a></li>
<li class="chapter" data-level="15.1.3" data-path="CAppA.html"><a href="CAppA.html#central-limit-theorem"><i class="fa fa-check"></i><b>15.1.3</b> Central Limit Theorem<span></span></a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="CAppA.html"><a href="CAppA.html#S:AppA:PE"><i class="fa fa-check"></i><b>15.2</b> Point Estimation and Properties<span></span></a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="CAppA.html"><a href="CAppA.html#method-of-moments-estimation"><i class="fa fa-check"></i><b>15.2.1</b> Method of Moments Estimation<span></span></a></li>
<li class="chapter" data-level="15.2.2" data-path="CAppA.html"><a href="CAppA.html#S:AppA:MLE"><i class="fa fa-check"></i><b>15.2.2</b> Maximum Likelihood Estimation<span></span></a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="CAppA.html"><a href="CAppA.html#S:AppA:IE"><i class="fa fa-check"></i><b>15.3</b> Interval Estimation<span></span></a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="CAppA.html"><a href="CAppA.html#S:AppA:IE:ED"><i class="fa fa-check"></i><b>15.3.1</b> Exact Distribution for Normal Sample Mean<span></span></a></li>
<li class="chapter" data-level="15.3.2" data-path="CAppA.html"><a href="CAppA.html#large-sample-properties-of-mle"><i class="fa fa-check"></i><b>15.3.2</b> Large-sample Properties of <em>MLE</em><span></span></a></li>
<li class="chapter" data-level="15.3.3" data-path="CAppA.html"><a href="CAppA.html#confidence-interval"><i class="fa fa-check"></i><b>15.3.3</b> Confidence Interval<span></span></a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="CAppA.html"><a href="CAppA.html#S:AppA:HT"><i class="fa fa-check"></i><b>15.4</b> Hypothesis Testing<span></span></a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="CAppA.html"><a href="CAppA.html#basic-concepts"><i class="fa fa-check"></i><b>15.4.1</b> Basic Concepts<span></span></a></li>
<li class="chapter" data-level="15.4.2" data-path="CAppA.html"><a href="CAppA.html#student-t-test-based-on-mle"><i class="fa fa-check"></i><b>15.4.2</b> Student-<em>t</em> test based on <em>mle</em><span></span></a></li>
<li class="chapter" data-level="15.4.3" data-path="CAppA.html"><a href="CAppA.html#S:AppA:HT:LRT"><i class="fa fa-check"></i><b>15.4.3</b> Likelihood Ratio Test<span></span></a></li>
<li class="chapter" data-level="15.4.4" data-path="CAppA.html"><a href="CAppA.html#S:AppA:HT:IC"><i class="fa fa-check"></i><b>15.4.4</b> Information Criteria<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="CAppB.html"><a href="CAppB.html"><i class="fa fa-check"></i><b>16</b> Appendix B: Iterated Expectations<span></span></a>
<ul>
<li class="chapter" data-level="16.1" data-path="CAppB.html"><a href="CAppB.html#S:AppB:CD"><i class="fa fa-check"></i><b>16.1</b> Conditional Distribution and Conditional Expectation<span></span></a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="CAppB.html"><a href="CAppB.html#conditional-distribution"><i class="fa fa-check"></i><b>16.1.1</b> Conditional Distribution<span></span></a></li>
<li class="chapter" data-level="16.1.2" data-path="CAppB.html"><a href="CAppB.html#conditional-expectation-and-conditional-variance"><i class="fa fa-check"></i><b>16.1.2</b> Conditional Expectation and Conditional Variance<span></span></a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="CAppB.html"><a href="CAppB.html#S:AppB:IE"><i class="fa fa-check"></i><b>16.2</b> Iterated Expectations and Total Variance<span></span></a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="CAppB.html"><a href="CAppB.html#S:AppB:LIE"><i class="fa fa-check"></i><b>16.2.1</b> Law of Iterated Expectations<span></span></a></li>
<li class="chapter" data-level="16.2.2" data-path="CAppB.html"><a href="CAppB.html#law-of-total-variance"><i class="fa fa-check"></i><b>16.2.2</b> Law of Total Variance<span></span></a></li>
<li class="chapter" data-level="16.2.3" data-path="CAppB.html"><a href="CAppB.html#application"><i class="fa fa-check"></i><b>16.2.3</b> Application<span></span></a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="CAppB.html"><a href="CAppB.html#S:AppConjugateDistributions"><i class="fa fa-check"></i><b>16.3</b> Conjugate Distributions<span></span></a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="CAppB.html"><a href="CAppB.html#linear-exponential-family"><i class="fa fa-check"></i><b>16.3.1</b> Linear Exponential Family<span></span></a></li>
<li class="chapter" data-level="16.3.2" data-path="CAppB.html"><a href="CAppB.html#S:IterExp:Conjugate"><i class="fa fa-check"></i><b>16.3.2</b> Conjugate Distributions<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="CAppC.html"><a href="CAppC.html"><i class="fa fa-check"></i><b>17</b> Appendix C: Maximum Likelihood Theory<span></span></a>
<ul>
<li class="chapter" data-level="17.1" data-path="CAppC.html"><a href="CAppC.html#S:AppC:LF"><i class="fa fa-check"></i><b>17.1</b> Likelihood Function<span></span></a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="CAppC.html"><a href="CAppC.html#likelihood-and-log-likelihood-functions"><i class="fa fa-check"></i><b>17.1.1</b> Likelihood and Log-likelihood Functions<span></span></a></li>
<li class="chapter" data-level="17.1.2" data-path="CAppC.html"><a href="CAppC.html#properties-of-likelihood-functions"><i class="fa fa-check"></i><b>17.1.2</b> Properties of Likelihood Functions<span></span></a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="CAppC.html"><a href="CAppC.html#S:AppC:MLE"><i class="fa fa-check"></i><b>17.2</b> Maximum Likelihood Estimators<span></span></a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="CAppC.html"><a href="CAppC.html#definition-and-derivation-of-mle"><i class="fa fa-check"></i><b>17.2.1</b> Definition and Derivation of <em>MLE</em><span></span></a></li>
<li class="chapter" data-level="17.2.2" data-path="CAppC.html"><a href="CAppC.html#asymptotic-properties-of-mle"><i class="fa fa-check"></i><b>17.2.2</b> Asymptotic Properties of <em>MLE</em><span></span></a></li>
<li class="chapter" data-level="17.2.3" data-path="CAppC.html"><a href="CAppC.html#use-of-maximum-likelihood-estimation"><i class="fa fa-check"></i><b>17.2.3</b> Use of Maximum Likelihood Estimation<span></span></a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="CAppC.html"><a href="CAppC.html#S:AppC:SI"><i class="fa fa-check"></i><b>17.3</b> Statistical Inference Based on Maximum Likelihood Estimation<span></span></a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="CAppC.html"><a href="CAppC.html#hypothesis-testing"><i class="fa fa-check"></i><b>17.3.1</b> Hypothesis Testing<span></span></a></li>
<li class="chapter" data-level="17.3.2" data-path="CAppC.html"><a href="CAppC.html#S:AppC:MLEModelVal"><i class="fa fa-check"></i><b>17.3.2</b> <em>MLE</em> and Model Validation<span></span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html"><i class="fa fa-check"></i><b>18</b> Appendix D: Summary of Distributions<span></span></a>
<ul>
<li class="chapter" data-level="18.1" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#S:DiscreteDistributions"><i class="fa fa-check"></i><b>18.1</b> Discrete Distributions<span></span></a>
<ul>
<li class="chapter" data-level="18.1.1" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#the-ab0-class"><i class="fa fa-check"></i><b>18.1.1</b> The <em>(a,b,0)</em> Class<span></span></a></li>
<li class="chapter" data-level="18.1.2" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#the-ab1-class"><i class="fa fa-check"></i><b>18.1.2</b> The <em>(a,b,1)</em> Class<span></span></a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#S:ContinuousDistributions"><i class="fa fa-check"></i><b>18.2</b> Continuous Distributions<span></span></a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#one-parameter-distributions"><i class="fa fa-check"></i><b>18.2.1</b> One Parameter Distributions<span></span></a></li>
<li class="chapter" data-level="18.2.2" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#two-parameter-distributions"><i class="fa fa-check"></i><b>18.2.2</b> Two Parameter Distributions<span></span></a></li>
<li class="chapter" data-level="18.2.3" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#three-parameter-distributions"><i class="fa fa-check"></i><b>18.2.3</b> Three Parameter Distributions<span></span></a></li>
<li class="chapter" data-level="18.2.4" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#four-parameter-distribution"><i class="fa fa-check"></i><b>18.2.4</b> Four Parameter Distribution<span></span></a></li>
<li class="chapter" data-level="18.2.5" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#other-distributions"><i class="fa fa-check"></i><b>18.2.5</b> Other Distributions<span></span></a></li>
<li class="chapter" data-level="18.2.6" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#distributions-with-finite-support"><i class="fa fa-check"></i><b>18.2.6</b> Distributions with Finite Support<span></span></a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="ChapSummaryDistributions.html"><a href="ChapSummaryDistributions.html#limited-expected-values"><i class="fa fa-check"></i><b>18.3</b> Limited Expected Values<span></span></a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="ChapNotationConvention.html"><a href="ChapNotationConvention.html"><i class="fa fa-check"></i><b>19</b> Appendix E: Conventions for Notation<span></span></a>
<ul>
<li class="chapter" data-level="19.1" data-path="ChapNotationConvention.html"><a href="ChapNotationConvention.html#S:General"><i class="fa fa-check"></i><b>19.1</b> General Conventions<span></span></a></li>
<li class="chapter" data-level="19.2" data-path="ChapNotationConvention.html"><a href="ChapNotationConvention.html#S:Abbreviations"><i class="fa fa-check"></i><b>19.2</b> Abbreviations<span></span></a></li>
<li class="chapter" data-level="19.3" data-path="ChapNotationConvention.html"><a href="ChapNotationConvention.html#S:StatSymbols"><i class="fa fa-check"></i><b>19.3</b> Common Statistical Symbols and Operators<span></span></a></li>
<li class="chapter" data-level="19.4" data-path="ChapNotationConvention.html"><a href="ChapNotationConvention.html#S:Symbols"><i class="fa fa-check"></i><b>19.4</b> Common Mathematical Symbols and Functions<span></span></a></li>
<li class="chapter" data-level="19.5" data-path="ChapNotationConvention.html"><a href="ChapNotationConvention.html#further-readings"><i class="fa fa-check"></i><b>19.5</b> Further Readings<span></span></a></li>
</ul></li>
<li><a href="bibliography.html#bibliography">Bibliography<span></span></a></li>
<li class="divider"></li>
<li><a href="https://github.com/OpenActTexts/Loss-Data-Analytics" target="blank">Loss Data Analytics on GitHub</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Loss Data Analytics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ChapCredibility" class="section level1 hasAnchor" number="9">
<h1><span class="header-section-number">Chapter 9</span> Experience Rating Using Credibility Theory<a href="ChapCredibility.html#ChapCredibility" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><em>Chapter Preview.</em> This chapter introduces credibility theory as an important actuarial tool for estimating pure premiums, frequencies, and severities for individual risks or classes of risks. Credibility theory provides a convenient framework for combining the experience for an individual risk or class with other data to produce more stable and accurate estimates. Several models for calculating credibility estimates will be discussed including limited fluctuation, Bhlmann, Bhlmann-Straub, and nonparametric and semiparametric credibility methods. The chapter will also show a connection between credibility theory and Bayesian estimation which was introduced in Chapter <a href="ChapModelSelection.html#ChapModelSelection">4</a>.</p>
<div id="introduction-to-applications-of-credibility-theory" class="section level2 hasAnchor" number="9.1">
<h2><span class="header-section-number">9.1</span> Introduction to Applications of Credibility Theory<a href="ChapCredibility.html#introduction-to-applications-of-credibility-theory" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>What premium should be charged to provide insurance? The answer depends upon the exposure to the risk of loss. A common method to compute an insurance premium is to rate an insured using a <a href="#" class="tooltip" style="color:green"><em>classification rating plan</em><span style="font-size:8pt">A rating plan that uses an insureds risk characteristics to determine premium</span></a>. A classification plan is used to select an insurance rate based on an insureds rating characteristics such as geographic territory, age, etc. All classification rating plans use a limited set of criteria to group insureds into a class and there will be variation in the risk of loss among insureds within the class.</p>
<p>An experience rating plan attempts to capture some of the variation in the risk of loss among insureds within a rating class by using the insureds own loss experience to complement the rate from the classification rating plan. One way to do this is to use a <a href="#" class="tooltip" style="color:green"><em>credibility weight</em><span style="font-size:8pt">The weight assigned to an insureds historical loss experience for the purposes of determining their premium in an experience rating plan</span></a> <span class="math inline">\(Z\)</span> with <span class="math inline">\(0\leq Z \leq 1\)</span> to compute</p>
<p><span class="math display">\[
\hat{R}=Z\bar{X}+(1-Z)M,
\]</span></p>
<p><span class="math display">\[\begin{eqnarray*}
\hat{R}&amp;=&amp;\textrm{credibility weighted rate for risk,}\\
           \bar{X}&amp;=&amp;\textrm{average loss for the risk over a specified time period,}\\
                  M&amp;=&amp;\textrm{the rate for the classification group, often called the manual rate.}\\
\end{eqnarray*}\]</span></p>
<p>For a risk whose loss experience is stable from year to year, <span class="math inline">\(Z\)</span> might be close to 1. For a risk whose losses vary widely from year to year, <span class="math inline">\(Z\)</span> may be close to 0.</p>
<p>Credibility theory is also used for computing rates for individual classes within a classification rating plan. When classification plan rates are being determined, some or many of the groups may not have sufficient data to produce stable and reliable rates. The actual loss experience for a group will be assigned a credibility weight <span class="math inline">\(Z\)</span> and the <a href="#" class="tooltip" style="color:green"><em>complement of credibility</em><span style="font-size:8pt">The remainder of the weight not assigned to an insureds historical loss experience in the experience rating plan</span></a> <span class="math inline">\(1-Z\)</span> may be given to the average experience for risks across all classes. Or, if a class rating plan is being updated, the complement of credibility may be assigned to the current <a href="#" class="tooltip" style="color:green"><em>class rate</em><span style="font-size:8pt">Average rate per exposure for an insured in a particular classification group</span></a>. Credibility theory can also be applied to the calculation of expected frequencies and severities.</p>
<p>Computing numeric values for <span class="math inline">\(Z\)</span> requires analysis and understanding of the data. What are the variances in the number of losses and sizes of losses for risks? What is the variance between expected values across risks?</p>
<div id="surveyElement91">

</div>
<div id="surveyResult91">

</div>
<h5 style="text-align: center;">
<a id="display.Quiz91.1" href="javascript:toggleQuiz
('display.Quiz91.2','display.Quiz91.1');"><i><strong>Show Quiz Solution</strong></i></a>
</h5>
<div id="display.Quiz91.2" style="display: none">
<p id="Quiz91Soln">
</p>
<hr />
</div>
<script type="text/javascript" src="./Quizzes/QuizJavascript/Quiz91.js">
</script>
</div>
<div id="limited-fluctuation-credibility" class="section level2 hasAnchor" number="9.2">
<h2><span class="header-section-number">9.2</span> Limited Fluctuation Credibility<a href="ChapCredibility.html#limited-fluctuation-credibility" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<hr />
<p>In this section, you learn how to:</p>
<ul>
<li>Calculate full credibility standards for number of claims, average size of claims, and aggregate losses.</li>
<li>Learn how the relationship between means and variances of underlying distributions affects full credibility standards.</li>
<li>Determine credibility-weight <span class="math inline">\(Z\)</span> using the square-root partial credibility formula.</li>
</ul>
<hr />
<p><a href="#" class="tooltip" style="color:green"><em>Limited fluctuation credibility</em><span style="font-size:8pt">A credibility method that attempts to limit fluctuations in its estimates</span></a>, also called classical credibility and American credibility, was given this name because the method explicitly attempts to limit fluctuations in estimates for claim frequencies, severities, or losses. For example, suppose that you want to estimate the expected number of claims <span class="math inline">\(N\)</span> for a group of risks in an insurance rating class. How many risks are needed in the class to ensure that a specified level of accuracy is attained in the estimate? First the question will be considered from the perspective of how many claims are needed.</p>
<div id="S:frequency" class="section level3 hasAnchor" number="9.2.1">
<h3><span class="header-section-number">9.2.1</span> Full Credibility for Claim Frequency<a href="ChapCredibility.html#S:frequency" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let <span class="math inline">\(N\)</span> be a random variable representing the number of claims for a group of risks, for example, risks within a particular rating classification. The observed number of claims will be used to estimate <span class="math inline">\(\mu_N=\mathrm{E}[N]\)</span>, the expected number of claims. How big does <span class="math inline">\(\mu_N\)</span> need to be to get a good estimate? One way to quantify the accuracy of the estimate would be with a statement like: ``The observed value of <span class="math inline">\(N\)</span> should be within 5<span class="math inline">\(\%\)</span> of <span class="math inline">\(\mu_N\)</span> at least 90<span class="math inline">\(\%\)</span> of the time. Writing this as a mathematical expression would give <span class="math inline">\(\Pr[0.95 \mu_N \leq N \leq 1.05 \mu_N] \geq 0.90\)</span>. Generalizing this statement by letting the range parameter <span class="math inline">\(k\)</span> replace 5<span class="math inline">\(\%\)</span> and probability level <span class="math inline">\(p\)</span> replace 0.90 gives the equation</p>
<p><span class="math display" id="eq:kpercent-interval">\[\begin{equation}
\Pr[(1-k) \mu_N \leq N \leq (1+k) \mu_N] \geq p .
\tag{9.1}
\end{equation}\]</span></p>
<p>The expected number of claims required for the probability on the left-hand side of <a href="ChapCredibility.html#eq:kpercent-interval">(9.1)</a> to equal <span class="math inline">\(p\)</span> is called the <a href="#" class="tooltip" style="color:green"><em>full credibility standard</em><span style="font-size:8pt">The threshold of experience necessary to assign 100% credibility to the insureds own experience</span></a>.</p>
<p>If the expected number of claims is greater than or equal to the full credibility standard then full credibility can be assigned to the data so <span class="math inline">\(Z=1\)</span>. Usually the expected value <span class="math inline">\(\mu_N\)</span> is not known so full credibility will be assigned to the data if the actual observed number of claims <span class="math inline">\(n\)</span> is greater than or equal to the full credibility standard. The <span class="math inline">\(k\)</span> and <span class="math inline">\(p\)</span> values must be selected and the actuary may rely on experience, judgment, and other factors in making the choices.</p>
<p>Subtracting <span class="math inline">\(\mu_N\)</span> from each term in <a href="ChapCredibility.html#eq:kpercent-interval">(9.1)</a> and dividing by the standard deviation <span class="math inline">\(\sigma_N\)</span> of <span class="math inline">\(N\)</span> gives</p>
<p><span class="math display" id="eq:normalized-interval">\[\begin{equation}
\Pr\left[\frac{-k\mu_N}{\sigma_N}\leq \frac{N-\mu_N}{\sigma_N} \leq \frac{k\mu_N}{\sigma_N}\right] \geq p.
\tag{9.2}
\end{equation}\]</span></p>
<p>In limited fluctuation credibility the standard normal distribution is used to approximate the distribution of <span class="math inline">\((N-\mu_N)/\sigma_N\)</span>. If <span class="math inline">\(N\)</span> is the sum of many claims from a large group of similar risks and the claims are independent, then the approximation may be reasonable.</p>
<p>Let <span class="math inline">\(y_p\)</span> be the value such that</p>
<p><span class="math display">\[
\Pr[-y_p\leq \frac{N-\mu_N}{\sigma_N} \leq y_p]=\Phi(y_p)-\Phi(-y_p)=p
\]</span></p>
<p>where <span class="math inline">\(\Phi( )\)</span> is the <a href="#" class="tooltip" style="color:green"><em>cumulative distribution function of the standard normal</em><span style="font-size:8pt">Cumulative density function for the normal distribution with mean 0 and standard deviation 1</span></a>. Because <span class="math inline">\(\Phi(-y_p)=1-\Phi(y_p)\)</span>, the equality can be rewritten as <span class="math inline">\(2\Phi(y_p)-1=p\)</span>. Solving for <span class="math inline">\(y_p\)</span> gives <span class="math inline">\(y_p=\Phi^{-1}((p+1)/2)\)</span> where <span class="math inline">\(\Phi^{-1}( )\)</span> is the inverse of <span class="math inline">\(\Phi( )\)</span>.</p>
<p>Equation <a href="ChapCredibility.html#eq:normalized-interval">(9.2)</a> will be satisfied if <span class="math inline">\(k\mu_N/\sigma_N \geq y_p\)</span> assuming the normal approximation. First we will consider this inequality for the case when <span class="math inline">\(N\)</span> has a Poisson distribution: <span class="math inline">\(\Pr[N=n] = \lambda^n\textrm{e}^{-\lambda}/n!\)</span>. Because <span class="math inline">\(\lambda=\mu_N=\sigma_N^2\)</span> for the Poisson, taking square roots yields <span class="math inline">\(\mu_N^{1/2}=\sigma_N\)</span>. So, <span class="math inline">\(k\mu_N/\mu_N^{1/2} \geq y_p\)</span> which is equivalent to <span class="math inline">\(\mu_N \geq (y_p/k)^2\)</span>. Lets define <span class="math inline">\(\lambda_{kp}\)</span> to be the value of <span class="math inline">\(\mu_N\)</span> for which equality holds. Then the full credibility standard for the Poisson distribution is</p>
<p><span class="math display" id="eq:full-credibility-Poisson">\[\begin{equation}
\lambda_{kp} = \left(\frac{y_p}{k}\right)^2 \textrm{with } y_p=\Phi^{-1}((p+1)/2).
\tag{9.3}
\end{equation}\]</span></p>
<p>If the expected number of claims <span class="math inline">\(\mu_N\)</span> is greater than or equal to <span class="math inline">\(\lambda_{kp}\)</span> then equation <a href="ChapCredibility.html#eq:kpercent-interval">(9.1)</a> is assumed to hold and full credibility can be assigned to the data. As noted previously, because <span class="math inline">\(\mu_N\)</span> is usually unknown, full credibility is given if the observed number of claims <span class="math inline">\(n\)</span> satisfies <span class="math inline">\(n \geq \lambda_{kp}.\)</span></p>
<p><strong>Example 9.2.1.</strong>
The full credibility standard is set so that the observed number of claims is to be within 5% of the expected value with probability <span class="math inline">\(p=0.95\)</span>. If the number of claims has a Poisson distribution find the number of claims needed for full credibility.</p>
<h5 style="text-align: center;">
<a id="displayExample.9.2.1" href="javascript:toggleEX('toggleExample.9.2.1','displayExample.9.2.1');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.9.2.1" style="display: none">
<p><strong>Solution.</strong> Referring to a standard normal distribution table, <span class="math inline">\(y_p=\Phi^{-1}((p+1)/2)=\Phi^{-1}((0.95+1)/2)\)</span>=<span class="math inline">\(\Phi^{-1}(0.975)=1.960\)</span>. Using this value and <span class="math inline">\(k=.05\)</span> then <span class="math inline">\(\lambda_{kp} = (y_p/k)^{2}=(1.960/0.05)^{2}=1,536.64\)</span>. After rounding up the full credibility standard is 1,537.</p>
</div>
<hr />
<p>If claims are not Poisson distributed then equation <a href="ChapCredibility.html#eq:normalized-interval">(9.2)</a> does not imply <a href="ChapCredibility.html#eq:full-credibility-Poisson">(9.3)</a>. Setting the upper bound of <span class="math inline">\((N-\mu_N)/\sigma_N\)</span> in <a href="ChapCredibility.html#eq:normalized-interval">(9.2)</a> equal to <span class="math inline">\(y_p\)</span> gives <span class="math inline">\(k\mu_N/\sigma_N=y_p\)</span>. Squaring both sides and moving everything to the right side except for one of the <span class="math inline">\(\mu_N\)</span>s gives <span class="math inline">\(\mu_N=(y_p/k)^2(\sigma_N^2/\mu_N)\)</span>. This is the full credibility standard for frequency and will be denoted by <span class="math inline">\(n_f\)</span>,</p>
<p><span class="math display" id="eq:full-credibility-frequency">\[\begin{equation}
n_f=\left(\frac{y_p}{k}\right)^2\left(\frac{\sigma_N^2}{\mu_N}\right)=\lambda_{kp}\left(\frac{\sigma_N^2}{\mu_N}\right).
\tag{9.4}
\end{equation}\]</span></p>
<p>This is the same equation as the Poisson full credibility standard except for the <span class="math inline">\((\sigma_N^2/\mu_N)\)</span> multiplier. When the claims distribution is Poisson this extra term is one because the variance equals the mean.</p>
<p><strong>Example 9.2.2.</strong>
The full credibility standard is set so that the total number of claims is to be within 5<span class="math inline">\(\%\)</span> of the observed value with probability <span class="math inline">\(p=0.95\)</span>. The number of claims has a negative binomial distribution,</p>
<p><span class="math display">\[
\Pr(N=x)={x+r-1\choose x} \left(\frac{1}{1+\beta}\right)^r \left(\frac{\beta}{1+\beta}\right)^x ,
\]</span></p>
<p>with <span class="math inline">\(\beta=1\)</span>. Calculate the full credibility standard.</p>
<h5 style="text-align: center;">
<a id="displayExample.9.2.2" href="javascript:toggleEX('toggleExample.9.2.2','displayExample.9.2.2');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.9.2.2" style="display: none">
<p><strong>Solution</strong> From the prior example, <span class="math inline">\(\lambda_{kp} =1,536.64\)</span>. The mean and variance for the negative binomial are <span class="math inline">\(\mathrm{E}(N)=r\beta\)</span> and <span class="math inline">\(\mathrm{Var}(N)=r\beta(1+\beta)\)</span> so <span class="math inline">\((\sigma_N^2/\mu_N)=(r\beta(1+\beta)/(r\beta))=1+\beta\)</span> which equals 2 when <span class="math inline">\(\beta=1\)</span>. So, <span class="math inline">\(n_f=\lambda_{kp}(\sigma_N^2/\mu_N)=1,536.64(2)=3,073.28\)</span> and rounding up gives a full credibility standard of 3,074.</p>
</div>
<hr />
<p>We see that the negative binomial distribution with <span class="math inline">\((\sigma_N^2/\mu_N)&gt;1\)</span> requires more claims for full credibility than a Poisson distribution for the same <span class="math inline">\(k\)</span> and <span class="math inline">\(p\)</span> values. The next example shows that a binomial distribution which has <span class="math inline">\((\sigma_N^2/\mu_N)&lt;1\)</span> will need fewer claims for full credibility.</p>
<p><strong>Example 9.2.3.</strong>
The full credibility standard is set so that the total number of claims is to be within 5<span class="math inline">\(\%\)</span> of the observed value with probability <span class="math inline">\(p=0.95\)</span>. The number of claims has a binomial distribution</p>
<p><span class="math display">\[
\Pr(N=x)={m\choose x}q^x(1-q)^{m-x}.
\]</span></p>
<p>Calculate the full credibility standard for <span class="math inline">\(q=1/4\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayExample.9.2.3" href="javascript:toggleEX('toggleExample.9.2.3','displayExample.9.2.3');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.9.2.3" style="display: none">
<p><strong>Solution</strong> From the first example in this section <span class="math inline">\(\lambda_{kp} =1,536.64\)</span>. The mean and variance for a binomial are <span class="math inline">\(\mathrm{E}(N)=mq\)</span> and <span class="math inline">\(\mathrm{Var}(N)=mq(1-q)\)</span> so <span class="math inline">\((\sigma_N^2/\mu_N)=(mq(1-q)/(mq))=1-q\)</span> which equals 3/4 when <span class="math inline">\(q=1/4\)</span>. So, <span class="math inline">\(n_f=\lambda_{kp}(\sigma_N^2/\mu_N)=1,536.64(3/4)=1,152.48\)</span> and rounding up gives a full credibility standard of 1,153.</p>
</div>
<hr />
<p>Rather than using expected number of claims to define the full credibility standard, the number of exposures can be used for the full credibility standard. An exposure is a measure of risk. For example, one car insured for a full year would be one car-year. Two cars each insured for exactly one-half year would also result in one car-year. Car-years attempt to quantify exposure to loss. Two car-years would be expected to generate twice as many claims as one car-year if the vehicles have the same risk of loss. To translate a full credibility standard denominated in terms of number of claims to a full credibility standard denominated in exposures one needs a reasonable estimate of the expected number of claims per exposure.</p>
<p><strong>Example 9.2.4.</strong>
The full credibility standard should be selected so that the observed number of claims will be within 5<span class="math inline">\(\%\)</span> of the expected value with probability <span class="math inline">\(p=0.95\)</span>. The number of claims has a Poisson distribution. If one exposure is expected to have about 0.20 claims per year, find the number of exposures needed for full credibility.</p>
<h5 style="text-align: center;">
<a id="displayExample.9.2.4" href="javascript:toggleEX('toggleExample.9.2.4','displayExample.9.2.4');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.9.2.4" style="display: none">
<p><strong>Solution</strong> With <span class="math inline">\(p=0.95\)</span> and <span class="math inline">\(k=.05\)</span>, <span class="math inline">\(\lambda_{kp} = (y_p/k)^{2}=(1.960/0.05)^{2}=1,536.64\)</span> claims are required for full credibility. The claims frequency rate is 0.20 claims per exposure. To convert the full credibility standard to a standard denominated in exposures the calculation is: (1,536.64 claims)/(0.20 claims/exposures) = 7,683.20 exposures. This can be rounded up to 7,684.</p>
</div>
<hr />
<p>Frequency can be defined as the number of claims per exposure. Letting <span class="math inline">\(m\)</span> denote the number of exposures. Then, if observed claim frequency <span class="math inline">\(N/m\)</span> is used to estimate <span class="math inline">\(\mathrm{E}(N/m)\)</span>:</p>
<p><span class="math display">\[
\Pr[(1-k)\mathrm{E}(N/m)\leq N/m \leq(1+k)\mathrm{E}(N/m)] \geq p.
\]</span></p>
<p>Because the number of exposures is not a random variable, <span class="math inline">\(\mathrm{E}(N/m)=\mathrm{E}(N)/m=\mu_N/m\)</span> and the prior equation becomes</p>
<p><span class="math display">\[
\Pr\left[(1-k)\frac{\mu_N}{m}\leq \frac{N}{m} \leq(1+k)\frac{\mu_N}{m}\right] \geq p.
\]</span></p>
<p>Multiplying through by <span class="math inline">\(m\)</span> results in equation <a href="ChapCredibility.html#eq:kpercent-interval">(9.1)</a> at the beginning of the section. The full credibility standards that were developed for estimating expected number of claims also apply to frequency.</p>
</div>
<div id="full-credibility-for-aggregate-losses-and-pure-premium" class="section level3 hasAnchor" number="9.2.2">
<h3><span class="header-section-number">9.2.2</span> Full Credibility for Aggregate Losses and Pure Premium<a href="ChapCredibility.html#full-credibility-for-aggregate-losses-and-pure-premium" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Aggregate losses are the total of all loss amounts for a risk or group of risks. Letting <span class="math inline">\(S\)</span> represent aggregate losses</p>
<p><span class="math display">\[
S=X_1+X_2+\cdots+X_N.
\]</span></p>
<p>The random variable <span class="math inline">\(N\)</span> represents the number of losses and random variables <span class="math inline">\(X_1, X_2,\ldots,X_N\)</span> are the individual loss amounts. In this section it is assumed that <span class="math inline">\(N\)</span> is independent of the loss amounts and that <span class="math inline">\(X_1, X_2,\ldots,X_N\)</span> are <a href="#" class="tooltip" style="color:green"><em>iid</em><span style="font-size:8pt">Independent and identically distributed</span></a>.</p>
<p>The mean and variance of <span class="math inline">\(S\)</span> are</p>
<p><span class="math display">\[
\mu_S=\mathrm{E}(S)=\mathrm{E}(N)\mathrm{E}(X)=\mu_N\mu_X
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\sigma^{2}_S=\mathrm{Var}(S)=\mathrm{E}(N)\mathrm{Var}(X)+[\mathrm{E}(X)]^{2}\mathrm{Var}(N)=\mu_N\sigma^{2}_X+\mu^{2}_X\sigma^{2}_N ,
\]</span></p>
<p>where <span class="math inline">\(X\)</span> is the amount of a single loss. See the discussion on <em>collective risk models</em> in Section <a href="ChapAggLossModels.html#S:AggLoss:CRM">5.3</a> for more discussion of this framework.</p>
<p>Observed losses <span class="math inline">\(S\)</span> will be used to estimate expected losses <span class="math inline">\(\mu_S=\mathrm{E}(S)\)</span>. As with the frequency model in the previous section, the observed losses must be close to the expected losses as quantified in the equation</p>
<p><span class="math display">\[
\Pr[(1-k)\mu_S\leq S \leq(1+k)\mu_S] \geq p.
\]</span></p>
<p>After subtracting the mean and dividing by the standard deviation,</p>
<p><span class="math display">\[
\Pr\left[\frac{-k\mu_S}{\sigma_S}\leq (S-\mu_S)/\sigma_S \leq \frac{k\mu_S}{\sigma_S}\right] \geq p .
\]</span></p>
<p>As done in the previous section the distribution for <span class="math inline">\((S-\mu_S)/\sigma_S\)</span> is assumed to be standard normal and <span class="math inline">\(k\mu_S/\sigma_S=y_p=\Phi^{-1}((p+1)/2)\)</span>. This equation can be rewritten as <span class="math inline">\(\mu_S^2=(y_p/k)^2\sigma_S^2\)</span>. Using the prior formulas for <span class="math inline">\(\mu_S\)</span> and <span class="math inline">\(\sigma_{S}^2\)</span> gives <span class="math inline">\((\mu_N\mu_X)^2=(y_p/k)^2(\mu_N\sigma^{2}_X+\mu^{2}_X\sigma^{2}_N)\)</span>. Dividing both sides by <span class="math inline">\(\mu_N\mu_X^2\)</span> and reordering terms on the right side results in a full credibility standard <span class="math inline">\(n_S\)</span> for aggregate losses</p>
<p><span class="math display" id="eq:full-credibility-losses">\[\begin{equation}
n_S=\left(\frac{y_p}{k}\right)^2\left[\left(\frac{\sigma_N^2}{\mu_N}\right)+\left(\frac{\sigma_X}{\mu_X}\right)^2\right]=\lambda_{kp}\left[\left(\frac{\sigma_N^2}{\mu_N}\right)+\left(\frac{\sigma_X}{\mu_X}\right)^2\right].
\tag{9.5}
\end{equation}\]</span></p>
<p><strong>Example 9.2.5.</strong>
The number of claims has a Poisson distribution. Individual loss amounts are independently and identically distributed with a Pareto distribution <span class="math inline">\(F(x)=1-[\theta/(x+\theta)]^{\alpha}\)</span>. The number of claims and loss amounts are independent.
If observed aggregate losses should be within 5<span class="math inline">\(\%\)</span> of the expected value with probability <span class="math inline">\(p=0.95\)</span>, how many losses are required for full credibility?</p>
<h5 style="text-align: center;">
<a id="displayExample.9.2.5" href="javascript:toggleEX('toggleExample.9.2.5','displayExample.9.2.5');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.9.2.5" style="display: none">
<p><strong>Solution.</strong> Because the number of claims is Poisson, <span class="math inline">\((\sigma_N^2/\mu_N)=1\)</span>. The mean of the Pareto is <span class="math inline">\(\mu_X=\theta/(\alpha-1)\)</span> and the variance is <span class="math inline">\(\sigma_X^2=\theta^{2}\alpha/[(\alpha-1)^{2}(\alpha-2)]\)</span> so <span class="math inline">\((\sigma_X/\mu_X)^2=\alpha/(\alpha-2)\)</span>. Combining the frequency and severity terms gives <span class="math inline">\([(\sigma_N^2/\mu_N)+(\sigma_X/\mu_X)^2]=2(\alpha-1)/(\alpha-2)\)</span>. From a standard normal distribution table <span class="math inline">\(y_p=\Phi^{-1}((0.95+1)/2)=1.960\)</span>. The full credibility standard is <span class="math inline">\(n_S=(1.96/0.05)^{2}[2(\alpha-1)/(\alpha-2)]=3,073.28(\alpha-1)/(\alpha-2)\)</span>. Suppose <span class="math inline">\(\alpha=3\)</span> then <span class="math inline">\(n_S=6,146.56\)</span> for a full credibility standard of 6,147. Note that considerably more claims are needed for full credibility for aggregate losses than frequency alone.</p>
</div>
<hr />
<p>When the number of claims is Poisson distributed then equation <a href="ChapCredibility.html#eq:full-credibility-losses">(9.5)</a> can be simplified using <span class="math inline">\((\sigma_N^2/\mu_N)=1\)</span>. It follows that</p>
<p><span class="math display">\[
[(\sigma_N^2/\mu_N)+(\sigma_X/\mu_X)^2]=[1+(\sigma_X/\mu_X)^2]=[(\mu_X^2+\sigma_X^2)/\mu_X^2]=\mathrm{E}(X^2)/\mathrm{E}(X)^2
\]</span></p>
<p>using the relationship <span class="math inline">\(\mu_X^2+\sigma_X^2=\mathrm{E}(X^2)\)</span>. The full credibility standard is <span class="math inline">\(n_S=\lambda_{kp}~\mathrm{E}(X^2)/\mathrm{E}(X)^2\)</span>.</p>
<p>The pure premium <span class="math inline">\(PP\)</span> is equal to aggregate losses <span class="math inline">\(S\)</span> divided by exposures <span class="math inline">\(m\)</span>: <span class="math inline">\(PP=S/m\)</span>. The full credibility standard for pure premium will require</p>
<p><span class="math display">\[
\Pr\left[(1-k)\mu_{PP}\leq PP \leq(1+k)\mu_{PP}\right] \geq p.
\]</span></p>
<p>The number of exposures <span class="math inline">\(m\)</span> is assumed fixed and not a random variable so <span class="math inline">\(\mu_{PP}=\mathrm{E}(S/m)=\mathrm{E}(S)/m=\mu_S/m\)</span>.</p>
<p><span class="math display">\[
\Pr\left[(1-k)\left(\frac{\mu_S}{m}\right)\leq \left(\frac{S}{m}\right) \leq(1+k)\left(\frac{\mu_S}{m}\right)\right] \geq p.
\]</span></p>
<p>Multiplying through by <span class="math inline">\(m\)</span> returns the bounds for losses</p>
<p><span class="math display">\[
\Pr[(1-k)\mu_S\leq S \leq(1+k)\mu_S] \geq p.
\]</span></p>
<p>This means that the full credibility standard <span class="math inline">\(n_{PP}\)</span> for the pure premium is the same as that for aggregate losses</p>
<p><span class="math display">\[
n_{PP}=n_S=\lambda_{kp}\left[\left(\frac{\sigma_N^2}{\mu_n}\right)+\left(\frac{\sigma_X}{\mu_X}\right)^2\right].
\]</span></p>
</div>
<div id="full-credibility-for-severity" class="section level3 hasAnchor" number="9.2.3">
<h3><span class="header-section-number">9.2.3</span> Full Credibility for Severity<a href="ChapCredibility.html#full-credibility-for-severity" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let <span class="math inline">\(X\)</span> be a random variable representing the size of one claim. Claim severity is <span class="math inline">\(\mu_X=\mathrm{E}(X)\)</span>. Suppose that <span class="math inline">\({X_1,X_2, \ldots, X_n}\)</span> is a random sample of <span class="math inline">\(n\)</span> claims that will be used to estimate claim severity <span class="math inline">\(\mu_X\)</span>. The claims are assumed to be <em>iid</em>. The average value of the sample is</p>
<p><span class="math display">\[
\bar{X}=\frac{1}{n}\left(X_1+X_2+\cdots+X_n\right).
\]</span></p>
<p>How big does <span class="math inline">\(n\)</span> need to be to get a good estimate? Note that <span class="math inline">\(n\)</span> is not a random variable whereas it is in the aggregate loss model.</p>
<p>In Section <a href="ChapCredibility.html#S:frequency">9.2.1</a> the accuracy of an estimator for frequency was defined by requiring that the number of claims lie within a specified interval about the mean number of claims with a specified probability. For severity this requirement is</p>
<p><span class="math display">\[
\Pr[(1-k)\mu_X\leq \bar{X} \leq(1+k)\mu_X ]\geq p ,
\]</span></p>
<p>where <span class="math inline">\(k\)</span> and <span class="math inline">\(p\)</span> need to be specified. Following the steps in Section <a href="ChapCredibility.html#S:frequency">9.2.1</a>, the mean claim severity <span class="math inline">\(\mu_X\)</span> is subtracted from each term and the standard deviation of the claim severity estimator <span class="math inline">\(\sigma_{\bar{X}}\)</span> is divided into each term yielding</p>
<p><span class="math display">\[
\Pr\left[\frac{-k~\mu_X}{\sigma_{\bar{X}}}\leq (\bar{X}-\mu_X)/\sigma_{\bar{X}} \leq \frac{k~\mu_X}{\sigma_{\bar{X}}}\right] \geq p .
\]</span></p>
<p>As in prior sections, it is assumed that <span class="math inline">\((\bar{X}-\mu_X)/\sigma_{\bar{X}}\)</span> is approximately normally distributed and the prior equation is satisfied if <span class="math inline">\(k\mu_X/\sigma_{\bar{X}}\geq y_p\)</span> with <span class="math inline">\(y_p=\Phi^{-1}((p+1)/2)\)</span>. Because <span class="math inline">\(\bar{X}\)</span> is the average of individual claims <span class="math inline">\(X_1, X_2,\dots, X_n\)</span>, its standard deviation is equal to the standard deviation of an individual claim divided by <span class="math inline">\(\sqrt{n}\)</span>: <span class="math inline">\(\sigma_{\bar{X}}=\sigma_X/\sqrt{n}\)</span>. So, <span class="math inline">\(k\mu_X/(\sigma_X/\sqrt{n})\geq y_p\)</span> and with a little algebra this can be rewritten as <span class="math inline">\(n \geq (y_p/k)^2(\sigma_X/\mu_X)^2\)</span>. The full credibility standard for severity is</p>
<p><span class="math display" id="eq:full-credibility-severity">\[\begin{equation}
n_X=\left(\frac{y_p}{k}\right)^2\left(\frac{\sigma_X}{\mu_X}\right)^2=\lambda_{kp}\left(\frac{\sigma_X}{\mu_X}\right)^2.
\tag{9.6}
\end{equation}\]</span></p>
<p>Note that the term <span class="math inline">\(\sigma_X/\mu_X\)</span> is the <a href="#" class="tooltip" style="color:green"><em>coefficient of variation</em><span style="font-size:8pt">Standard deviation divided by the mean of a distribution, to measure variability in terms of units of the mean</span></a> for an individual claim. Even though <span class="math inline">\(\lambda_{kp}\)</span> is the full credibility standard for frequency given a Poisson distribution, there is no assumption about the distribution for the number of claims.</p>
<p><strong>Example 9.2.6.</strong>
Individual loss amounts are independently and identically distributed with a Type II Pareto distribution <span class="math inline">\(F(x)=1-[\theta/(x+\theta)]^{\alpha}\)</span>. How many claims are required for the average severity of observed claims to be within 5<span class="math inline">\(\%\)</span> of the expected severity with probability <span class="math inline">\(p=0.95\)</span>?</p>
<h5 style="text-align: center;">
<a id="displayExample.9.2.6" href="javascript:toggleEX('toggleExample.9.2.6','displayExample.9.2.6');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.9.2.6" style="display: none">
<p><strong>Solution.</strong> The mean of the Pareto is <span class="math inline">\(\mu_X=\theta/(\alpha-1)\)</span> and the variance is <span class="math inline">\(\sigma_X^2=\theta^{2}\alpha/[(\alpha-1)^{2}(\alpha-2)]\)</span> so <span class="math inline">\((\sigma_X/\mu_X)^2=\alpha/(\alpha-2)\)</span>. From a standard normal distribution table <span class="math inline">\(y_p=\Phi^{-1}((0.95+1)/2)=1.960\)</span>. The full credibility standard is <span class="math inline">\(n_X=(1.96/0.05)^{2}[\alpha/(\alpha-2)]=1,536.64\alpha/(\alpha-2)\)</span>. Suppose <span class="math inline">\(\alpha=3\)</span> then <span class="math inline">\(n_X=4,609.92\)</span> for a full credibility standard of 4,610.</p>
</div>
<hr />
</div>
<div id="partial-credibility" class="section level3 hasAnchor" number="9.2.4">
<h3><span class="header-section-number">9.2.4</span> Partial Credibility<a href="ChapCredibility.html#partial-credibility" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In prior sections full credibility standards were calculated for estimating frequency (<span class="math inline">\(n_f\)</span>), pure premium (<span class="math inline">\(n_{PP}\)</span>), and severity (<span class="math inline">\(n_X\)</span>) - in this section these full credibility standards will be denoted by <span class="math inline">\(n_{0}\)</span>. In each case the full credibility standard was the expected number of claims required to achieve a defined level of accuracy when using empirical data to estimate an expected value. If the observed number of claims is greater than or equal to the full credibility standard then a full credibility weight <span class="math inline">\(Z=1\)</span> is given to the data.</p>
<p>In limited fluctuation credibility, credibility weights <span class="math inline">\(Z\)</span> assigned to data are</p>
<!-- $$  -->
<!-- Z=\quad \sqrt{\frac{n}{n_{0}}} \quad \textrm{if} \quad   n < n_{0} \quad \textrm{and}  \quad Z=\quad 1 \quad \textrm{for} \quad   n \geq n_{0} , -->
<!-- $$ -->
<p><span class="math display">\[
Z=
\left\{
\begin{array}{ll}
\sqrt{n /n_{0}} &amp;\textrm{if }   n &lt; n_{0} \\
1 &amp; \textrm{if }   n \ge n_{0} ,
\end{array}
\right.
\]</span></p>
<p>where <span class="math inline">\(n_0\)</span> is the full credibility standard. The quantity <span class="math inline">\(n\)</span> is the number of claims for the data that is used to estimate the expected frequency, severity, or pure premium.</p>
<p><strong>Example 9.2.7.</strong>
The number of claims has a Poisson distribution. Individual loss amounts are independently and identically distributed with a Type II Pareto distribution <span class="math inline">\(F(x)=1-[\theta/(x+\theta)]^{\alpha}\)</span>. Assume that <span class="math inline">\(\alpha=3\)</span>. The number of claims and loss amounts are independent. The full credibility standard is that the observed pure premium should be within 5<span class="math inline">\(\%\)</span> of the expected value with probability <span class="math inline">\(p=0.95\)</span>. What credibility <span class="math inline">\(Z\)</span> is assigned to a pure premium computed from 1,000 claims?</p>
<h5 style="text-align: center;">
<a id="displayExample.9.2.7" href="javascript:toggleEX('toggleExample.9.2.7','displayExample.9.2.7');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.9.2.7" style="display: none">
<p><strong>Solution.</strong> Because the number of claims is Poisson,</p>
<p><span class="math display">\[
\frac{\mathrm{E}(X^2)}{[\mathrm{E}~(X)]^2}
=\frac{\sigma_N^2}{\mu_N}+\left(\frac{\sigma_X}{\mu_X}\right)^2.  
\]</span></p>
<p>The mean of the Pareto is <span class="math inline">\(\mu_X=\theta/(\alpha-1)\)</span> and the second moment is <span class="math inline">\(\mathrm{E}(X^2)=2\theta^{2}/[(\alpha-1)(\alpha-2)]\)</span> so <span class="math inline">\(\mathrm{E}(X^2)/[\mathrm{E}~(X)]^2=2(\alpha-1)/(\alpha-2)\)</span>. From a standard normal distribution table, <span class="math inline">\(y_p=\Phi^{-1}((0.95+1)/2)=1.960\)</span>. The full credibility standard is</p>
<p><span class="math display">\[
n_{PP}=(1.96/0.05)^{2}[2(\alpha-1)/(\alpha-2)]=3,073.28(\alpha-1)/(\alpha-2)
\]</span></p>
<p>and if <span class="math inline">\(\alpha=3\)</span> then <span class="math inline">\(n_0=n_{PP}=6,146.56\)</span> or 6,147 if rounded up. The credibility assigned to 1,000 claims is <span class="math inline">\(Z=(1,000/6,147)^{1/2}=0.40\)</span>.</p>
</div>
<hr />
<p>Limited fluctuation credibility uses the formula <span class="math inline">\(Z=\sqrt{n/n_0}\)</span> to limit the fluctuation in the credibility-weighted estimate to match the fluctuation allowed for data with expected claims at the full credibility standard. Variance or standard deviation is used as the measure of fluctuation. Next we show an example to explain why the square-root formula is used.</p>
<p>Suppose that average claim severity is being estimated from a sample of size <span class="math inline">\(n\)</span> that is less than the full credibility standard <span class="math inline">\(n_0=n_X\)</span>. Applying credibility theory, the estimate <span class="math inline">\(\hat{\mu}_X\)</span> would be</p>
<p><span class="math display">\[
\hat{\mu}_X=Z\bar{X}+(1-Z)M_X ,
\]</span></p>
<p>with <span class="math inline">\(\bar{X}=(X_1+X_2+\cdots+X_n)/n\)</span> and <span class="math inline">\(iid\)</span> random variables <span class="math inline">\(X_i\)</span> representing the sizes of individual claims. The complement of credibility is applied to <span class="math inline">\(M_X\)</span> which could be last years estimated average severity adjusted for inflation, the average severity for a much larger pool of risks, or some other relevant quantity selected by the actuary. It is assumed that the variance of <span class="math inline">\(M_X\)</span> is zero or negligible. With this assumption</p>
<p><span class="math display">\[
\mathrm{Var}(\hat{\mu}_X)=\mathrm{Var}(Z\bar{X})=Z^2\mathrm{Var}(\bar{X})=\frac{n}{n_0}\mathrm{Var}(\bar{X}).
\]</span></p>
<p>Because <span class="math inline">\(\bar{X}=(X_1+X_2+\cdots+X_n)/n\)</span> it follows that <span class="math inline">\(\mathrm{Var}(\bar{X})=\mathrm{Var}(X_i)/n\)</span> where random variable <span class="math inline">\(X_i\)</span> is one claim. So,</p>
<p><span class="math display">\[
\mathrm{Var}(\hat{\mu}_X)=\frac{n}{n_0}\mathrm{Var}(\bar{X})=\frac{n}{n_0}\frac{\mathrm{Var}(X_i)}{n}=\frac{\mathrm{Var}(X_i)}{n_0}.
\]</span></p>
<p>The last term is exactly the variance of a sample mean <span class="math inline">\(\bar{X}\)</span> when the sample size is equal to the full credibility standard <span class="math inline">\(n_0=n_X\)</span>.</p>
<div id="surveyElement92">

</div>
<div id="surveyResult92">

</div>
<h5 style="text-align: center;">
<a id="display.Quiz92.1" href="javascript:toggleQuiz
('display.Quiz92.2','display.Quiz92.1');"><i><strong>Show Quiz Solution</strong></i></a>
</h5>
<div id="display.Quiz92.2" style="display: none">
<p id="Quiz92Soln">
</p>
<hr />
</div>
<script type="text/javascript" src="./Quizzes/QuizJavascript/Quiz92.js">
</script>
</div>
</div>
<div id="S:Cred:Buhlmann" class="section level2 hasAnchor" number="9.3">
<h2><span class="header-section-number">9.3</span> Bhlmann Credibility<a href="ChapCredibility.html#S:Cred:Buhlmann" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<hr />
<p>In this section, you learn how to:</p>
<ul>
<li>Compute a credibility-weighted estimate for the expected loss for a risk or group of risks.</li>
<li>Determine the credibility <span class="math inline">\(Z\)</span> assigned to observations.</li>
<li>Calculate the values required in Bhlmann credibility including the Expected Value of the Process Variance (<span class="math inline">\(EPV\)</span>), Variance of the Hypothetical Means (<span class="math inline">\(VHM\)</span>) and collective mean <span class="math inline">\(\mu\)</span>.</li>
<li>Recognize situations when the Bhlmann model is appropriate.</li>
</ul>
<hr />
<p>A classification rating plan groups policyholders together into classes based on risk characteristics. Although policyholders within a class have similarities, they are not identical and their expected losses will not be exactly the same. An experience rating plan can supplement a class rating plan by credibility weighting an individual policyholders loss experience with the class rate to produce a more accurate rate for the policyholder.</p>
<p>In the presentation of <a href="#" class="tooltip" style="color:green"><em>Buhlmann credibility</em><span style="font-size:8pt">A credibility method that uses the amount of experience, expected value of the process variance, and variance of the hypothetical means to determine the credibility weight</span></a> it is convenient to assign a <a href="#" class="tooltip" style="color:green"><em>risk parameter</em><span style="font-size:8pt">Parameter in a distribution whose value reflects the risk categorization</span></a> <span class="math inline">\(\theta\)</span> to each policyholder. Losses <span class="math inline">\(X\)</span> for the policyholder will have a common distribution function <span class="math inline">\(F_{\theta}(x)\)</span> with mean <span class="math inline">\(\mu(\theta)=\mathrm{E}(X|\theta)\)</span> and variance <span class="math inline">\(\sigma^2(\theta)=\mathrm{Var}(X|\theta)\)</span>. Losses <span class="math inline">\(X\)</span> can represent pure premiums, aggregate losses, number of claims, claim severities, or some other measure of loss for a period of time, often one year. Risk parameter <span class="math inline">\(\theta\)</span> may be continuous or discrete and may be multivariate depending on the model.</p>
<p>If a policyholder with risk parameter <span class="math inline">\(\theta\)</span> had losses <span class="math inline">\(X_1, \ldots, X_n\)</span> during <span class="math inline">\(n\)</span> time periods then the goal is to find <span class="math inline">\(\mathrm{E}(\mu(\theta)|X_1,\ldots, X_n)\)</span>, the conditional expectation of <span class="math inline">\(\mu(\theta)\)</span> given <span class="math inline">\(X_1,\ldots, X_n\)</span>. The Bhlmann credibility-weighted estimate for <span class="math inline">\(\mathrm{E}(\mu(\theta)|X_1,\ldots, X_n)\)</span> for the policyholder is</p>
<p><span class="math display" id="eq:buhlcred">\[\begin{equation}
\hat{\mu}(\theta)=Z\bar{X}+(1-Z)\mu
\tag{9.7}
\end{equation}\]</span></p>
<p>with</p>
<p><span class="math display">\[\begin{eqnarray*}
\theta&amp;=&amp;\textrm{a risk parameter that identifies a policyholder&#39;s risk level}\\
\hat{\mu}(\theta)&amp;=&amp;\textrm{estimated expected loss for a policyholder with parameter }\theta\\
&amp; &amp; \textrm{and loss experience } \bar{X}\\
\bar{X}&amp;=&amp;(X_1+\cdots+X_n)/n \textrm{ is the average of $n$ observations of the policyholder } \\
Z&amp;=&amp;\textrm{credibility assigned to $n$ observations } \\
\mu&amp;=&amp;\textrm{the expected loss for a randomly chosen policyholder in the class.}\\
\end{eqnarray*}\]</span></p>
<p>For a selected policyholder, random variables <span class="math inline">\(X_j\)</span> are assumed to be <em>iid</em> for <span class="math inline">\(j=1,\ldots,n\)</span> because it is assumed that the policyholders exposure to loss is not changing through time. The quantity <span class="math inline">\(\bar{X}\)</span> is the average of <span class="math inline">\(n\)</span> observations and <span class="math inline">\(\mathrm{E}(\bar{X}|\theta)=\mathrm{E}(X_j|\theta)=\mu(\theta)\)</span>.</p>
<p>If a policyholder is randomly chosen from the class and there is no loss information about the risk then the expected loss is <span class="math inline">\(\mu=\mathrm{E}(\mu(\theta))\)</span> where the expectation is taken over all <span class="math inline">\(\theta\)</span>s in the class. In this situation <span class="math inline">\(Z=0\)</span> and the expected loss is <span class="math inline">\(\hat\mu(\theta)=\mu\)</span> for the risk. The quantity <span class="math inline">\(\mu\)</span> can also be written as <span class="math inline">\(\mu=\mathrm{E}(X_j)\)</span> or <span class="math inline">\(\mu=\mathrm{E}(\bar{X})\)</span> and is often called the overall mean or <a href="#" class="tooltip" style="color:green"><em>collective mean</em><span style="font-size:8pt">The mean estimate of a risk when no loss information about the risk is known</span></a>. Note that <span class="math inline">\(\mathrm{E}(X_j)\)</span> is evaluated with the <a href="#" class="tooltip" style="color:green"><em>law of total expectation</em><span style="font-size:8pt">The expected value of the conditional expected value of x given y is the same as the expected value of x</span></a>: <span class="math inline">\(\mathrm{E}(X_j)=\mathrm{E}(\mathrm{E}[X_j|\theta])\)</span>.</p>
<p><strong>Example 9.3.1.</strong>
The number of claims <span class="math inline">\(X\)</span> for an insured in a class has a Poisson distribution with mean <span class="math inline">\(\theta&gt;0\)</span>. The risk parameter <span class="math inline">\(\theta\)</span> is exponentially distributed within the class with <a href="#" class="tooltip" style="color:green"><em>pdf</em><span style="font-size:8pt">Probability density function</span></a> <span class="math inline">\(f(\theta)=e^{-\theta}\)</span>. What is the expected number of claims for an insured chosen at random from the class?</p>
<h5 style="text-align: center;">
<a id="displayExample.9.3.1" href="javascript:toggleEX('toggleExample.9.3.1','displayExample.9.3.1');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.9.3.1" style="display: none">
<p><strong>Solution</strong> Random variable <span class="math inline">\(X\)</span> is Poisson with parameter <span class="math inline">\(\theta\)</span> and E<span class="math inline">\((X|\theta)=\theta\)</span>. The expected number of claims for a randomly chosen insured is <span class="math inline">\(\mu=\mathrm{E}(\mu(\theta))=\mathrm{E}(\mathrm{E}(X|\theta))=\)</span>E<span class="math inline">\((\theta)=\int_{0}^{\infty}\theta e^{-\theta} d\theta=1\)</span>.</p>
</div>
<hr />
<p>In the prior example the risk parameter <span class="math inline">\(\theta\)</span> is a random variable with an exponential distribution. In the next example there are three types of risks and the risk parameter has a discrete distribution.</p>
<p><strong>Example 9.3.2.</strong> For any risk (policyholder) in a population the number of losses <span class="math inline">\(N\)</span> in a year has a Poisson distribution with parameter <span class="math inline">\(\lambda\)</span>. Individual loss amounts <span class="math inline">\(X_i\)</span> for a risk are independent of <span class="math inline">\(N\)</span> and are <em>iid</em> with Type II Pareto distribution <span class="math inline">\(F(x)=1-[\theta/(x+\theta)]^{\alpha}\)</span>. There are three types of risks in the population as follows:</p>
<p><span class="math display">\[
\small{
\begin{array}{|c|c|c|c|}
\hline
\text{Risk } &amp; \text{Percentage} &amp; \text{Poisson} &amp; \text{Pareto} \\
\text{Type} &amp; \text{of Population} &amp; \text{Parameter} &amp; \text{Parameters} \\
\hline
A &amp; 50\% &amp; \lambda=0.5 &amp; \theta=1000, \alpha=2.0 \\
B &amp; 30\% &amp; \lambda=1.0 &amp; \theta=1500, \alpha=2.0 \\  
C &amp; 20\% &amp; \lambda=2.0 &amp; \theta=2000, \alpha=2.0 \\              
\hline
\end{array}
}
\]</span></p>
<p>If a risk is selected at random from the population, what is the expected aggregate loss in a year?</p>
<h5 style="text-align: center;">
<a id="displayExample.9.3.2" href="javascript:toggleEX('toggleExample.9.3.2','displayExample.9.3.2');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.9.3.2" style="display: none">
<p><strong>Solution</strong> The expected number of claims for a risk is <span class="math inline">\(\mathrm{E}(N|\lambda\)</span>)=<span class="math inline">\(\lambda\)</span>. The expected value for a Pareto distributed random variable is <span class="math inline">\(\mathrm{E}(X | \theta, \alpha\)</span>)=<span class="math inline">\(\theta/(\alpha-1)\)</span>. The expected value of the aggregate loss random variable <span class="math inline">\(S=X_1+\cdots+X_N\)</span> for a risk with parameters <span class="math inline">\(\lambda\)</span>, <span class="math inline">\(\alpha\)</span>, and <span class="math inline">\(\theta\)</span> is <span class="math inline">\(\mathrm{E}(S)=\mathrm{E}(N)\mathrm{E}(X)\)</span> = <span class="math inline">\(\lambda\theta/(\alpha-1)\)</span>. The expected aggregate loss for a risk of type A is <span class="math inline">\(\mathrm{E}(S_{\textrm{A}}\)</span>)=(0.5)(1000)/(2-1)=500. The expected aggregate loss for a risk selected at random from the population is <span class="math inline">\(\mathrm{E}(S)\)</span> = 0.5[(0.5)(1000)]+0.3[(1.0)(1500)]+0.2[(2.0)(2000)]=1500.</p>
</div>
<hr />
<p>What is the risk parameter for a risk (policyholder) in the prior example? One could say that the risk parameter has three components <span class="math inline">\((\lambda,\theta,\alpha)\)</span> with possible values (0.5,1000,2.0), (1.0,1500,2.0), and (2.0,2000,2.0) depending on the type of risk.</p>
<p>Note that in both of the examples the risk parameter is a random quantity with its own probability distribution. We do not know the value of the risk parameter for a randomly chosen risk.</p>
<p>Although formula <a href="ChapCredibility.html#eq:buhlcred">(9.7)</a> was introduced using experience rating as an example, the Bhlmann credibility model has wider application. Suppose that a rating plan has multiple classes. Credibility formula <a href="ChapCredibility.html#eq:buhlcred">(9.7)</a> can be used to determine individual class rates. The overall mean <span class="math inline">\(\mu\)</span> would be the average loss for all classes combined, <span class="math inline">\(\bar{X}\)</span> would be the experience for the individual class, and <span class="math inline">\(\hat{\mu}(\theta)\)</span> would be the estimated loss for the class.</p>
<div id="S:EPV-VHM-Z" class="section level3 hasAnchor" number="9.3.1">
<h3><span class="header-section-number">9.3.1</span> Credibility <em>Z</em>, <em>EPV</em>, and <em>VHM</em><a href="ChapCredibility.html#S:EPV-VHM-Z" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>When computing the credibility estimate <span class="math inline">\(\hat{\mu}(\theta)=Z\bar{X}+(1-Z)\mu\)</span>, how much weight <span class="math inline">\(Z\)</span> should go to experience <span class="math inline">\(\bar{X}\)</span> and how much weight <span class="math inline">\((1-Z)\)</span> to the overall mean <span class="math inline">\(\mu\)</span>? In Bhlmann credibility there are three factors that need to be considered:</p>
<ol style="list-style-type: decimal">
<li>How much variation is there in a single observation <span class="math inline">\(X_j\)</span> for a selected risk? With <span class="math inline">\(\bar{X}=(X_1+\cdots+X_n)/n\)</span> and assuming that the observations are <em>iid</em> conditional on <span class="math inline">\(\theta\)</span>, it follows that <span class="math inline">\(\mathrm{Var}(\bar{X}|\theta)\)</span> = <span class="math inline">\(\mathrm{Var}(X_j|\theta)/n\)</span>. For larger <span class="math inline">\(\mathrm{Var}(\bar{X}|\theta)\)</span> less credibility weight <span class="math inline">\(Z\)</span> should be given to experience <span class="math inline">\(\bar{X}\)</span>. The <a href="#" class="tooltip" style="color:green"><em>Expected Value of the Process Variance</em><span style="font-size:8pt">Average of the natural variability of observations from within each risk</span></a>, abbreviated <span class="math inline">\(EPV\)</span>, is the expected value of <span class="math inline">\(\mathrm{Var}(X_j|\theta\)</span>) across all risks:</li>
</ol>
<p><span class="math display">\[
EPV = \mathrm{E}(\mathrm{Var}(X_j|\theta)).
\]</span></p>
<p>Because <span class="math inline">\(\mathrm{Var}(\bar{X}|\theta)\)</span> = <span class="math inline">\(\mathrm{Var}(X_j|\theta)/n\)</span> it follows that <span class="math inline">\(\mathrm{E}(\mathrm{Var}(\bar{X}|\theta))=EPV/n\)</span>.</p>
<ol start="2" style="list-style-type: decimal">
<li>How homogeneous is the population of risks whose experience was combined to compute the overall mean <span class="math inline">\(\mu\)</span>? If all the risks are similar in loss potential then more weight <span class="math inline">\((1-Z)\)</span> would be given to the overall mean <span class="math inline">\(\mu\)</span> because <span class="math inline">\(\mu\)</span> is the average for a group of similar risks whose means <span class="math inline">\(\mu(\theta)\)</span> are not far apart. The homogeneity or heterogeneity of the population is measured by the <a href="#" class="tooltip" style="color:green"><em>Variance of the Hypothetical Means</em><span style="font-size:8pt">Variance of the means across different classes, used to determine how similar or different the classes are from one another</span></a> with abbreviation <span class="math inline">\(VHM\)</span>:</li>
</ol>
<p><span class="math display">\[
VHM=\mathrm{Var}(\mathrm{E}(X_j|\theta))=\mathrm{Var}(\mathrm{E}(\bar{X}|\theta)).
\]</span></p>
<p>Note that we used <span class="math inline">\(\mathrm{E}(\bar{X}|\theta)=\mathrm{E}(X_j|\theta)\)</span> for the second equality.</p>
<ol start="3" style="list-style-type: decimal">
<li>How many observations <span class="math inline">\(n\)</span> were used to compute <span class="math inline">\(\bar{X}\)</span>? A larger sample would infer a larger <span class="math inline">\(Z\)</span>.</li>
</ol>
<p><strong>Example 9.3.3.</strong> The number of claims <span class="math inline">\(N\)</span> in a year for a risk in a population has a Poisson distribution with mean <span class="math inline">\(\lambda&gt;0\)</span>. The risk parameter <span class="math inline">\(\lambda\)</span> is uniformly distributed over the interval <span class="math inline">\((0,2)\)</span>. Calculate the <span class="math inline">\(EPV\)</span> and <span class="math inline">\(VHM\)</span> for the population.</p>
<h5 style="text-align: center;">
<a id="displayExample.9.3.3" href="javascript:toggleEX('toggleExample.9.3.3','displayExample.9.3.3');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.9.3.3" style="display: none">
<p><strong>Solution.</strong> Random variable <span class="math inline">\(N\)</span> is Poisson with parameter <span class="math inline">\(\lambda\)</span> so <span class="math inline">\(\mathrm{Var}(N|\lambda)=\lambda\)</span>. The Expected Value of the Process variance is <span class="math inline">\(EPV=\mathrm{E}(\mathrm{Var}(N|\lambda))\)</span> = <span class="math inline">\(\mathrm{E}(\lambda)=\int_{0}^{2}\lambda \frac{1}{2} d\lambda=1\)</span>. The Variance of the Hypothetical Means is <span class="math inline">\(VHM=\mathrm{Var}(\mathrm{E}(N|\lambda))\)</span> = <span class="math inline">\(\mathrm{Var}(\lambda)=\mathrm{E}(\lambda^2)-(\mathrm{E}(\lambda))^2\)</span> = <span class="math inline">\(\int_{0}^{2}\lambda^2 \frac{1}{2} d\lambda-(1)^2=\frac{1}{3}\)</span>.</p>
</div>
<hr />
<p>The Bhlmann credibility formula includes values for <span class="math inline">\(n\)</span>, <span class="math inline">\(EPV\)</span>, and <span class="math inline">\(VHM\)</span>:</p>
<p><span class="math display" id="eq:buhlZ">\[\begin{equation}
Z=\frac{n}{n+K} \quad , \quad K =\frac{EPV}{VHM}.
\tag{9.8}
\end{equation}\]</span></p>
<p>If the <span class="math inline">\(VHM\)</span> increases then <span class="math inline">\(Z\)</span> increases. If the <span class="math inline">\(EPV\)</span> increases then <span class="math inline">\(Z\)</span> gets smaller. Unlike limited fluctuation credibility where <span class="math inline">\(Z=1\)</span> when the expected number of claims is greater than the full credibility standard, <span class="math inline">\(Z\)</span> can approach but not equal 1 as the number of observations <span class="math inline">\(n\)</span> goes to infinity.</p>
<p>If you multiply the numerator and denominator of the <span class="math inline">\(Z\)</span> formula by (<span class="math inline">\(VHM\)</span>/<span class="math inline">\(n\)</span>) then <span class="math inline">\(Z\)</span> can be rewritten as</p>
<p><span class="math display">\[
Z=\frac{VHM}{VHM+(EPV/n)} .
\]</span></p>
<p>The number of observations <span class="math inline">\(n\)</span> is captured in the term (<span class="math inline">\(EPV/n\)</span>). As shown in bullet (1) at the beginning of the section, <span class="math inline">\(\mathrm{E}(\mathrm{Var}(\bar{X}|\theta))\)</span> = <span class="math inline">\(EPV/n\)</span>. As the number of observations get larger, the expected variance of <span class="math inline">\(\bar{X}\)</span> gets smaller and credibility <span class="math inline">\(Z\)</span> increases so that more weight gets assigned to <span class="math inline">\(\bar{X}\)</span> in the credibility-weighted estimate <span class="math inline">\(\hat{\mu}(\theta)\)</span>.</p>
<p><strong>Example 9.3.4.</strong>
Use the law of total variance to show that <span class="math inline">\(\mathrm{Var}(\bar{X})\)</span> = <span class="math inline">\(VHM + (EPV/n)\)</span> and derive a formula for <span class="math inline">\(Z\)</span> in terms of <span class="math inline">\(\bar{X}\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayExample.9.3.4" href="javascript:toggleEX('toggleExample.9.3.4','displayExample.9.3.4');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.9.3.4" style="display: none">
<p><strong>Solution</strong> The quantity <span class="math inline">\(\mathrm{Var}(\bar{X})\)</span> is called the unconditional variance or the total variance of <span class="math inline">\(\bar{X}\)</span>. The law of total variance, equation <a href="CAppB.html#eq:LawTotVar">(16.2)</a>, says</p>
<p><span class="math display">\[
\mathrm{Var}(\bar{X})=\textrm{E(Var}(\bar{X}|\theta))+\textrm{Var(E}(\bar{X}|\theta)).
\]</span></p>
<p>In bullet (1) at the beginning of this section we showed <span class="math inline">\(\mathrm{E}(\mathrm{Var}(\bar{X}|\theta))\)</span> = <span class="math inline">\(EPV/n\)</span>. In the bullet (2), <span class="math inline">\(\mathrm{Var}(\mathrm{E}(\bar{X}|\theta))=VHM\)</span>. Reordering the right hand side gives <span class="math inline">\(\mathrm{Var}(\bar{X})\)</span> = <span class="math inline">\(VHM +(EPV/n)\)</span>. Another way to write the formula for credibility <span class="math inline">\(Z\)</span> is <span class="math inline">\(Z=\mathrm{Var}(\mathrm{E}(\bar{X}|\theta))/\mathrm{Var}(\bar{X})\)</span>. This implies <span class="math inline">\((1-Z)=\mathrm{E}(\mathrm{Var}(\bar{X}|\theta))/\mathrm{Var}(\bar{X})\)</span>.</p>
</div>
<hr />
<p>The following long example and solution demonstrate how to compute the credibility-weighted estimate with frequency and severity data.</p>
<p><strong>Example 9.3.5.</strong>
For any risk in a population the number of losses <span class="math inline">\(N\)</span> in a year has a Poisson distribution with parameter <span class="math inline">\(\lambda\)</span>. Individual loss amounts <span class="math inline">\(X\)</span> for a selected risk are independent of <span class="math inline">\(N\)</span> and are <em>iid</em> with exponential distribution <span class="math inline">\(F(x)=1-e^{-x/\beta}\)</span>. There are three types of risks in the population as shown below. A risk was selected at random from the population and all losses were recorded over a five-year period. The total amount of losses over the five-year period was 5,000. Use Bhlmann credibility to estimate the annual expected aggregate loss for the risk.</p>
<p><span class="math display">\[
\small{
\begin{array}{|c|c|c|c|}
\hline
\text{Risk } &amp; \text{Percentage} &amp; \text{Poisson} &amp; \text{Exponential} \\
\text{Type} &amp; \text{of Population} &amp; \text{Parameter} &amp; \text{Parameter} \\
\hline
A &amp; 50\% &amp; \lambda=0.5 &amp; \beta=1000 \\
B &amp; 30\% &amp; \lambda=1.0 &amp; \beta=1500 \\  
C &amp; 20\% &amp; \lambda=2.0 &amp; \beta=2000 \\              
\hline
\end{array}
}
\]</span></p>
<h5 style="text-align: center;">
<a id="displayExample.9.3.5" href="javascript:toggleEX('toggleExample.9.3.5','displayExample.9.3.5');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.9.3.5" style="display: none">
<p><strong>Solution</strong> Because individual loss amounts <span class="math inline">\(X\)</span> are exponentially distributed, <span class="math inline">\(\mathrm{E}(X| \beta)=\beta\)</span> and <span class="math inline">\(\mathrm{Var}(X| \beta)=\beta^2\)</span>. For aggregate loss <span class="math inline">\(S=X_1+\cdots+X_N\)</span>, the mean is <span class="math inline">\(\mathrm{E}(S)=\mathrm{E}(N)\mathrm{E}(X)\)</span> and process variance is <span class="math inline">\(\mathrm{Var}(S)=\mathrm{E}(N)\mathrm{Var}(X)+[\mathrm{E}(X)]^2 \mathrm{Var}(N)\)</span>. With Poisson frequency and exponentially distributed loss amounts, <span class="math inline">\(\mathrm{E}(S| \lambda, \beta) = \lambda\beta\)</span> and <span class="math inline">\(\mathrm{Var}(S| \lambda, \beta\)</span>) = <span class="math inline">\(\lambda\beta^2+\beta^2\lambda=2\lambda\beta^2\)</span>.<br />
<strong>Population mean <span class="math inline">\(\mu\)</span></strong>: Risk means are <span class="math inline">\(\mu\)</span>(A)=0.5(1000)=500; <span class="math inline">\(\mu\)</span>(B)=1.0(1500)=1500; <span class="math inline">\(\mu\)</span>(C)=2.0(2000)=4000; and <span class="math inline">\(\mu\)</span>=0.50(500)+0.30(1500)+0.20(4000)=1,500.<br />
<strong>VHM</strong>: <em>VHM</em>=<span class="math inline">\(0.50(500-1500)^2+0.30(1500-1500)^2+0.20(4000-1500)^2\)</span>=1,750,000.<br />
<strong>EPV</strong>: Process variances are <span class="math inline">\(\sigma^2(A)=2(0.5)(1000)^2=1,000,000\)</span>; <span class="math inline">\(\sigma^2(B)=2(1.0)(1500)^2=4,500,000\)</span>; <span class="math inline">\(\sigma^2(C)=2(2.0)(2000)^2=16,000,000\)</span>; and <span class="math inline">\(EPV\)</span>=0.50(1,000,000)+0.30(4,500,000)+0.20(16,000,000)=5,050,000.<br />
<strong><span class="math inline">\(\mathbf{\bar{X}}\)</span></strong>: <span class="math inline">\(\bar{X}_5=5,000/5\)</span>=1,000.<br />
<strong><span class="math inline">\(\mathbf{K}\)</span></strong>: <span class="math inline">\(K=5,050,000/1,750,000\)</span>=2.89.<br />
<strong><span class="math inline">\(\mathbf{Z}\)</span></strong>: There are five years of observations so <span class="math inline">\(n=5\)</span>. <span class="math inline">\(Z=5/(5+2.89)\)</span>=0.63.<br />
<strong><span class="math inline">\(\boldsymbol{\hat{\mu}(\theta)}\)</span></strong>: <span class="math inline">\(\hat{\mu}(\theta)=0.63(1,000)+(1-0.63)1,500=\boxed{\mathbf{1,185.00}}\)</span>.</p>
</div>
<hr />
<p>In real world applications of Bhlmann credibility the value of <span class="math inline">\(K=EPV/VHM\)</span> must be estimated. Sometimes a value for <span class="math inline">\(K\)</span> is selected using judgment. A smaller <span class="math inline">\(K\)</span> makes estimator <span class="math inline">\(\hat{\mu}(\theta)\)</span> more responsive to actual experience <span class="math inline">\(\bar{X}\)</span> whereas a larger <span class="math inline">\(K\)</span> produces a more stable estimate by giving more weight to <span class="math inline">\(\mu\)</span>. Judgment may be used to balance responsiveness and stability. A later section in this chapter will discuss methods for determining <span class="math inline">\(K\)</span> from data.</p>
<p>For a policyholder with risk parameter <span class="math inline">\(\theta\)</span>, Bhlmann credibility uses a linear approximation <span class="math inline">\(\hat{\mu}(\theta)=Z\bar{X}+(1-Z)\mu\)</span> to estimate <span class="math inline">\(\mathrm{E}(\mu(\theta)|X_1,\ldots,X_n)\)</span>, the expected loss for the policyholder given prior losses <span class="math inline">\(X_1,\ldots, X_n\)</span>. We can rewrite this as <span class="math inline">\(\hat{\mu}(\theta)=a+b\bar{X}\)</span> which makes it obvious that the credibility estimate is a linear function of <span class="math inline">\(\bar{X}\)</span>.</p>
<p>If <span class="math inline">\(\mathrm{E}(\mu(\theta)|X_1,\ldots,X_n)\)</span> is approximated by the linear function <span class="math inline">\(a+b\bar{X}\)</span> and constants <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are chosen so that <span class="math inline">\(\mathrm{E}[(\mathrm{E}(\mu(\theta)|X_1,\ldots,X_n)-(a+b\bar{X}))^2]\)</span> is minimized, what are <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>? The answer is <span class="math inline">\(b=n/(n+K)\)</span> and <span class="math inline">\(a=(1-b)\mu\)</span> with <span class="math inline">\(K=EPV/VHM\)</span> and <span class="math inline">\(\mu=\mathrm{E}(\mu(\theta))\)</span>. More details can be found in references <span class="citation">(<a href="#ref-Buhlmann1967" role="doc-biblioref">Bhlmann 1967</a>)</span>, <span class="citation">(<a href="#ref-BuhlmannGisler2005" role="doc-biblioref">Bhlmann and Gisler 2005</a>)</span>, <span class="citation">(<a href="#ref-klugman2012" role="doc-biblioref">Klugman, Panjer, and Willmot 2012</a>)</span>, and <span class="citation">(<a href="#ref-Tse2009" role="doc-biblioref">Tse 2009</a>)</span>.</p>
<p>Bhlmann credibility is also called least-squares credibility, greatest accuracy credibility, or Bayesian credibility.</p>
<div id="surveyElement93">

</div>
<div id="surveyResult93">

</div>
<h5 style="text-align: center;">
<a id="display.Quiz93.1" href="javascript:toggleQuiz
('display.Quiz93.2','display.Quiz93.1');"><i><strong>Show Quiz Solution</strong></i></a>
</h5>
<div id="display.Quiz93.2" style="display: none">
<p id="Quiz93Soln">
</p>
<hr />
</div>
<script type="text/javascript" src="./Quizzes/QuizJavascript/Quiz93.js">
</script>
</div>
</div>
<div id="bhlmann-straub-credibility" class="section level2 hasAnchor" number="9.4">
<h2><span class="header-section-number">9.4</span> Bhlmann-Straub Credibility<a href="ChapCredibility.html#bhlmann-straub-credibility" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<hr />
<p>In this section, you learn how to:</p>
<ul>
<li>Compute a credibility-weighted estimate for the expected loss for a risk or group of risks using the Bhlmann-Straub model.</li>
<li>Determine the credibility <span class="math inline">\(Z\)</span> assigned to observations.</li>
<li>Calculate required values including the Expected Value of the Process Variance (<span class="math inline">\(EPV\)</span>), Variance of the Hypothetical Means (<span class="math inline">\(VHM\)</span>) and collective mean <span class="math inline">\(\mu\)</span>.</li>
<li>Recognize situations when the Bhlmann-Straub model is appropriate.</li>
</ul>
<hr />
<p>With standard Bhlmann or least-squares credibility as described in the prior section, losses <span class="math inline">\(X_1,\ldots,X_n\)</span> arising from a selected policyholder are assumed to be <em>iid</em>. If the subscripts indicate year 1, year 2 and so on up to year <span class="math inline">\(n\)</span>, then the <em>iid</em> assumption means that the policyholder has the same exposure to loss every year. For commercial insurance this assumption is frequently violated.</p>
<p>Consider a commercial policyholder that uses a fleet of vehicles in its business. In year 1 there are <span class="math inline">\(m_1\)</span> vehicles in the fleet, <span class="math inline">\(m_2\)</span> vehicles in year 2, .., and <span class="math inline">\(m_n\)</span> vehicles in year <span class="math inline">\(n\)</span>. The exposure to loss from ownership and use of this fleet is not constant from year to year. The annual losses for the fleet are not <em>iid</em>.</p>
<p>Define <span class="math inline">\(Y_{jk}\)</span> to be the loss for the <span class="math inline">\(k^{th}\)</span> vehicle in the fleet for year <span class="math inline">\(j\)</span>. Then, the total losses for the fleet in year <span class="math inline">\(j\)</span> are <span class="math inline">\(Y_{j1}+\cdots+Y_{jm_j}\)</span> where we are adding up the losses for each of the <span class="math inline">\(m_j\)</span> vehicles. In the Bhlmann-Straub model it is assumed that random variables <span class="math inline">\(Y_{jk}\)</span> are <em>iid</em> across all vehicles and years for the policyholder. With this assumption the means <span class="math inline">\(\mathrm{E}(Y_{jk}|\theta)=\mu(\theta)\)</span> and variances <span class="math inline">\(\mathrm{Var}(Y_{jk}|\theta)=\sigma^2(\theta)\)</span> are the same for all vehicles and years. The quantity <span class="math inline">\(\mu(\theta)\)</span> is the expected loss and <span class="math inline">\(\sigma^2(\theta)\)</span> is the variance in the loss for one year for one vehicle for a policyholder with risk parameter <span class="math inline">\(\theta\)</span>.</p>
<p>If <span class="math inline">\(X_j\)</span> is the average loss per unit of exposure in year <span class="math inline">\(j\)</span>, <span class="math inline">\(X_j=(Y_{j1}+\cdots+Y_{jm_j})/m_j\)</span>, then <span class="math inline">\(\mathrm{E}(X_j|\theta)=\mu(\theta)\)</span> and <span class="math inline">\(\mathrm{Var}(X_j|\theta)=\sigma^2(\theta)/m_j\)</span> for a policyholder with risk parameter <span class="math inline">\(\theta\)</span>. Note that we used the fact that the <span class="math inline">\(Y_{jk}\)</span> are <em>iid</em> for a given policyholder. The average loss per vehicle for the entire <span class="math inline">\(n\)</span>-year period is</p>
<p><span class="math display">\[\begin{equation*}
\bar{X}= \frac{1}{m} \sum_{j=1}^{n} m_j X_{j} \quad , \quad  m=\sum_{j=1}^{n}  m_j.
\end{equation*}\]</span></p>
<p>It follows that E<span class="math inline">\((\bar{X}|\theta)=\mu(\theta)\)</span> and <span class="math inline">\(\mathrm{Var}(\bar{X}|\theta)=\sigma^2(\theta)/m\)</span> where <span class="math inline">\(\mu(\theta)\)</span> and <span class="math inline">\(\sigma^2(\theta)\)</span> are the mean and variance for a single vehicle for one year for the policyholder.</p>
<p><strong>Example 9.4.1.</strong>
Prove that <span class="math inline">\(\mathrm{Var}(\bar{X}|\theta)=\sigma^2(\theta)/m\)</span> for a risk with risk parameter <span class="math inline">\(\theta\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayExample.9.4.1" href="javascript:toggleEX('toggleExample.9.4.1','displayExample.9.4.1');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.9.4.1" style="display: none">
<p><strong>Solution</strong></p>
<p><span class="math display">\[\begin{eqnarray*}
\mathrm{Var}(\bar{X}|\theta)&amp;=&amp;\mathrm{Var}\left(\frac{1}{m} \sum_{j=1}^{n} m_j X_j|\theta \right)\\
                                  &amp;=&amp;\frac{1}{m^2}\sum_{j=1}^{n} \mathrm{Var}(m_j X_{j}|\theta)=\frac{1}{m^2}\sum_{j=1}^{n} m_j^2 \mathrm{Var}(X_j|\theta)\\
                                  &amp;=&amp;\frac{1}{m^2}\sum_{j=1}^{n} m_j^2 (\sigma^2(\theta)/m_j)=\frac{\sigma^2(\theta)}{m^2}\sum_{j=1}^{n} m_j=\sigma^2(\theta)/m.\\
\end{eqnarray*}\]</span></p>
</div>
<hr />
<p>The <a href="#" class="tooltip" style="color:green"><em>Buhlmann-Straub credibility</em><span style="font-size:8pt">An extension of the buhlmann credibility model that allows for varying exposure by year</span></a> estimate is:</p>
<p><span class="math display" id="eq:bscred">\[\begin{equation}\hat{\mu}(\theta)=Z\bar{X}+(1-Z)\mu
\tag{9.9}
\end{equation}\]</span></p>
<p>with</p>
<p><span class="math display">\[\begin{eqnarray*}
\theta&amp;=&amp;\textrm{a risk parameter that identifies a policyholder&#39;s risk level}\\
\hat{\mu}(\theta)&amp;=&amp;\textrm{estimated expected loss for one exposure for the policyholder}\\
&amp; &amp; \textrm{with loss experience } \bar{X}\\
\bar{X}&amp;=&amp; \frac{1}{m} \sum_{j=1}^{n} m_j X_j \textrm{ is the average loss per exposure for $m$ exposures.}\\
&amp; &amp; \textrm{$X_j$ is the average loss per exposure and $m_j$ is the number of exposures in year $j$.} \\
Z&amp;=&amp;\textrm{credibility assigned to $m$ exposures } \\
\mu&amp;=&amp;\textrm{expected loss for one exposure for randomly chosen}\\
&amp; &amp; \textrm{ policyholder from population.}\\
\end{eqnarray*}\]</span></p>
<p>Note that <span class="math inline">\(\hat{\mu}(\theta)\)</span> is the estimator for the expected loss for one exposure. If the policyholder has <span class="math inline">\(m_j\)</span> exposures then the expected loss is <span class="math inline">\(m_j\hat{\mu}(\theta)\)</span>.</p>
<p>In Example 9.3.4, it was shown that <span class="math inline">\(Z=\mathrm{Var}(\mathrm{E}(\bar{X}|\theta))/\mathrm{Var}(\bar{X})\)</span> where <span class="math inline">\(\bar{X}\)</span> is the average loss for <span class="math inline">\(n\)</span> observations. In equation <a href="ChapCredibility.html#eq:bscred">(9.9)</a> the <span class="math inline">\(\bar{X}\)</span> is the average loss for <span class="math inline">\(m\)</span> exposures and the same <span class="math inline">\(Z\)</span> formula can be used:</p>
<p><span class="math display">\[
Z=\frac{\mathrm{Var}(\mathrm{E}(\bar{X}|\theta))}{\mathrm{Var}(\bar{X})}=
\frac{\mathrm{Var}(\mathrm{E}(\bar{X}|\theta))}{\mathrm{E}(\mathrm{Var}(\bar{X}|\theta))+\mathrm{Var}(\mathrm{E}(\bar{X}|\theta))}.
\]</span></p>
<p>The denominator was expanded using the <a href="#" class="tooltip" style="color:green"><em>law of total variance</em><span style="font-size:8pt">A decomposition of the variance of a random variable into conditional components. specifically, for random variables x and y on the same probability space, var(x) = e[var(y|x)] + var[e(x|y)].</span></a>. As noted above <span class="math inline">\(\mathrm{E}(\bar{X}|\theta)=\mu(\theta)\)</span> so <span class="math inline">\(\mathrm{Var}(\mathrm{E}(\bar{X}|\theta))=\mathrm{Var}(\mu(\theta))=VHM\)</span>.
Because <span class="math inline">\(\mathrm{Var}(\bar{X}|\theta)=\sigma^2(\theta)/m\)</span> it follows that <span class="math inline">\(\mathrm{E}(\mathrm{Var}(\bar{X}|\theta))=\mathrm{E}(\sigma^2(\theta))/m\)</span> = <span class="math inline">\(EPV/m\)</span>. Making these substitutions and using a little algebra gives</p>
<p><span class="math display" id="eq:bsZ">\[\begin{equation}
Z=\frac{m}{m+K} \quad , \quad K =\frac{EPV}{VHM}.
\tag{9.10}
\end{equation}\]</span></p>
<p>This is the same <span class="math inline">\(Z\)</span> as for Bhlmann credibility except number of exposures <span class="math inline">\(m\)</span> replaces number of years or observations <span class="math inline">\(n\)</span>.</p>
<p><strong>Example 9.4.2.</strong> A commercial automobile policyholder had the following exposures and claims over a three-year period:</p>
<p><span class="math display">\[
\small{
\begin{array}{|c|c|c|}
\hline
\text{Year} &amp; \text{Number of Vehicles} &amp; \text{Number of Claims} \\
\hline
1 &amp;   9 &amp;  5  \\
2 &amp; 12 &amp;  4  \\  
3 &amp; 15 &amp;  4  \\              
\hline
\end{array}
}
\]</span></p>
<ul>
<li>The number of claims in a year for each vehicle in the policyholders fleet is Poisson distributed with the same mean (parameter) <span class="math inline">\(\lambda\)</span>.</li>
<li>Parameter <span class="math inline">\(\lambda\)</span> is distributed among the policyholders in the population with <em>pdf</em> <span class="math inline">\(f(\lambda)=6\lambda(1-\lambda)\)</span> with <span class="math inline">\(0&lt;\lambda&lt;1\)</span>.</li>
</ul>
<p>The policyholder has 18 vehicles in its fleet in year 4. Use Bhlmann-Straub credibility to estimate the expected number of policyholder claims in year 4.</p>
<h5 style="text-align: center;">
<a id="displayExample.9.4.2" href="javascript:toggleEX('toggleExample.9.4.2','displayExample.9.4.2');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.9.4.2" style="display: none">
<p><strong>Solution</strong> The expected number of claims for one vehicle for a randomly chosen policyholder is <span class="math inline">\(\mu=\mathrm{E}(\lambda)=\int_{0}^{1} \lambda[6\lambda(1-\lambda)] d\lambda=1/2\)</span>. The average number of claims per vehicle for the policyholder is <span class="math inline">\(\bar{X}\)</span>=13/36. The expected value of the process variance for a single vehicle is <span class="math inline">\(EPV=\mathrm{E}(\lambda)=1/2\)</span>. The variance of the hypothetical means across policyholders is <span class="math inline">\(VHM = \mathrm{Var}(\lambda)\)</span> = <span class="math inline">\(\mathrm{E}(\lambda^2\)</span>)-<span class="math inline">\((\mathrm{E}(\lambda))^2=\int_{0}^{1} \lambda^2[6\lambda(1-\lambda)] d\lambda-(1/2)^2=(3/10)-(1/4)=(6/20)-(5/20)=1/20\)</span>. So, <span class="math inline">\(K=EPV/VHM\)</span>=(1/2)/(1/20)=10. The number of exposures in the experience period is <span class="math inline">\(m=9+12+15=36\)</span>. The credibility is <span class="math inline">\(Z=36/(36+10)=18/23\)</span>. The credibility-weighted estimate for the number of claims for one vehicle is <span class="math inline">\(\hat{\mu}(\theta)=Z\bar{X}+(1-Z)\mu\)</span>=(18/23)(13/36)+(5/23)(1/2)=9/23. With 18 vehicles in the fleet in year 4 the expected number of claims is 18(9/23)=162/23=7.04 .</p>
</div>
<hr />
</div>
<div id="S:Cred:BayesInf" class="section level2 hasAnchor" number="9.5">
<h2><span class="header-section-number">9.5</span> Bayesian Inference and Bhlmann Credibility<a href="ChapCredibility.html#S:Cred:BayesInf" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<hr />
<p>In this section, you learn how to:</p>
<ul>
<li>Use Bayes Theorem to determine a formula for the expected loss of a risk given a likelihood and prior distribution.</li>
<li>Determine the posterior distributions for the gamma-Poisson and beta-binomial Bayesian models and compute expected values.</li>
<li>Understand the connection between the Bhlmann and Bayesian estimates for the gamma-Poisson and beta-binomial models.</li>
</ul>
<hr />
<p>Section <a href="ChapModelSelection.html#S:MS:BayesInference">4.4</a> reviews <a href="#" class="tooltip" style="color:green"><em>Bayesian inference</em><span style="font-size:8pt">A branch of statistics that leverages bayes theorem to update the distribution as more experience becomes available</span></a> and it is assumed that the reader is familiar with that material. The reader is also advised to read the Bhlmann credibility Section <a href="ChapCredibility.html#S:Cred:Buhlmann">9.3</a> in this chapter. This section will compare Bayesian inference with Bhlmann credibility and show connections between the two models.</p>
<p>A risk with risk parameter <span class="math inline">\(\theta\)</span> has expected loss <span class="math inline">\(\mu(\theta)=\mathrm{E}(X|\theta)\)</span> with random variable <span class="math inline">\(X\)</span> representing pure premium, aggregate loss, number of claims, claim severity, or some other measure of loss during a period of time. If the risk has <span class="math inline">\(n\)</span> losses <span class="math inline">\(X_1,\ldots, X_n\)</span> during n separate periods of time, then these losses are assumed to be <span class="math inline">\(iid\)</span> for the policyholder and <span class="math inline">\(\mu(\theta)=\mathrm{E}(X_i|\theta)\)</span> for <span class="math inline">\(i=1,..,n\)</span>.</p>
<p>If the risk had <span class="math inline">\(n\)</span> losses <span class="math inline">\(x_1,\ldots, x_n\)</span> then <span class="math inline">\(\mathrm{E}(\mu(\theta)|x_1,\ldots, x_n)\)</span> is the conditional expectation of <span class="math inline">\(\mu(\theta)\)</span>. The Bhlmann credibility formula <span class="math inline">\(\hat{\mu}(\theta)=Z\bar{X}+(1-Z)\mu\)</span> is a linear function of <span class="math inline">\(\bar{X}=(x_1+\cdots+x_n)/n\)</span> used to estimate <span class="math inline">\(\mathrm{E}(\mu(\theta)|x_1,\ldots,x_n)\)</span>.</p>
<p>The expectation <span class="math inline">\(\mathrm{E}(\mu(\theta)|x_1,\ldots,x_n)\)</span> can be calculated from the conditional density function <span class="math inline">\(f(x|\theta)\)</span> and the posterior distribution <span class="math inline">\(\pi(\theta|x_1,\ldots,x_n)\)</span>:</p>
<p><span class="math display">\[\begin{eqnarray*}  
\mathrm{E}(\mu(\theta)|x_1,\ldots,x_n)&amp;=&amp;\int \mu(\theta) \pi(\theta|x_1,\ldots,x_n) d\theta \\
                           \mu(\theta)&amp;=&amp;\mathrm{E}(X|\theta)=\int  xf(x|\theta) dx .\\
\end{eqnarray*}\]</span></p>
<p>The posterior distribution comes from <a href="#" class="tooltip" style="color:green"><em>Bayes theorem</em><span style="font-size:8pt">A probability law that expresses conditional probability of the event a given the event b in terms of the conditional probability of the event b given the event a and the unconditional probability of a</span></a></p>
<p><span class="math display">\[\begin{equation*}
\pi(\theta|x_1,\ldots,x_n)=\frac{\prod_{j=1}^{n} f(x_j|\theta)}{f(x_1,\ldots,x_n)}\pi({\theta}).
\end{equation*}\]</span></p>
<p>The conditional density function <span class="math inline">\(f(x|\theta)\)</span> and the prior distribution <span class="math inline">\(\pi(\theta)\)</span> must be specified. The numerator <span class="math inline">\(\prod_{j=1}^{n} f(x_j|\theta)\)</span> on the right-hand side is called the likelihood. The denominator <span class="math inline">\(f(x_1,\ldots,x_n)\)</span> is the joint density function for <span class="math inline">\(n\)</span> losses <span class="math inline">\(x_1,\ldots,x_n\)</span>.</p>
<div id="Sec:Cred:gammaPoisson" class="section level3 hasAnchor" number="9.5.1">
<h3><span class="header-section-number">9.5.1</span> Gamma-Poisson Model<a href="ChapCredibility.html#Sec:Cred:gammaPoisson" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the <a href="#" class="tooltip" style="color:green"><em>Gamma-Poisson model</em><span style="font-size:8pt">A statistical model that assumes the frequency of claims is poisson whose mean has a prior distribution that is a gamma distribution</span></a> the number of claims <span class="math inline">\(X\)</span> has a Poisson distribution <span class="math inline">\(\Pr(X=x|\lambda)=\lambda^xe^{-\lambda}/x!\)</span> for a risk with risk parameter <span class="math inline">\(\lambda\)</span>. The prior distribution for <span class="math inline">\(\lambda\)</span> is gamma with <span class="math inline">\(\pi(\lambda)=\beta^\alpha\lambda^{\alpha-1}e^{-\beta\lambda}/\Gamma(\alpha)\)</span>. (Note that a rate parameter <span class="math inline">\(\beta\)</span> is being used in the gamma distribution rather than a scale parameter.) The mean of the gamma is <span class="math inline">\(\mathrm{E}(\lambda)=\alpha/\beta\)</span> and the variance is <span class="math inline">\(\mathrm{Var}(\lambda)=\alpha/\beta^2\)</span>. In this section we will assume that <span class="math inline">\(\lambda\)</span> is the expected number of claims per year though we could have chosen another time interval.</p>
<p>If a risk is selected at random from the population then the expected number of claims in a year is <span class="math inline">\(\mathrm{E}(N)=\mathrm{E}(\mathrm{E}[N|\lambda])\)</span> = <span class="math inline">\(\mathrm{E}(\lambda)=\alpha/\beta\)</span>. If we had no observations for the selected risk then the expected number of claims for the risk is <span class="math inline">\(\alpha/\beta\)</span>.</p>
<p>During <span class="math inline">\(n\)</span> years the following number of claims by year was observed for the randomly selected risk: <span class="math inline">\(x_1,\ldots,x_n\)</span>. From Bayes theorem the posterior distribution is</p>
<p><span class="math display">\[
\pi(\lambda|x_1,\ldots,x_n)=\frac{\prod_{j=1}^{n} (\lambda^{x_j}e^{-\lambda}/x_j!)}{\Pr(X_1=x_1,\ldots,X_n=x_n)}\beta^\alpha\lambda^{\alpha-1}e^{-\beta\lambda}/\Gamma(\alpha).
\]</span></p>
<p>Combining terms that have a <span class="math inline">\(\lambda\)</span> and putting all other terms into constant <span class="math inline">\(C\)</span> gives</p>
<p><span class="math display">\[\begin{equation*}
\pi(\lambda|x_1,\ldots,x_n)=C\lambda^{(\alpha+\sum_{j=1}^{n}x_j)-1}e^{-(\beta+n)\lambda}.
\end{equation*}\]</span></p>
<p>This is a gamma distribution with parameters <span class="math inline">\(\alpha&#39;=\alpha+\sum_{j=1}^{n}x_j\)</span> and <span class="math inline">\(\beta&#39;=\beta+n\)</span>. The constant must be <span class="math inline">\(C={\beta&#39;}^{\alpha&#39;}/\Gamma(\alpha&#39;)\)</span> so that <span class="math inline">\(\int_{0}^{\infty}\pi(\lambda|x_1,\ldots,x_n) d\lambda=1\)</span> though we do not need to know <span class="math inline">\(C\)</span>. As explained in Chapter <a href="ChapModelSelection.html#ChapModelSelection">4</a> the gamma distribution is a conjugate prior for the Poisson distribution so the posterior distribution is also gamma. See also Appendix Section <a href="CAppB.html#S:IterExp:Conjugate">16.3.2</a>.</p>
<p>Because the posterior distribution is gamma the expected number of claims for the selected risk is</p>
<p><span class="math display">\[\begin{equation*}  
\mathrm{E}(\lambda|x_1,\ldots,x_n) = \frac{\alpha+\sum_{j=1}^{n}x_j}{\beta+n}=\frac{\alpha + \textrm{number of claims}}{\beta+\textrm{number of years}}.
\end{equation*}\]</span></p>
<p>This formula is slightly different from Chapter <a href="ChapModelSelection.html#ChapModelSelection">4</a> because parameter <span class="math inline">\(\beta\)</span> is multiplied by <span class="math inline">\(\lambda\)</span> in the exponential of the gamma <em>pdf</em> whereas in Chapter <a href="ChapModelSelection.html#ChapModelSelection">4</a> <span class="math inline">\(\lambda\)</span> is divided by parameter <span class="math inline">\(\theta\)</span>. We have chosen this form for the exponential to simplify the equation for the expected number of claims.</p>
<p>Now we will compute the Bhlmann credibility estimate for the gamma-Poisson model. The variance for a Poisson distribution with parameter <span class="math inline">\(\lambda\)</span> is <span class="math inline">\(\lambda\)</span> so <span class="math inline">\(EPV=\mathrm{E}(\mathrm{Var}(X|\lambda))=\mathrm{E}(\lambda)=\alpha/\beta\)</span>. The mean number of claims per year for the risk is <span class="math inline">\(\lambda\)</span> so <span class="math inline">\(VHM=\mathrm{Var}(\mathrm{E}(X|\lambda))\)</span> = <span class="math inline">\(\mathrm{Var}(\lambda)=\alpha/\beta^2\)</span>. The credibility parameter is <span class="math inline">\(K=EPV/VHM\)</span> = <span class="math inline">\((\alpha/\beta)/(\alpha/\beta^2)=\beta\)</span>. The overall mean is <span class="math inline">\(\mathrm{E}(\mathrm{E}(X|\lambda))=\mathrm{E}(\lambda)=\alpha/\beta\)</span>. The sample mean is <span class="math inline">\(\bar{X}=(\sum_{j=1}^{n}x_j)/n\)</span>. The credibility-weighted estimate for the expected number of claims for the risk is</p>
<p><span class="math display">\[
\hat{\mu}=\frac{n}{n+\beta}\frac{\sum_{j=1}^{n}x_j}{n} +\left(1-\frac{n}{n+\beta}\right)\frac{\alpha}{\beta}=\frac{\alpha+\sum_{j=1}^{n}x_j}{\beta+n}.
\]</span></p>
<p>For the gamma-Poisson model the Bhlmann credibility estimate matches the Bayesian analysis result.</p>
</div>
<div id="beta-binomial-model" class="section level3 hasAnchor" number="9.5.2">
<h3><span class="header-section-number">9.5.2</span> Beta-Binomial Model<a href="ChapCredibility.html#beta-binomial-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <a href="#" class="tooltip" style="color:green"><em>Beta-Binomial model</em><span style="font-size:8pt">A statistical model for modeling the probability of an event using the binomial distribution with a probability that has a prior distribution from a beta distribution</span></a> is useful for modeling the probability of an event. Assume that random variable <span class="math inline">\(X\)</span> is the number of successes in <span class="math inline">\(n\)</span> trials and that <span class="math inline">\(X\)</span> has a binomial distribution <span class="math inline">\(\Pr(X=x|p)=\binom{n}{x}p^x(1-p)^{n-x}\)</span>. In the beta-binomial model the prior distribution for probability <span class="math inline">\(p\)</span> is a beta distribution with <em>pdf</em></p>
<p><span class="math display">\[\begin{equation*}  
\pi(p)=\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}p^{\alpha-1}(1-p)^{\beta-1} , \quad  0&lt;p&lt;1, \alpha&gt;0, \beta&gt;0.
\end{equation*}\]</span></p>
<p>The posterior distribution for <span class="math inline">\(p\)</span> given an outcome of <span class="math inline">\(x\)</span> successes in <span class="math inline">\(n\)</span> trials is</p>
<p><span class="math display">\[\begin{equation*}
\pi(p|x)=\frac{\binom{n}{x}p^x(1-p)^{n-x}}{\Pr(x)}\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}p^{\alpha-1}(1-p)^{\beta-1}.
\end{equation*}\]</span></p>
<p>Combining terms that have a <span class="math inline">\(p\)</span> and putting everything else into the constant <span class="math inline">\(C\)</span> yields</p>
<p><span class="math display">\[\begin{equation*}
\pi(p| x)=Cp^{\alpha+x-1}(1-p)^{\beta+(n-x)-1}.
\end{equation*}\]</span></p>
<p>This is a beta distribution with new parameters <span class="math inline">\(\alpha^\prime=\alpha+x\)</span> and <span class="math inline">\(\beta^\prime=\beta+(n-x)\)</span>. The constant must be</p>
<p><span class="math display">\[\begin{equation*}
C=\frac{\Gamma(\alpha+\beta+n)}{\Gamma(\alpha+x)\Gamma(\beta+n-x)}.
\end{equation*}\]</span></p>
<p>The mean for the beta distribution with parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> is <span class="math inline">\(\mathrm{E}(p)=\alpha/(\alpha+\beta)\)</span>. Given <span class="math inline">\(x\)</span> successes in <span class="math inline">\(n\)</span> trials in the beta-binomial model the mean of the posterior distribution is</p>
<p><span class="math display">\[\begin{equation*}
\mathrm{E}(p|x)=\frac{\alpha+x}{\alpha+\beta+n}.  
\end{equation*}\]</span></p>
<p>As the number of trials <span class="math inline">\(n\)</span> and successes <span class="math inline">\(x\)</span> increase, the expected value of <span class="math inline">\(p\)</span> approaches <span class="math inline">\(x/n\)</span>.</p>
<p>The Bhlmann credibility estimate for <span class="math inline">\(\mathrm{E}(p|x)\)</span> is exactly as the same as the Bayesian estimate as demonstrated in the following example.</p>
<p><strong>Example 9.5.1</strong>
The probability that a coin toss will yield heads is <span class="math inline">\(p\)</span>. The prior distribution for probability <span class="math inline">\(p\)</span> is beta with parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. On <span class="math inline">\(n\)</span> tosses of the coin there were exactly <span class="math inline">\(x\)</span> heads. Use Bhlmann credibility to estimate the expected value of <span class="math inline">\(p\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayExample.9.5.1" href="javascript:toggleEX('toggleExample.9.5.1','displayExample.9.5.1');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.9.5.1" style="display: none">
<p><strong>Solution</strong> Define random variables <span class="math inline">\(Y_j\)</span> such that <span class="math inline">\(Y_j=1\)</span> if the <span class="math inline">\(j^{th}\)</span> coin toss is heads and <span class="math inline">\(Y_j=0\)</span> if tails for <span class="math inline">\(j=1,\ldots, n\)</span>. Random variables <span class="math inline">\(Y_j\)</span> are <em>iid</em> conditional on <span class="math inline">\(p\)</span> with Pr<span class="math inline">\([Y=1|p]=p\)</span> and Pr<span class="math inline">\([Y=0|p]=1-p\)</span> The number of heads in <span class="math inline">\(n\)</span> tosses can be represented by the random variable <span class="math inline">\(X=Y_1+\cdots+Y_n\)</span>. We want to estimate <span class="math inline">\(p=E[Y_j]\)</span> using Bhlmann credibility: <span class="math inline">\(\hat{p} = Z\bar{Y} +(1-Z)\mu\)</span>. The overall mean is <span class="math inline">\(\mu=\mathrm{E}(\mathrm{E}(Y_j|p))\)</span> = <span class="math inline">\(\mathrm{E}(p)=\alpha/(\alpha+\beta)\)</span>. The sample mean is <span class="math inline">\(\bar{y}=x/n\)</span>. The credibility is <span class="math inline">\(Z=n/(n+K)\)</span> and <span class="math inline">\(K=EPV/VHM\)</span>. With <span class="math inline">\(\mathrm{Var}(Y_j|p)=p(1-p)\)</span> it follows that <span class="math inline">\(EPV = \mathrm{E}(\mathrm{Var}[Y_j|p])\)</span> = <span class="math inline">\(\mathrm{E}(p(1-p)\)</span>). Because <span class="math inline">\(\mathrm{E}(Y_j|p)=p\)</span> then <span class="math inline">\(VHM=\mathrm{Var}((\mathrm{E}(Y_j|p))=\mathrm{Var}(p)\)</span>. For the beta distribution</p>
<p><span class="math display">\[
\mathrm{E}(p)=\frac{\alpha}{\alpha+\beta}, \mathrm{E}(p^2)=\frac{\alpha(\alpha+1)}{(\alpha+\beta)(\alpha+\beta+1)}, \textrm{ and } \mathrm{Var}(p)=\frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}.
\]</span></p>
<p>Parameter <span class="math inline">\(K=EPV/VHM\)</span>=<span class="math inline">\([\mathrm{E}(p)-\mathrm{E}(p^2)]/\mathrm{Var}(p)\)</span>. With some algebra this reduces to <span class="math inline">\(K=\alpha+\beta\)</span>. The Bhlmann credibility-weighted estimate is</p>
<p><span class="math display">\[\begin{align*}
  \hat{p} &amp;= \frac{n}{n+\alpha+\beta}\left(\frac{x}{n}\right)+\left(1-\frac{n}{n+\alpha+\beta}\right)\frac{\alpha}{\alpha+\beta} \\
  \hat{p} &amp; =\frac{\alpha+x}{\alpha+\beta+n}\\
\end{align*}\]</span>
which is the same as the Bayesian posterior mean.</p>
</div>
<hr />
</div>
<div id="exact-credibility" class="section level3 hasAnchor" number="9.5.3">
<h3><span class="header-section-number">9.5.3</span> Exact Credibility<a href="ChapCredibility.html#exact-credibility" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As demonstrated in the prior section, the Bhlmann credibility estimates for the gamma-Poisson and beta-binomial models exactly match the Bayesian analysis results. The term <a href="#" class="tooltip" style="color:green"><em>exact credibility</em><span style="font-size:8pt">A situation where the bayesian credibility estimate matches that of the buhlmann credibility estimate</span></a> is applied in these situations. Exact credibility may occur if the probability distribution for <span class="math inline">\(X_j\)</span> is in the linear exponential family and the prior distribution is a conjugate prior. Besides these two models, examples of exact credibility also include Gamma-Exponential and Normal-Normal models.</p>
<p>It is also noteworthy that if the conditional mean <span class="math inline">\(\mathrm{E}(\mu(\theta)|X_1,...,X_n)\)</span> is linear in the past observations, then the Bhlmann credibility estimate will coincide with the Bayesian estimate. More information about exact credibility can be found in <span class="citation">(<a href="#ref-BuhlmannGisler2005" role="doc-biblioref">Bhlmann and Gisler 2005</a>)</span>, <span class="citation">(<a href="#ref-klugman2012" role="doc-biblioref">Klugman, Panjer, and Willmot 2012</a>)</span>, and <span class="citation">(<a href="#ref-Tse2009" role="doc-biblioref">Tse 2009</a>)</span>.</p>
</div>
</div>
<div id="estimating-credibility-parameters" class="section level2 hasAnchor" number="9.6">
<h2><span class="header-section-number">9.6</span> Estimating Credibility Parameters<a href="ChapCredibility.html#estimating-credibility-parameters" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<hr />
<p>In this section, you learn how to:</p>
<ul>
<li>Perform nonparametric estimation with the Bhlmann and Bhlmann-Straub credibility models.</li>
<li>Identify situations when semiparametric estimation is appropriate.</li>
<li>Use data to approximate the <span class="math inline">\(EPV\)</span> and <span class="math inline">\(VHM\)</span>.</li>
<li>Balance credibility-weighted estimates.</li>
</ul>
<hr />
<p>The examples in this chapter have provided assumptions for calculating credibility parameters. In actual practice the actuary must use real world data and judgment to determine credibility parameters.</p>
<div id="full-credibility-standard-for-limited-fluctuation-credibility" class="section level3 hasAnchor" number="9.6.1">
<h3><span class="header-section-number">9.6.1</span> Full Credibility Standard for Limited Fluctuation Credibility<a href="ChapCredibility.html#full-credibility-standard-for-limited-fluctuation-credibility" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Limited-fluctuation credibility requires a full credibility standard. The general formula for aggregate losses or pure premium, as obtained in formula <a href="ChapCredibility.html#eq:full-credibility-losses">(9.5)</a>, is</p>
<p><span class="math display">\[
n_S=\left(\frac{y_p}{k}\right)^2\left[\left(\frac{\sigma_N^2}{\mu_N}\right)+\left(\frac{\sigma_X}{\mu_X}\right)^2\right] ,
\]</span></p>
<p>with <span class="math inline">\(N\)</span> representing number of claims and <span class="math inline">\(X\)</span> the size of claims. If one assumes <span class="math inline">\(\sigma_X=0\)</span> then the full credibility standard for frequency results. If <span class="math inline">\(\sigma_N=0\)</span> then the full credibility formula for severity follows. Probability <span class="math inline">\(p\)</span> and <span class="math inline">\(k\)</span> value are often selected using judgment and experience.</p>
<p>In practice it is often assumed that the number of claims is Poisson distributed so that <span class="math inline">\(\sigma_N^2/\mu_N=1\)</span>. In this case the formula can be simplified to</p>
<p><span class="math display">\[\begin{equation*}
n_S=\left(\frac{y_p}{k}\right)^2\left[\frac{\mathrm{E}(X^2)}{(\mathrm{E}(X))^2}\right].
\end{equation*}\]</span></p>
<p>An empirical mean and second moment for the sizes of individual claim losses can be computed from past data, if available.</p>
</div>
<div id="nonparametric-estimation-for-bhlmann-and-bhlmann-straub-models" class="section level3 hasAnchor" number="9.6.2">
<h3><span class="header-section-number">9.6.2</span> Nonparametric Estimation for Bhlmann and Bhlmann-Straub Models<a href="ChapCredibility.html#nonparametric-estimation-for-bhlmann-and-bhlmann-straub-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Bayesian analysis as described previously requires assumptions about a prior distribution and likelihood. It is possible to produce estimates without these assumptions and these methods are often referred to as <a href="#" class="tooltip" style="color:green"><em>empirical Bayes methods</em><span style="font-size:8pt">Credibility methods that estimate the credibility weight without using any assumptions about prior distributions or likelihoods, instead relying only on empirical data</span></a>. Bhlmann and Bhlmann-Straub credibility with parameters estimated from the data are included in the category of empirical Bayes methods.</p>
<p><strong>Bhlmann Model</strong> First we will address the simpler Bhlmann model. Assume that there are <span class="math inline">\(r\)</span> risks in a population. For risk <span class="math inline">\(i\)</span> with risk parameter <span class="math inline">\(\theta_i\)</span> the losses for <span class="math inline">\(n\)</span> periods are <span class="math inline">\(X_{i1},\ldots, X_{in}\)</span>. The losses for a given risk are <em>iid</em> across periods as assumed in the Bhlmann model. For risk <span class="math inline">\(i\)</span> the sample mean is <span class="math inline">\(\bar{X}_i=\sum_{j=1}^{n}X_{ij}/n\)</span> and the unbiased sample process variance is <span class="math inline">\(s_i^2=\sum_{j=1}^{n}(X_{ij}-\bar{X}_i)^2/(n-1)\)</span>. An unbiased estimator for the <span class="math inline">\(EPV\)</span> can be calculated by taking the average of <span class="math inline">\(s_i^2\)</span> for the <span class="math inline">\(r\)</span> risks in the population:</p>
<p><span class="math display" id="eq:EPV-estimate">\[\begin{equation}  
\widehat{EPV}=\frac{1}{r}\sum_{i=1}^{r} s_i^2 = \frac{1}{r(n-1)} \sum_{i=1}^{r} \sum_{j=1}^{n}(X_{ij}-\bar{X}_i)^2 .
\tag{9.11}
\end{equation}\]</span></p>
<p>The individual risk means <span class="math inline">\(\bar{X}_i\)</span> for <span class="math inline">\(i=1,\ldots, r\)</span> can be used to estimate the <span class="math inline">\(VHM\)</span>. An unbiased estimator of Var(<span class="math inline">\(\bar{X}_i\)</span>) is</p>
<p><span class="math display">\[\begin{equation*}
\widehat{\mathrm{Var}}(\bar{X}_i)=\frac{1}{r-1} \sum_{i=1}^{r}(\bar{X}_i-\bar{X})^2 \textrm{  and  }  \bar{X}=\frac{1}{r}\sum_{i=1}^{r} \bar{X}_i,
\end{equation*}\]</span></p>
<p>but Var(<span class="math inline">\(\bar{X}_i\)</span>) is not the <span class="math inline">\(VHM\)</span>. Using equation <a href="CAppB.html#eq:LawTotVar">(16.2)</a>, the total variance formula or <em>unconditional variance</em> formula is</p>
<p><span class="math display">\[
\mathrm{Var}(\bar{X}_i)=\textrm{E(Var}(\bar{X}_i|\Theta=\theta_i))+\textrm{Var(E}(\bar{X}_i|\Theta=\theta_i)).
\]</span></p>
<p>The <span class="math inline">\(VHM\)</span> is the second term on the right because <span class="math inline">\(\mu(\theta_i)=\mathrm{E}(\bar{X}_i|\Theta=\theta_i)\)</span> is the hypothetical mean for risk <span class="math inline">\(i\)</span>. So,</p>
<p><span class="math display">\[\begin{equation*}
VHM=\textrm{Var(E}(\mu(\theta_i)) = \mathrm{Var}(\bar{X}_i) - \textrm{E(Var}(\bar{X}_i|\Theta=\theta_i)).
\end{equation*}\]</span></p>
<p>As discussed previously in Section <a href="ChapCredibility.html#S:EPV-VHM-Z">9.3.1</a>, <span class="math inline">\(EPV/n\)</span> = <span class="math inline">\(\mathrm{E}(\mathrm{Var}[\bar{X}_i|\Theta=\theta_i])\)</span> and using the above estimators gives an unbiased estimator for the <span class="math inline">\(VHM\)</span>:</p>
<p><span class="math display" id="eq:VHM-estimate">\[\begin{equation}
\widehat{VHM} = \frac{1}{r-1} \sum_{i=1}^{r}(\bar{X}_i-\bar{X})^2 - \frac{\widehat{EPV}}{n} .
\tag{9.12}
\end{equation}\]</span></p>
<p>Although the expected loss for a risk with parameter <span class="math inline">\(\theta_i\)</span> is <span class="math inline">\(\mu(\theta_i)\)</span>=<span class="math inline">\(\mathrm{E}(\bar{X}_i|\Theta=\theta_i\)</span>), the variance of the sample mean <span class="math inline">\(\bar{X}_i\)</span> is greater than or equal to the variance of the hypothetical means: <span class="math inline">\(\mathrm{Var}(\bar{X}_i)\geq\)</span>Var(<span class="math inline">\(\mu(\theta_i)\)</span>). The variance in the sample means <span class="math inline">\(\mathrm{Var}(\bar{X}_i\)</span>) includes both the variance in the hypothetical means plus a process variance term.</p>
<p>In some cases formula <a href="ChapCredibility.html#eq:VHM-estimate">(9.12)</a> can produce a negative value for <span class="math inline">\(\widehat{VHM}\)</span> because of the subtraction of <span class="math inline">\(\widehat{EPV}/n\)</span>, but a variance cannot be negative. The process variance within risks is so large that it overwhelms the measurement of the variance in means between risks. In this case we cannot use this method to determine the values needed for Bhlmann credibility.</p>
<p><strong>Example 9.6.1.</strong>
Two policyholders had claims over a three-year period as shown in the table below. Estimate the expected number of claims for each policyholder using Bhlmann credibility and calculating necessary parameters from the data.</p>
<p><span class="math display">\[
\small{
\begin{array}{|c|c|c|}
\hline
\text{Year} &amp; \text{Risk A} &amp; \text{Risk B} \\
\hline
1 &amp; 0 &amp;  2 \\
2 &amp; 1 &amp;  1  \\  
3 &amp; 0 &amp;  2  \\              
\hline
\end{array}
}
\]</span></p>
<h5 style="text-align: center;">
<a id="displayExample.9.6.1" href="javascript:toggleEX('toggleExample.9.6.1','displayExample.9.6.1');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.9.6.1" style="display: none">
<p><strong>Solution</strong> <span class="math inline">\(\bar{x}_A=\frac{1}{3}(0+1+0)=\frac{1}{3}\)</span>, <span class="math inline">\(\bar{x}_B=\frac{1}{3}(2+1+2)=\frac{5}{3}\)</span></p>
<p><span class="math inline">\(\bar{x}=\frac{1}{2}(\frac{1}{3}+\frac{5}{3})=1\)</span></p>
<p><span class="math inline">\(s_A^2=\frac{1}{3-1}\left[(0-\frac{1}{3})^2+(1-\frac{1}{3})^2+(0-\frac{1}{3})^2\right]=\frac{1}{3}\)</span></p>
<p><span class="math inline">\(s_B^2=\frac{1}{3-1}\left[(2-\frac{5}{3})^2+(1-\frac{5}{3})^2+(2-\frac{5}{3})^2\right]=\frac{1}{3}\)</span></p>
<p><span class="math inline">\(\widehat{EPV}=\frac{1}{2}\left(\frac{1}{3}+\frac{1}{3}\right)=\frac{1}{3}\)</span></p>
<p><span class="math inline">\(\widehat{VHM}=\frac{1}{2-1}\left[(\frac{1}{3}-1)^2+(\frac{5}{3}-1)^2\right]-\frac{1/3}{3}=\frac{7}{9}\)</span></p>
<p><span class="math inline">\(K=\frac{1/3}{7/9}=\frac{3}{7}\)</span></p>
<p><span class="math inline">\(Z=\frac{3}{3+(3/7))}=\frac{7}{8}\)</span></p>
<p><span class="math inline">\(\hat{\mu}_A=\frac{7}{8}\left(\frac{1}{3}\right)+(1-\frac{7}{8})1=\frac{5}{12}\)</span></p>
<p><span class="math inline">\(\hat{\mu}_B=\frac{7}{8}\left(\frac{5}{3}\right)+(1-\frac{7}{8})1=\frac{19}{12}\)</span></p>
</div>
<hr />
<p><strong>Example 9.6.2.</strong>
Two policyholders had claims over a three-year period as shown in the table below. Calculate the nonparametric estimate for the <span class="math inline">\(VHM\)</span>.</p>
<p><span class="math display">\[
\small{
\begin{array}{|c|c|c|}
\hline
\text{Year} &amp; \text{Risk A} &amp; \text{Risk B} \\
\hline
1 &amp; 3 &amp;  3 \\
2 &amp; 0 &amp;  0  \\  
3 &amp; 0 &amp;  3  \\              
\hline
\end{array}
}
\]</span></p>
<h5 style="text-align: center;">
<a id="displayExample.9.6.2" href="javascript:toggleEX('toggleExample.9.6.2','displayExample.9.6.2');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.9.6.2" style="display: none">
<p><strong>Solution</strong> <span class="math inline">\(\bar{x}_A=\frac{1}{3}(3+0+0)=1\)</span>, <span class="math inline">\(\bar{x}_B=\frac{1}{3}(3+0+3)=2\)</span></p>
<p><span class="math inline">\(\bar{x}=\frac{1}{2}(1+2)=\frac{3}{2}\)</span></p>
<p><span class="math inline">\(s_A^2=\frac{1}{3-1}\left[(3-1)^2+(0-1)^2+(0-1)^2\right]=3\)</span></p>
<p><span class="math inline">\(s_B^2=\frac{1}{3-1}\left[(3-2)^2+(0-2)^2+(3-2)^2\right]=3\)</span></p>
<p><span class="math inline">\(\widehat{EPV}=\frac{1}{2}(3+3)=3\)</span></p>
<p><span class="math inline">\(\widehat{VHM}=\frac{1}{2-1}\left[(1-\frac{3}{2})^2+(2-\frac{3}{2})^2\right]-\frac{3}{3}=-\frac{1}{2}.\)</span></p>
<p>The process variance is so large that it is not possible to estimate the <span class="math inline">\(VHM\)</span>.</p>
</div>
<hr />
<p><strong>Bhlmann-Straub Model</strong> Empirical formulas for <span class="math inline">\(EPV\)</span> and <span class="math inline">\(VHM\)</span> in the Bhlmann-Straub model are more complicated because a risks number of exposures can change from one period to another. Also, the number of experience periods does not have to be constant across the population. First some definitions:</p>
<ul>
<li><span class="math inline">\(X_{ij}\)</span> is the losses per exposure for risk <span class="math inline">\(i\)</span> in period <span class="math inline">\(j\)</span>. Losses can refer to number of claims or amount of loss. There are <span class="math inline">\(r\)</span> risks so <span class="math inline">\(i=1,\ldots,r\)</span>.</li>
<li><span class="math inline">\(n_i\)</span> is the number of observation periods for risk <span class="math inline">\(i\)</span></li>
<li><span class="math inline">\(m_{ij}\)</span> is the number of exposures for risk <span class="math inline">\(i\)</span> in period <span class="math inline">\(j\)</span> for <span class="math inline">\(j=1,\ldots,n_i\)</span></li>
</ul>
<p>Risk <span class="math inline">\(i\)</span> with risk parameter <span class="math inline">\(\theta_i\)</span> has <span class="math inline">\(m_{ij}\)</span> exposures in period <span class="math inline">\(j\)</span> which means that the losses per exposure random variable can be written as <span class="math inline">\(X_{ij}=(Y_{i1}+\cdots+Y_{im_{ij}})/m_{ij}\)</span>. Random variable <span class="math inline">\(Y_{ik}\)</span> is the loss for one exposure. For risk <span class="math inline">\(i\)</span> losses <span class="math inline">\(Y_{ik}\)</span> are <em>iid</em> with mean <span class="math inline">\(\mathrm{E}(Y_{ik})=\mu(\theta_i)\)</span> and process variance <span class="math inline">\(\mathrm{Var}(Y_{ik}\)</span>) = <span class="math inline">\(\sigma^2(\theta_i)\)</span>. It follows that <span class="math inline">\(\mathrm{Var}(X_{ij})\)</span> = <span class="math inline">\(\sigma^2(\theta_i)/m_{ij}\)</span>.</p>
<p>Two more important definitions are:</p>
<ul>
<li><span class="math inline">\(\bar{X}_i=\frac{1}{m_i}\sum_{j=1}^{n_i} m_{ij}X_{ij}\)</span> with <span class="math inline">\(m_i = \sum_{j=1}^{n_i} m_{ij}\)</span>. <span class="math inline">\(\bar{X}_i\)</span> is the average loss per exposure for risk <span class="math inline">\(i\)</span> for all observation periods combined.</li>
<li><span class="math inline">\(\bar{X}=\frac{1}{m}\sum_{i=1}^{r} m_i \bar{X}_i\)</span> with <span class="math inline">\(m=\sum_{i=1}^r m_i\)</span>. <span class="math inline">\(\bar{X}\)</span> is the average loss per exposure for all risks for all observation periods combined.</li>
</ul>
<p>An unbiased estimator for the process variance <span class="math inline">\(\sigma^2(\theta_i)\)</span> of one exposure for risk <span class="math inline">\(i\)</span> is</p>
<p><span class="math display">\[\begin{equation*}  
{s_i}^2=\frac{\sum_{j=1}^{n_i} m_{ij}(X_{ij}-\bar{X}_i)^2}{n_i-1}. \end{equation*}\]</span></p>
<p>The weights <span class="math inline">\(m_{ij}\)</span> are applied to the squared differences because the <span class="math inline">\(X_{ij}\)</span> are the averages of <span class="math inline">\(m_{ij}\)</span> exposures. The weighted average of the sample variances <span class="math inline">\({s_i}^2\)</span> for each risk <span class="math inline">\(i\)</span> in the population with weights proportional to the number of <span class="math inline">\((n_i-1)\)</span> observation periods will produce the expected value of the process variance (<span class="math inline">\(EPV\)</span>) estimate</p>
<p><span class="math display">\[\begin{equation*}  
\widehat{EPV}=\frac{\sum_{i=1}^r  (n_i-1){s_i}^2}{\sum_{i=1}^r (n_i-1)}=\frac{\sum_{i=1}^r \sum_{j=1}^{n_i} m_{ij}(X_{ij}-\bar{X}_i)^2}{\sum_{i=1}^r (n_i-1)}.     
\end{equation*}\]</span></p>
<p>The quantity <span class="math inline">\(\widehat{EPV}\)</span> is an unbiased estimator for the expected value of the process variance of one exposure for a risk chosen at random from the population.</p>
<p>To calculate an estimator for the variance in the hypothetical means (<span class="math inline">\(VHM\)</span>) the squared differences of the individual risk sample means <span class="math inline">\(\bar{X}_i\)</span> and population mean <span class="math inline">\(\bar{X}\)</span> are used. An unbiased estimator for the <span class="math inline">\(VHM\)</span> is</p>
<p><span class="math display">\[\begin{equation*}  
\widehat{VHM}=\frac{\sum_{i=1}^r m_i(\bar{X}_i-\bar{X})^2 - (r-1)\widehat{EPV}}{m-\frac{1}{m}\sum_{i=1}^r m_i^2}.  
\end{equation*}\]</span></p>
<p>This complicated formula is necessary because of the varying number of exposures. Proofs that the <span class="math inline">\(EPV\)</span> and <span class="math inline">\(VHM\)</span> estimators shown above are unbiased can be found in several references mentioned at the end of this chapter including <span class="citation">(<a href="#ref-BuhlmannGisler2005" role="doc-biblioref">Bhlmann and Gisler 2005</a>)</span>, <span class="citation">(<a href="#ref-klugman2012" role="doc-biblioref">Klugman, Panjer, and Willmot 2012</a>)</span>, and <span class="citation">(<a href="#ref-Tse2009" role="doc-biblioref">Tse 2009</a>)</span>.</p>
<p><strong>Example 9.6.3.</strong>
Two policyholders had claims shown in the table below. Estimate the expected number of claims per vehicle for each policyholder using Bhlmann-Straub credibility and calculating parameters from the data.</p>
<p><span class="math display">\[
\small{
\begin{array}{|c|c|c|c|c|c|}
\hline
\text{Policyholder} &amp;  &amp; \text{Year 1} &amp; \text{Year 2} &amp; \text{Year 3} &amp; \text{Year 4} \\
\hline
\text{A} &amp; \text{Number of claims} &amp; 0 &amp; 2 &amp; 2 &amp; 3 \\
\hline
\text{A} &amp; \text{Insured vehicles} &amp;  1 &amp; 2 &amp; 2 &amp; 2\\  
\hline
&amp; &amp; &amp; &amp; &amp; \\
\hline
\text{B} &amp; \text{Number of claims} &amp; 0 &amp; 0 &amp; 1 &amp; 2\\    
\hline
\text{B} &amp; \text{Insured vehicles} &amp;  0 &amp; 2 &amp; 3 &amp; 4\\      
\hline
\end{array}
}
\]</span></p>
<h5 style="text-align: center;">
<a id="displayExample.9.6.3" href="javascript:toggleEX('toggleExample.9.6.3','displayExample.9.6.3');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.9.6.3" style="display: none">
<p><strong>Solution</strong> <span class="math inline">\(\bar{x}_A=\frac{0+2+2+3}{1+2+2+2}=1\)</span></p>
<p><span class="math inline">\(\bar{x}_B=\frac{0+1+2}{2+3+4}=\frac{1}{3}\)</span></p>
<p><span class="math inline">\(\bar{x}=\frac{7(1)+9(1/3)}{7+9}=\frac{5}{8}\)</span></p>
<p><span class="math inline">\(s_A^2=\frac{1}{4-1}\left[1(0-1)^2+2(1-1)^2+2(1-1)^2+2(\frac{3}{2}-1)^2\right]=\frac{1}{2 }\)</span></p>
<p><span class="math inline">\(s_B^2=\frac{1}{3-1}\left[2(0-\frac{1}{3})^2+3(\frac{1}{3}-\frac{1}{3})^2+4(\frac{1}{2}-\frac{1}{3})^2\right]=\frac{1}{6}\)</span></p>
<p><span class="math inline">\(\widehat{EPV}=\left[3\left(\frac{1}{2}\right)+2\left(\frac{1}{6}\right)\right]/(3+2)=\frac{11}{30}=0.3667\)</span></p>
<p><span class="math inline">\(\widehat{VHM}=\left[(7(1-\frac{5}{8})^2+9(\frac{1}{3}-\frac{5}{8})^2-(2-1)\frac{11}{30}\right]/\left[16-\left(\frac{1}{16}\right)(7^2+9^2)\right]=0.1757\)</span></p>
<p><span class="math inline">\(K=\frac{0.3667}{0.1757}=2.0871\)</span></p>
<p><span class="math inline">\(m_A=7\)</span>, <span class="math inline">\(m_B=9\)</span></p>
<p><span class="math inline">\(Z_A=\frac{7}{7+2.0871}=0.7703\)</span>, <span class="math inline">\(Z_B=\frac{9}{9+2.0871}=0.8118\)</span></p>
<p><span class="math inline">\(\hat{\mu}_A=0.7703(1)+(1-0.7703)(5/8)=0.9139\)</span></p>
<p><span class="math inline">\(\hat{\mu}_B=0.8118(1/3)+(1-0.8118)(5/8)=0.3882\)</span></p>
</div>
<hr />
</div>
<div id="semiparametric-estimation-for-bhlmann-and-bhlmann-straub-models" class="section level3 hasAnchor" number="9.6.3">
<h3><span class="header-section-number">9.6.3</span> Semiparametric Estimation for Bhlmann and Bhlmann-Straub Models<a href="ChapCredibility.html#semiparametric-estimation-for-bhlmann-and-bhlmann-straub-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the prior section on <a href="#" class="tooltip" style="color:green"><em>nonparametric estimation</em><span style="font-size:8pt">Statistical method that allows the functional form of a fit from data to have no assumed prior distribution, constraints, or parameters</span></a>, there were no assumptions about the distribution of the losses per exposure <span class="math inline">\(X_{ij}\)</span>. Assuming that the <span class="math inline">\(X_{ij}\)</span> have a particular distribution and using properties of the distribution along with the data to determine credibility parameters is referred to as <a href="#" class="tooltip" style="color:green"><em>semiparametric estimation</em><span style="font-size:8pt">Credibility method that assumes a distribution for the loss per exposure random variable and otherwise uses empirical data</span></a>.</p>
<p>An example of semiparametric estimation would be the assumption of a Poisson distribution when estimating claim frequencies. The Poisson distribution has the property that the mean and variance are identical and this property can simplify calculations. The following simple example comes from the prior section but now includes a Poisson assumption about claim frequencies.</p>
<p><strong>Example 9.6.4.</strong>
Two policyholders had claims over a three-year period as shown in the table below. Assume that the number of claims for each risk has a Poisson distribution. Estimate the expected number of claims for each policyholder using Bhlmann credibility and calculating necessary parameters from the data.</p>
<p><span class="math display">\[
\small{
\begin{array}{|c|c|c|}
\hline
\text{Year} &amp; \text{Risk A} &amp; \text{Risk B} \\
\hline
1 &amp; 0 &amp;  2 \\
2 &amp; 1 &amp;  1  \\  
3 &amp; 0 &amp;  2  \\              
\hline
\end{array}
}
\]</span></p>
<h5 style="text-align: center;">
<a id="displayExample.9.6.4" href="javascript:toggleEX('toggleExample.9.6.4','displayExample.9.6.4');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.9.6.4" style="display: none">
<p><strong>Solution</strong> <span class="math inline">\(\bar{x}_A=\frac{1}{3}(0+1+0)=\frac{1}{3}\)</span>, <span class="math inline">\(\bar{x}_B=\frac{1}{3}(2+1+2)=\frac{5}{3}\)</span></p>
<p><span class="math inline">\(\bar{x}=\frac{1}{2}(\frac{1}{3}+\frac{5}{3})=1\)</span></p>
<p>With Poisson assumption the estimated variance for risk A is <span class="math inline">\(\hat\sigma_A^2=\bar{x}_A=\frac{1}{3}\)</span></p>
<p>Similarly, <span class="math inline">\(\hat\sigma_B^2=\bar{x}_B=\frac{5}{3}\)</span></p>
<p><span class="math inline">\(\widehat{EPV}=\frac{1}{2}(\frac{1}{3})+\frac{1}{2}(\frac{5}{3})=1\)</span>. This is also <span class="math inline">\(\bar{x}\)</span> because of Poisson assumption.</p>
<p><span class="math inline">\(\widehat{VHM}=\frac{1}{2-1}\left[(\frac{1}{3}-1)^2+(\frac{5}{3}-1)^2\right]-\frac{1}{3}=\frac{5}{9}\)</span></p>
<p><span class="math inline">\(K=\frac{1}{5/9}=\frac{9}{5}\)</span></p>
<p><span class="math inline">\(Z_A=Z_B=\frac{3}{3+(9/5)}=\frac{5}{8}\)</span></p>
<p><span class="math inline">\(\hat{\mu}_A=\frac{5}{8}\left(\frac{1}{3}\right)+(1-\frac{5}{8})1=\frac{7}{12}\)</span></p>
<p><span class="math inline">\(\hat{\mu}_B=\frac{5}{8}\left(\frac{5}{3}\right)+(1-\frac{5}{8})1=\frac{17}{12}.\)</span></p>
</div>
<hr />
<p>Although we assumed that the number of claims for each risk was Poisson distributed in the prior example, we did not need this additional assumption because there was enough information to use nonparametric estimation. In fact, the Poisson assumption might not be appropriate because for risk B the sample mean is not equal to the sample variance: <span class="math inline">\(\bar{x}_B=\frac{5}{3}\neq s_B^2=\frac{1}{3}\)</span>.</p>
<p>The following example is commonly used to demonstrate a situation where semiparametric estimation is needed. There is insufficient information for nonparametric estimation but with the Poisson assumption, estimates can be calculated.</p>
<p><strong>Example 9.6.5.</strong>
A portfolio of 2,000 policyholders generated the following claims profile during a five-year period:</p>
<p><span class="math display">\[
\small{
\begin{array}{|c|c|}
\hline
\text{Number of Claims} &amp;   \\
\text{In 5 Years}           &amp;  \text{Number of policies}\\
\hline
0 &amp;  923 \\
1 &amp;  682 \\  
2 &amp;  249 \\  
3 &amp;  70   \\
4 &amp;  51   \\  
5 &amp;  25   \\     
\hline
\end{array}
}
\]</span></p>
<p>In your model you assume that the number of claims for each policyholder has a Poisson distribution and that a policyholders expected number of claims is constant through time. Use Bhlmann credibility to estimate the annual expected number of claims for policyholders with 3 claims during the five-year period.</p>
<h5 style="text-align: center;">
<a id="displayExample.9.6.5" href="javascript:toggleEX('toggleExample.9.6.5','displayExample.9.6.5');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.9.6.5" style="display: none">
<p><strong>Solution</strong> Let <span class="math inline">\(\theta_i\)</span> be the risk parameter for the <span class="math inline">\(i^{th}\)</span> risk in the portfolio with mean <span class="math inline">\(\mu(\theta_i)\)</span> and variance <span class="math inline">\(\sigma^2(\theta_i)\)</span>. With the Poisson assumption <span class="math inline">\(\mu(\theta_i)=\sigma^2(\theta_i)\)</span>. The expected value of the process variance is <span class="math inline">\(EPV=\mathrm{E}(\sigma^2(\theta_i)\)</span>) where the expectation is taken across all risks in the population. Because of the Poisson assumption for all risks it follows that <span class="math inline">\(EPV=\mathrm{E}(\sigma^2(\theta_i))\)</span> = <span class="math inline">\(\mathrm{E}(\mu(\theta_i))\)</span>. An estimate for the annual expected number of claims is <span class="math inline">\(\hat{\mu}(\theta_i)\)</span>= (observed number of claims)/5. This can also serve as the estimate for the expected value of the process variance for a risk. Weighting the process variance estimates (or means) by the number of policies in each group gives the estimators</p>
<p><span class="math display">\[\begin{equation*}  
\widehat{EPV}=\bar{x}=\frac{923(0)+682(1)+249(2)+70(3)+51(4)+25(5)}{(5)(2000)}=0.1719.
\end{equation*}\]</span></p>
<p>Using the formula (<a href="ChapCredibility.html#eq:VHM-estimate">(9.12)</a>), the <span class="math inline">\(VHM\)</span> estimator is</p>
<p><span class="math display">\[\begin{eqnarray*}
\widehat{VHM}&amp;=&amp;\frac{1}{2000-1}[923(0-0.1719)^2+682(0.20-0.1719)^2+249(0.40-0.1719)^2\\
                            &amp;   &amp;+70(0.60-0.1719)^2+51(0.80-0.1719)^2+25(1-0.1719)^2]-\frac{0.1719}{5}\\
                            &amp;=&amp; 0.0111\\
               \hat{K}  &amp;=&amp; \widehat{EPV}/\widehat{VHM}=0.1719/0.0111=15.49\\
               \hat{Z}  &amp;=&amp; \frac{5}{5+15.49}=0.2440\\
               \hat{\mu}_{3 \textrm{ claims}}&amp; = &amp; 0.2440(3/5)+(1-0.2440)0.1719=0.2764 .\\
\end{eqnarray*}\]</span></p>
</div>
<hr />
</div>
<div id="balancing-credibility-estimators" class="section level3 hasAnchor" number="9.6.4">
<h3><span class="header-section-number">9.6.4</span> Balancing Credibility Estimators<a href="ChapCredibility.html#balancing-credibility-estimators" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The credibility weighted model <span class="math inline">\(\hat{\mu}(\theta_i)=Z_i\bar{X}_i+(1-Z_i)\bar{X}\)</span>, where <span class="math inline">\(\bar{X}_i\)</span> is the loss per exposure for risk <span class="math inline">\(i\)</span> and <span class="math inline">\(\bar{X}\)</span> is loss per exposure for the population, can be used to estimate the expected loss for risk <span class="math inline">\(i\)</span>. The overall mean is <span class="math inline">\(\bar{X}=\sum_{i=1}^r(m_i/m) \bar{X}_i\)</span> where <span class="math inline">\(m_i\)</span> and <span class="math inline">\(m\)</span> are number of exposures for risk <span class="math inline">\(i\)</span> and population, respectively.</p>
<p>For the credibility weighted estimators to be in balance we want</p>
<p><span class="math display">\[  
\bar{X}=\sum_{i=1}^r(m_i/m) \bar{X}_i=\sum_{i=1}^r(m_i/m) \hat{\mu}(\theta_i).
\]</span></p>
<p>If this equation is satisfied then the estimated losses for each risk will add up to the population total, an important goal in ratemaking, but this may not happen if the complement of credibility is applied to <span class="math inline">\(\bar{X}\)</span>.</p>
<p>To achieve balance, we will set <span class="math inline">\(\hat{M}_X\)</span> as the amount that is applied to the complement of credibility and thus analyze the following equation:</p>
<p><span class="math display">\[  
\sum_{i=1}^r(m_i/m) \bar{X}_i=\sum_{i=1}^r(m_i/m) \left\{Z_i\bar{X}_i+(1-Z_i) \cdot \hat{M}_X\right\} .
\]</span></p>
<p>A little algebra gives</p>
<p><span class="math display">\[   
\sum_{i=1}^r m_i \bar{X}_i=\sum_{i=1}^r m_i Z_i\bar{X}_i + \hat{M}_X\sum_{i=1}^r m_i(1-Z_i),
\]</span></p>
<p>and</p>
<p><span class="math display">\[  
\hat{M}_X=\frac{\sum_{i=1}^r m_i(1-Z_i)\bar{X}_i}{\sum_{i=1}^r m_i(1-Z_i)}.
\]</span></p>
<p>Using this value for <span class="math inline">\(\hat{M}_X\)</span> will bring the credibility weighted estimators into balance.</p>
<p>If credibilities <span class="math inline">\(Z_i\)</span> were computed using the Bhlmann-Straub model, then <span class="math inline">\(Z_i=m_i/(m_i+K)\)</span>. The prior formula can be simplified using the following relationship</p>
<p><span class="math display">\[  
m_i(1-Z_i)=m_i\left(1-\frac{m_i}{m_i+K}\right)=m_i\left(\frac{(m_i+K)-m_i}{m_i+K}\right)=KZ_i .
\]</span></p>
<p>Therefore, an amount when applied to the complement of credibility that will bring the credibility-weighed estimators into balance with the overall mean loss per exposure is</p>
<p><span class="math display">\[  
\hat{M}_X=\frac{\sum_{i=1}^r  Z_i \bar{X}_i}{\sum_{i=1}^r  Z_i}.
\]</span></p>
<p><strong>Example 9.6.6.</strong>
An example from the nonparametric Bhlmann-Straub section had the following data for two risks. Find the amount associated with the complement of credibility, <span class="math inline">\(\hat{M}_X\)</span>, that will produce credibility-weighted estimates that are in balance.</p>
<p><span class="math display">\[
\small{
\begin{array}{|c|c|c|c|c|c|}
\hline
\text{Policyholder} &amp;  &amp; \text{Year 1} &amp; \text{Year 2} &amp; \text{Year 3} &amp; \text{Year 4} \\
\hline
\text{A} &amp; \text{Number of claims} &amp; 0 &amp; 2 &amp; 2 &amp; 3 \\
\hline
\text{A} &amp; \text{Insured vehicles} &amp;  1 &amp; 2 &amp; 2 &amp; 2\\  
\hline
&amp; &amp; &amp; &amp; &amp; \\
\hline
\text{B} &amp; \text{Number of claims} &amp; 0 &amp; 0 &amp; 1 &amp; 2\\    
\hline
\text{B} &amp; \text{Insured vehicles} &amp;  0 &amp; 2 &amp; 3 &amp; 4\\      
\hline
\end{array}
}
\]</span></p>
<h5 style="text-align: center;">
<a id="displayExample.9.6.6" href="javascript:toggleEX('toggleExample.9.6.6','displayExample.9.6.6');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExample.9.6.6" style="display: none">
<p><strong>Solution</strong> The credibilities from the prior example are <span class="math inline">\(Z_A=\frac{7}{7+2.0871}=0.7703\)</span> and <span class="math inline">\(Z_B=\frac{9}{9+2.0871}=0.8118\)</span>. The sample means are <span class="math inline">\(\bar{x}_A=1\)</span> and <span class="math inline">\(\bar{x}_B=1/3\)</span>. The balanced complement of credibility is</p>
<p><span class="math display">\[  
\hat{M}_X=\frac{0.7703(1)+0.8118(1/3)}{0.7703+0.8118}=0.6579.
\]</span></p>
<p>The updated credibility estimates are <span class="math inline">\(\hat{M}_{X_A}=0.7703(1)+(1-0.7703)(.6579)=0.9214\)</span> versus the previous 0.9139 and <span class="math inline">\(\hat{M}_{X_B}=0.8118(1/3)+(1-0.8118)(.6579)=0.3944\)</span> versus the previous 0.3882. Checking the balance on the new estimators: (7/16)(0.9214)+(9/16)(0.3944)=0.6250. This exactly matches <span class="math inline">\(\bar{X}=10/16=0.6250\)</span>.</p>
</div>
<hr />
<div id="surveyElement96">

</div>
<div id="surveyResult96">

</div>
<h5 style="text-align: center;">
<a id="display.Quiz96.1" href="javascript:toggleQuiz
('display.Quiz96.2','display.Quiz96.1');"><i><strong>Show Quiz Solution</strong></i></a>
</h5>
<div id="display.Quiz96.2" style="display: none">
<p id="Quiz96Soln">
</p>
<hr />
</div>
<script type="text/javascript" src="./Quizzes/QuizJavascript/Quiz96.js">
</script>
</div>
</div>
<div id="Cred-further-reading-and-resources" class="section level2 hasAnchor" number="9.7">
<h2><span class="header-section-number">9.7</span> Further Resources and Contributors<a href="ChapCredibility.html#Cred-further-reading-and-resources" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="exercises-4" class="section level4 unnumbered hasAnchor">
<h4>Exercises<a href="ChapCredibility.html#exercises-4" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Here are a set of exercises that guide the viewer through some of the theoretical foundations of <strong>Loss Data Analytics</strong>. Each tutorial is based on one or more questions from the professional actuarial examinations, typically the Society of Actuaries Exam C/STAM.</p>
<p style="text-align: center;">
<a href="https://www.ssc.wisc.edu/~jfrees/loss-data-analytics/loss-data-analyticscredibility-guided-tutorials/">Credibility Guided Tutorials</a>
</p>
</div>
<div id="contributors-6" class="section level4 unnumbered hasAnchor">
<h4>Contributors<a href="ChapCredibility.html#contributors-6" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><strong>Gary Dean</strong>, Ball State University is the author of the initial version of this chapter. Email: <a href="mailto:cgdean@bsu.edu" class="email">cgdean@bsu.edu</a> for chapter comments and suggested improvements.</li>
<li>Chapter reviewers include: Liang (Jason) Hong, Ambrose Lo, Ranee Thiagarajah, Hongjuan Zhou.</li>
</ul>

</div>
</div>
</div>
<h3>Bibliography<a href="bibliography.html#bibliography" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Buhlmann1967" class="csl-entry">
Bhlmann, Hans. 1967. <span>The Complement of Credibility,</span> 199207.
</div>
<div id="ref-BuhlmannGisler2005" class="csl-entry">
Bhlmann, Hans, and Alois Gisler. 2005. <em>A Course in Credibility Theory and Its Applications</em>. ACTEX Publications.
</div>
<div id="ref-klugman2012" class="csl-entry">
Klugman, Stuart A., Harry H. Panjer, and Gordon E. Willmot. 2012. <em>Loss Models: From Data to Decisions</em>. John Wiley &amp; Sons.
</div>
<div id="ref-Tse2009" class="csl-entry">
Tse, Yiu-Kuen. 2009. <em>Nonlife Actuarial Models: Theory, Methods and Evaluation</em>. Cambridge University Press.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ChapRiskClass.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ChapPortMgt.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
