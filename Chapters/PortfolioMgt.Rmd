#Portfolio Management including Reinsurance {#C:PortMgt}

`r chapnum = 10`

*Chapter Preview*. Define $S$ to be (random) obligations that arise from a collection (portfolio) of insurance contracts.

-   We are particularly interested in probabilities of large outcomes and so formalize the notion of a heavy-tail distribution in Section \@ref(S:Tails).

-   How much in assets does an insurer need to retain to meet obligations arising from the random $S$? A study of risk measures in Section \@ref(S:RiskMeasure) helps to address this question.

-   As with policyholders, insurers also seek mechanisms in order to     spread risks. A company that sells insurance to an insurance company is known as a reinsurer, studied in Section \@ref(S:Reinsurance).


##Tails of Distributions {#S:Tails}

In 1998 freezing rains fell on eastern Ontario, southwestern Quebec and lasted for six days. The event doubled the amount of precipitation in the area experienced in any prior ice storm, and resulted in a catastrophe that produced excess of 840,000 cases of insurance claims. This number is 20$\%$ more than that of the claims caused by the Hurricane Andrew - one of the largest natural disasters in the history of North America. After all, the catastrophe caused approximately 1.44 billion Canadian dollars insurance settlements which is the highest loss burden in the history of Canada. More examples of similar catastrophic events that caused extremal insurance losses are Hurricanes Harvey and Sandy, the 2011 Japanese earthquake and tsunami, and so forth.

In the context of insurance, a few large losses hitting a portfolio and then converting into claims usually represent the greatest part of the indemnities paid by insurance companies. The aforementioned losses, also called `extremes', are quantitatively modelled by the tails of the associated probability distributions.  From the quantitative modelling standpoint, relying on probabilistic models with improper tails is rather daunting.  For instance, periods of financial stress may appear with a higher frequency than expected, and insurance losses may occur with worse severity. Therefore, the study of probabilistic behavior in the tail portion of actuarial models is of utmost importance in the modern framework of quantitative risk management. For this reason, this section is devoted to the introduction of a few mathematical notions that characterize the tail weight of random variables (*rv*'s). The applications of these notions will benefit us in the construction and selection of appropriate models with desired mathematical properties in the tail portion, that are suitable for a given task.

Formally, define $X$ to be the (random) obligations that arise from a collection (portfolio) of insurance contracts.  We are particularly interested in studying the right tail of the distribution of $X$, which represents the occurrence of large losses. Speaking plainly, a *rv* is said to be heavier-tailed if higher probabilities are assigned to larger values.  Note that this by no mean implies the probability density/mass functions are increasing as the value of *rv* goes to infinity.  Ineed for a real-valued *rv*, the *pdf*/*pmf* must diminish at infinity in order to guarantee the total probability to be equal to one.  Instead, what we concern about is the rate of decaying of the probability function.
Unwelcome outcomes are more likely to occur for an insurance portfolio that is described by a loss *rv* possessing heavier (right) tail.  Tail weight can be an absolute or a relative concept.  Specifically, for the former, we may consider a *rv* to be heavy-tailed if certain mathematical properties of the probability distribution are met.  For the latter, we can say the tail of one distribution is heavier than the other if some tail measures are larger/smaller.

In the statistics and probability literature, there are several quantitative approaches have been proposed to classify and compare tail weight. Among most of these approaches, the survival functions serve as the building block.  In what follows, we are going to introduce two simple yet useful tail classification methods, in which the basic idea is to study the quantities that are closely related to behavior of the survival function of $X$.

### Classification Based on Moments

One possible way of classifying the tail weight of distribution is by assessing the existence of raw moments.  Since our major interest lies in the right tails of distributions, we henceforth assume the obligation/loss *rv*\ $X$ to be positive. At the outset, let us recall that the $k-$th raw moment of a continuous *rv*\ $X$, for $k\geq 0$, can be computed via

\begin{eqnarray*}
    \mu_k' &=& k \int_0^{\infty} x^{k-1} S(x) dx, \\
\end{eqnarray*}
    
where $S(\cdot)$ denotes the survival function of $X$.  It is a simple matter to see that the existence of the raw moments depends on the asymptotic behavior of the survival function at infinity.  Namely, the faster the survival function decays to zero, the higher the order of finite moment the associated *rv* possesses. Hence the maximal order of finite moment, denoted by $k^{\ast}:=\sup\{k\in \mathbf{R}_+:\mu_k'<\infty \}$, can be considered as an indicator of tail weight. This observation leads us to the moment-based tail weight classification method, which is defined formally next.

<!-- \label{def:moment-base} -->

**Definition  `r chapnum`.1.**  *For a positive loss random variable $X$, if all the positive raw moments exist, namely the maximal order of finite moment $k^{\ast}=\infty$, then $X$ is said to be light-tailed based on the moment method. If $k^{\ast}=a \in (0,\infty)$, then $X$ is said to be heavy-tailed based on the moment method. Moreover, for two positive loss random variables $X_1$ and $X_2$ with maximal orders of moment $k^{\ast}_1$ and $k^{\ast}_2$ respectively, we say $X_1$ has a heavier (right) tail than  $X_2$ if $k^{\ast}_1\leq k^{\ast}_2$.*

It is noteworthy that the first part of Definition  `r chapnum`.1 is an absolute concept of tail weight, while the second part is a relative concept of tail weight which compares the (right) tails between two distributions.  Next, we are going to present a few examples that illustrate the applications of the moment-based method for comparing tail weight.  Some of these examples are borrowed from @klugman2012.

<!-- \label{exm:gamma}   -->
**Example `r chapnum`.1.1. Finiteness of gamma moments.**
Let $X\sim Gamma(\alpha,\theta)$, with $\alpha>0$ and $\theta>0$, then for all $k>0$, show that $\mu_k' < \infty$.

<h5 style="text-align: center;"><a id="displayTextExamplePortMgt.1.1" href="javascript:toggleEX('toggleExamplePortMgt.1.1','displayTextExamplePortMgt.1.1');"><i><strong>Show Example Solution</strong></i></a> </h5>
<div id="toggleExamplePortMgt.1.1" style="display: none">

**Solution.**

\begin{eqnarray*}
    \mu_k' &=& \int_0^{\infty} x^k \frac{x^{\alpha-1} e^{-x/\theta}}{\Gamma(\alpha) \theta^{\alpha}} dx \\
    &=& \int_0^{\infty} (y\theta)^k  \frac{(y\theta)^{\alpha-1} e^{-y}}{\Gamma(\alpha) \theta^{\alpha}} \theta dy \\
    &=& \frac{\theta^k}{\Gamma(\alpha)} \Gamma(\alpha+k) < \infty.
\end{eqnarray*}
  
Since all the positive moments exist, i.e., $k^{\ast}=\infty$, in accordance with the moment-based classification method in Definition  `r chapnum`.1, the gamma distribution is light-tailed.  

</div>

*** 


**Example `r chapnum`.1.2. Finiteness of Weibull moments.**
Let $X\sim Weibull(\theta,\tau)$, with $\theta>0$ and $\tau>0$, then for all $k>0$, show that $\mu_k' < \infty$.

<h5 style="text-align: center;"><a id="displayTextExamplePortMgt.1.2" href="javascript:toggleEX('toggleExamplePortMgt.1.2','displayTextExamplePortMgt.1.2');"><i><strong>Show Example Solution</strong></i></a> </h5>
<div id="toggleExamplePortMgt.1.2" style="display: none">

**Solution.**


\begin{eqnarray*}
    \mu_k' &=& \int_0^{\infty} x^k \frac{\tau x^{\tau-1} }{\theta^{\tau}} e^{-(x/\theta)^{\tau}}dx \\
    &=& \int_0^{\infty}  \frac{ y^{k/\tau} }{\theta^{\tau}} e^{-y/\theta^{\tau}}dy \\
    &=& \theta^{k} \Gamma(1+k/\tau) < \infty.
\end{eqnarray*}

</div>

*** 

    
Again, due to the existence of all the positive moments, the Weibull distribution is light-tailed.

We notice in passing that the gamma and Weibull distributions have been used quite intensively in the actuarial practice nowadays.  Applications of these two distributions are vast which include, but are not limited to, insurance claim severity modelling, solvency assessment, loss reserving, aggregate risk approximation, reliability engineering and failure analysis.   We have thus far seen two examples of using the moment-based method to analyze light-tailed distributions.  We document a heavy-tailed example in what follows.

**Example `r chapnum`.1.3. Heavy tail nature of the Pareto distribution.**
Let $X\sim Pareto(\alpha,\theta)$, with $\alpha>0$ and $\theta>0$, then for $k>0$

\begin{eqnarray*}
    \mu_k^{'} &=& \int_0^{\infty} x^k \frac{\alpha \theta^{\alpha}}{(x+\theta)^{\alpha+1}} dx \\
    &=& \alpha \theta^{\alpha} \int_{\theta}^{\infty} (y-\theta)^k {y^{-(\alpha+1)}} dy.
\end{eqnarray*}

Consider a similar integration:

\begin{eqnarray*}
  g_k:=\int_{\theta}^{\infty} {y^{k-\alpha-1}} dy=\left\{
  \begin{array}{ll}
    <\infty, & \hbox{for } k<\alpha;\\
    =\infty, & \hbox{for } k\geq \alpha.
  \end{array}
\right.
\end{eqnarray*}

Meanwhile,

\[\lim_{y\rightarrow \infty} \frac{(y-\theta)^k {y^{-(\alpha+1)}}}{y^{k-\alpha-1}}=\lim_{y\rightarrow \infty}
(1-\theta/y)^{k}=1.\]

Application of the limit comparison theorem for improper integrals yields $\mu_k'$ is finite if and only if $g_k$ is finite. Hence we can conclude that the raw moments of Pareto *rv*'s exist only up to $k<\alpha$, i.e., $k^{\ast}=\alpha$, and thus the distribution is heavy-tailed.  What is more, the maximal order of finite moment depends only on the shape parameter $\alpha$ and it is an increasing function of $\alpha$. 
In other words, based on the moment method, the tail weight of Pareto *rv*'s is solely manipulated by $\alpha$ --  the smaller the value of $\alpha$, the heavier the tail weight becomes.  Since $k^{\ast}<\infty$, the tail of Pareto distribution is heavier than those of the gamma and Weibull distributions.  

*** 

We are going to conclude this current section by an open discussion on the limitations of the moment-based method.  Despite its simple implementation and intuitive interpretation, there are certain circumstances in which the application of the moment-based method is not suitable. First, for more complicated probabilistic models, the $k$-th raw moment may not be simple to derive, and thus the identification of the maximal order of finite moment can be challenging.  Second, the moment-based method does not well comply with main body of the well established heavy tail theory in the literature.  Specifically, the existence of moment generating functions is arguably the most popular method for classifying heavy tail  versus light tail within the community of academic actuaries.  However, for some *rv*'s such as the lognormal *rv*'s, their moment generating functions do not exist even that all the positive moments are finite.  In these cases, applications of the moment-based methods can lead to different tail weight assessment.  Third, when we need to compare the tail weight between two light-tailed distributions both having all positive moments exist, the moment-based method is no longer informative (see, e.g., Examples `r chapnum`.1 and `r chapnum`.2).


### Comparison Based on Limiting Tail Behavior

In order to resolve the aforementioned issues of the moment-based classification method, an alternative approach for comparing tail weight is to directly study the limiting behavior of the survival functions.

**Definition  `r chapnum`.2.** For two *rv*'s $X$ and $Y$, let

$$
\gamma:=\lim_{t\rightarrow \infty}\frac{S_X(t)}{S_Y(t)}.
$$
We say that

* $X$ has a **heavier right tail** than $Y$ if $\gamma=\infty$;  
* $X$ and $Y$ are **proportionally equivalent in the right tail** if $\gamma =c\in \mathbf{R}_+$;
* $X$ has a **lighter right tail** than $Y$ if $\gamma=0$. 

**Example `r chapnum`.4. Comparison of Pareto to Weibull distributions.**
Let $X\sim Pareto(\alpha, \theta)$ and $Y\sim Weibull(\tau, \theta)$, for $\alpha>0$, $\tau>0$, and $\theta>0$. Show that the Pareto has a heavier right tail than the Weibull.

<h5 style="text-align: center;"><a id="displayTextExamplePortMgt.1.4" 
href="javascript:toggleEX('toggleExamplePortMgt.1.4','displayTextExamplePortMgt.1.4');"><i><strong>Show Example Solution</strong></i></a> </h5>
<div id="toggleExamplePortMgt.1.4" style="display: none">

**Solution.**


\begin{eqnarray*}
    \lim_{t\rightarrow \infty}\frac{S_X(t)}{S_Y(t)} &=& \lim_{t\rightarrow \infty}\frac{(1+t/\theta)^{-\alpha}}{\exp\{-(t/\theta)^{\tau}\}} \\
    &=& \lim_{t\rightarrow \infty}\frac{\exp\{t/\theta^{\tau} \}}{(1+t^{1/\tau}/\theta)^{\alpha}} \\
    &=& \lim_{t\rightarrow \infty}\frac{\sum_{i=0}^{\infty}\left(\frac{t}{\theta^{\tau}}\right)^{i}/i!}{(1+t^{1/\tau}/\theta)^{\alpha}}\\
    &=& \lim_{t\rightarrow \infty} \sum_{i=0}^{\infty} \left(t^{-i/\alpha}+\frac{t^{(1/\tau-i/\alpha)}}{\theta} \right)^{-\alpha}/\theta^{\tau i}i!\\
    &=& \infty.
\end{eqnarray*}

Therefore, the Pareto distribution has a heavier tail than the Weibull distribution.  One may also realize that exponentials go to infinity faster than polynomials, thus the aforementioned limit must be infinite.

</div>

*** 


For some distributions  of which the survival functions do not admit explicit expressions, we may find the following alternative formula useful:

\begin{eqnarray*}
    \lim_{t\to \infty} \frac{S_X(t)}{S_Y(t)} &=& \lim_{t \to \infty} \frac{S_X^{'}(t)}{S_Y^{'}(t)} \\
    &=& \lim_{t \to \infty} \frac{-f_X(t)}{-f_Y(t)}\\
 &=& \lim_{t\to \infty} \frac{f_X(t)}{f_Y(t)}.
\end{eqnarray*}

given that the density functions exist.


**Example `r chapnum`.1.5. Comparison of Pareto to gamma distributions.**
Let $X\sim Pareto(\alpha, \theta)$ and $Y\sim Gamma(\alpha, \theta)$, for $\alpha>0$ and $\theta>0$. Show that the Pareto has a heavier right tail than the gamma.

<h5 style="text-align: center;"><a id="displayTextExamplePortMgt.1.5" 
href="javascript:toggleEX('toggleExamplePortMgt.1.5','displayTextExamplePortMgt.1.5');"><i><strong>Show Example Solution</strong></i></a> </h5>
<div id="toggleExamplePortMgt.1.5" style="display: none">

**Solution.**


\begin{eqnarray*}
    \lim_{t\to \infty} \frac{f_{X}(t)}{f_{Y}(t)} &=& \lim_{t \to \infty} \frac{\alpha \theta^{\alpha} (t+ \theta)^{-\alpha-1}}{t^{\tau-1} e^{-t/\lambda} \lambda^{-\tau} \Gamma(\tau)^{-1}} \\
 &\propto&  \lim_{t\to \infty} \frac{e^{t/\lambda}}{(t+\theta)^{\alpha+1} t^{\tau-1}} \\
    &=& \infty,
\end{eqnarray*}

as exponentials go to infinity faster than polynomials.

</div>

*** 


## Risk Measures {#S:RiskMeasure}

In the previous section, we studied two methods for classifying the weight of distribution tails.  We may claim that the risk associated with one distribution is more dangerous (asymptotically) than the others if the tail is heavier.  However, knowing one risk is more dangerous (asymptotically) than the others may not provide sufficient information for a sophisticated risk management purpose, and in addition, one is also interested in quantifying how much more. In fact, the magnitude of risk associated with a given loss distribution is an essential input for many insurance applications, such as actuarial pricing, reserving, hedging, insurance regulatory oversight, and so forth.

### Background 

To compare the magnitude of risk in a practically convenient manner, we aim to seek a function that maps the loss *rv* of interest to a numerical value indicating the level of riskiness, which is termed the risk measure.  Putting mathematically, denoted by $\mathcal{X}$ a set of insurance loss *rv*'s, a risk measure is a functional map $H:\mathcal{X}\rightarrow \mathbf{R}_+$.  In principle, risk measures can admit an unlimited number of functional formats.  Classical examples of risk measures include the mean $\mathrm{E}[X]$, the standard deviation $\mathrm{SD}(X):=\sqrt{\mathrm{Var}(X)}$, the standard deviation principle

<!-- \label{eqn:SD-principle} -->

\begin{equation}
H_{\mathrm{SD}}(X):=\mathrm{E}[X]+\alpha \mathrm{SD}(X),\text{ for } \alpha\geq 0,
(\#eq:SD-principle) 
\end{equation}


and the variance principle
$$
H_{\mathrm{Var}}(X):=\mathrm{E}[X]+\alpha \mathrm{Var}(X),\text{ for } \alpha\geq 0.
$$
It is a simple matter to check that all the aforementioned functions are risk measures in which we input the loss *rv* and the functions output a numerical value.  On a different note, the function $H^{\ast}(X):=\alpha X^{\beta}$ for any real-valued $\alpha,\beta\neq 0$, is not a risk measure since $H^{\ast}$ produces another *rv* rather than a single numerical value.

Since risk measures are scalar measures which aim to use a single numerical value to describe the stochastic nature of loss *rv*'s, it should not be surprising to us that there is no risk measures which can capture all the risk information of the associated *rv*'s.  Therefore, when seeking useful risk measures, it is important for us to keep in mind that the measures should be at least

* interpretable practically;  
* computable conveniently; and  
* being able to reflect the most critical information of risk underpinning the loss distribution.  

A vast number of risk measures have been developed in the literature of actuarial mathematics. Unfortunately, there is no best risk measure that can outperform the others, and the selection of appropriate risk measure depends mainly on the application questions at hand.  In this respect, it is imperative to emphasize that `risk' is a subjective concept, and thus even given the same problem, there are multifarious approaches to assess risk.  However, for many risk management applications, there is a wide agreement that economically sounded risk measures should satisfy four major axioms which we are going to describe in detail next.  Risk measures that satisfy these axioms are termed *coherent* risk measures.

Consider in what follows a risk measure $H(\cdot)$, then $H$ is a coherent risk measure if the following axioms are satisfied.  

* **Axiom 1.** *Subadditivity:* $H(X+Y)\leq H(X)+H(Y)$.  The economic implication of this axiom is that diversification benefits exist if different risks are combined.  
* **Axiom 2.** *Monotonicity:* if $\Pr[X\leq Y]=1$, then $H(X)\leq H(Y)$. Recall that $X$ and $Y$ are *rv*'s representing losses, the underlying economic implication is that higher losses essentially leads to a higher level of risk.    
* **Axiom 3.** *Positive homogeneity:* $H(cX)=cH(X)$ for any positive constant $c$.  A potential economic implication about this axiom is that risk measure should be independent of the monetary units in which the risk is measured.  For example, let $c$ be the currency exchange rate between the US and Canadian dollars, then the risk of random losses measured in terms of US dollars (i.e., X) and Canadian dollars (i.e., cX) should be different only up to the exchange rate $c$ (i.e., $cH(x)=H(cX)$).  
* **Axiom 4.** *Translation invariance:* $H(X+c)=H(X)+c$ for any positive constant $c$.  If the constant $c$ is interpreted as risk-free cash, this axiom tells that no additional risk is created for adding cash to an insurance portfolio, and injecting risk-free capital of $c$ can only reduce the risk by the same amount.  


Verifying the coherent properties for some risk measures can be quite straightforward, but it can be very challenging sometimes.  For example, it is a simple matter to check that the mean is a coherent risk measure since for any pair of *rv*'s $X$ and $Y$ having finite means and constant $c>0$,

* validation of *subadditivity*: $\mathrm{E}[X+Y]=\mathrm{E}[X]+\mathrm{E}[Y]$;
* validation of *monotonicity*: if $\Pr[X\leq Y]=1$, then $\mathrm{E}[X]\leq \mathrm{E}[Y]$;
* validation of *positive homogeneity*: $\mathrm{E}[cX]=c\mathrm{E}[X]$;
* validation of *translation invariance*: $\mathrm{E}[X+c]=\mathrm{E}[X]+c$

On a different note, the standard deviation is not a coherent risk measure.  Specifically, one can check that the standard deviation satisfies

* validation of *subadditivity*: 

\begin{eqnarray*} 
\mathrm{SD}[X+Y]&=&\sqrt{\mathrm{Var}(X)+\mathrm{Var}(Y)+2\mathrm{Cov}(X,Y)}\\
      &\leq& \sqrt{\mathrm{SD}(X)^2+\mathrm{SD}(Y)^2+2\mathrm{SD}(X)\mathrm{SD}(Y)}\\
      &=& \mathrm{SD}(X)+\mathrm{SD}(Y);
\end{eqnarray*}

* validation of *positive homogeneity*: $\mathrm{SD}[cX]=c~\mathrm{SD}[X]$.  

However, the standard deviation does not comply with translation invariance property as for any positive constant $c$,
$$
\mathrm{SD}(X+c)=\mathrm{SD}(X)<\mathrm{SD}(X)+c.
$$
Moreover, the standard deviation also does not satisfy the monotonicity property.  To see this, consider the following two *rv*'s:
<!-- \label{eqn:special_x} -->

\begin{eqnarray}
X=\left\{
    \begin{array}{ll}
      0, & \hbox{with probability $0.25$;} \\
      4, & \hbox{with probability $0.75$,}
    \end{array}
  \right.
(\#eq:special-x)
\end{eqnarray}

and $Y$ is a degenerate *rv* such that
<!-- \label{eqn:special_y} -->

\begin{eqnarray}
\Pr[Y = 4] = 1.
(\#eq:special-y)
\end{eqnarray}

It is easy to check that $\Pr[X\leq Y]=1$, but $\mathrm{SD}(X)=\sqrt{4^2\cdot 0.25\cdot 0.75}=\sqrt{3}>\mathrm{SD}(Y)=0$.

We have so far checked that $\mathrm{E}[\cdot]$ is a coherent risk measure, but not $\mathrm{SD}(\cdot)$.  Let us now proceed to study the coherent property for the standard deviation principle \@ref(eq:SD-principle) which is a linear combination of two coherent and incoherent risk measures.  To this end, for a given $\alpha>0$, we check the four axioms for $H_{\mathrm{SD}}(X+Y)$ one by one:

* validation of *subadditivity:*

\begin{eqnarray*}
  H_{\mathrm{SD}}(X+Y) &=& \mathrm{E}[X+Y]+\alpha \mathrm{SD}(X+Y) \\
  &\leq& \mathrm{E}[X]+\mathrm{E}[Y]+\alpha [\mathrm{SD}(X) +\mathrm{SD}(Y)]\\
  &=& H_{\mathrm{SD}}(X)+ H_{\mathrm{SD}}(Y);
\end{eqnarray*}

* validation of *positive homogeneity:*
$$
H_{\mathrm{SD}}(cX)=c\mathrm{E}[X]+c\alpha\mathrm{SD}(X)=cH_{\mathrm{SD}}(X);
$$
* validation of *translation invariance:*
$$
H_{\mathrm{SD}}(X+c)=\mathrm{E}[X]+c+\alpha\mathrm{SD}(X)=H_{\mathrm{SD}}(X)+c.
$$

It only remains to verify the monotonicity property, which may or may not be satisfied depending on the value of $\alpha$.  To see this, consider again the setup of \@ref(eq:special-x) and \@ref(eq:special-y) in which $\Pr[X\leq Y]=1$.  Let $\alpha=0.1\cdot \sqrt{3}$, then $H_{\mathrm{SD}}(X)=3+0.3=3.3< H_{\mathrm{SD}}(Y)=4$ and the monotonicity condition is met.  On the other hand, let $\alpha=\sqrt{3}$, then $H_{\mathrm{SD}}(X)=3+3=6> H_{\mathrm{SD}}(Y)=4$ and the monotonicity condition is not satisfied. More precisely, by setting

$$
  H_{\mathrm{SD}}(X) = 3+\alpha\sqrt{3} \leq4= H_{\mathrm{SD}}(Y),
$$

we find that the monotonicity condition is only satisfied for $0\leq\alpha\leq 1/\sqrt{3}$, and thus the standard deviation principle $H_{\mathrm{SD}}$ is coherent.  This result appears to be very intuitive to us since the standard deviation principle $H_{\mathrm{SD}}$ is a linear combination of two risk measures of which one is coherent and the other is incoherent.  If $\alpha\leq 1/\sqrt{3}$, then the coherent measure dominates the incoherent one, thus the resulting measure $H_{\mathrm{SD}}$ is coherent and vice versa. Note the the aforementioned conclusion may not be generalized to any pair of *rv*'s $X$ and $Y$.

The literature on risk measures has been growing rapidly in popularity and importance. In the succeeding two subsections, we introduce two indices which have recently earned an unprecedented amount of interest among theoreticians, practitioners, and regulators.  They are namely the *Value-at-Risk* (*VaR*) and the *Tail Value-at-Risk* (*TVaR*) measures.  The economic rationale behind these two popular risk measures is similar to that for the tail classification methods introduced in the previous section, with which we hope to capture the risk of extremal losses represented by the distribution tails. 


### Value-at-Risk

At the outset, we offer the formal definition of *VaR*.  

**Definition  `r chapnum`.3.**
Consider an insurance loss random variable $X$.  The Value-at-Risk measure of $X$ with confidence level $q\in [0,1]$ is formulated as

\begin{eqnarray}
VaR_q[X]:=\inf\{x\in \mathbf{R}:F_X(x)\geq q\}.
(\#eq:Value-at-Risk)
\end{eqnarray}

The *VaR* measure outputs the smallest value of $X$ such that the associated *cdf* first excesses or equates to $q$.  In the fields of probability and statistics, the *VaR* is also known as the percentiles.

Here is how we should interpret *VaR* in the lingo of actuarial mathematics. The *VaR* is a forecast of the `maximal' probable loss for an insurance product/portfolio or a risky investment occurring $q\times 100\%$ of times, over a specific time horizon (typically, one year).  For instance, let $X$ be the annual loss *rv* of an insurance product, $VaR_{0.95}[X]=100$ million means that there is a $5\%$ chance that the loss will exceed 100 million over a given year.  Owing to the meaningful interpretation, *VaR* has become the industrial standard to measuring financial and insurance risks since 1990's.  Financial conglomerates, regulators, and academics often utilize *VaR* to price insurance products, measure risk capital, ensure the compliance with regulatory rules, and disclose the financial positions.

Next, we are going to present a few examples about the computation of *VaR*.  

<!-- \label{exm:exponential}-->
**Example `r chapnum`.2.1. *VaR* for the exponential distribution.**
Consider an insurance loss *rv* $X\sim Exp(\theta)$ for $\theta>0$, then the *cdf*\ of $X$ is given by 
$$
F_X(x)=1-e^{-x/\theta}, \text{ for } x>0.
$$
Give a closed-form expression for the *VaR*.

<h5 style="text-align: center;"><a id="displayTextExamplePortMgt.2.1" 
href="javascript:toggleEX('toggleExamplePortMgt.2.1','displayTextExamplePortMgt.2.1');"><i><strong>Show Example Solution</strong></i></a> </h5>
<div id="toggleExamplePortMgt.2.1" style="display: none">

**Solution.**

Because exponential distribution is a continuous distribution, the smallest value such that the *cdf*\ first exceeds or equates to $q \in [0,1]$ must be at the point $x_q$ satisfying
$$
q=F_X(x_q)=1-\exp\{-x_q/\theta \}.
$$
Thus
$$
VaR_q[X]=F_X^{-1}(q)=-\theta[\log(1-q)].
$$
</div>

*** 

The result reported in Example `r chapnum`.6 can be generalized to any continuous *rv*'s having strictly increasing *cdf*.  Specifically, the *VaR* of any continuous *rv*'s is simply the inverse of the corresponding *cdf*.  Let us consider another example of continuous *rv* which has the support from negative infinity to positive infinity.


**Example `r chapnum`.2.2. *VaR* for the normal distribution.**
Consider an insurance loss *rv* $X\sim Normal(\mu,\sigma^2)$ with $\mu\in \mathbf{R}$ and $\sigma>0$.  In this case, one may interpret the negative values of $X$ as profit or revenue.  Give a closed-form expression for the *VaR*.

<h5 style="text-align: center;"><a id="displayTextExamplePortMgt.2.2" 
href="javascript:toggleEX('toggleExamplePortMgt.2.2','displayTextExamplePortMgt.2.2');"><i><strong>Show Example Solution</strong></i></a> </h5>
<div id="toggleExamplePortMgt.2.2" style="display: none">

**Solution.**

Because normal distribution is a continuous distribution, the *VaR* of $X$ must satisfy

\begin{eqnarray*}
 q &=& F_X(VaR_q[X])\\
&=&\Pr\left[(X-\mu)/\sigma\leq (VaR_q[X]-\mu)/\sigma\right]\\
&=&\Phi((VaR_q[X]-\mu)/\sigma).
\end{eqnarray*}

Therefore, we have
$$
VaR_q[X]=\Phi^{-1}(q)\ \sigma+\mu.
$$

</div>

*** 

In many insurance applications, we have to deal with transformations of *rv*'s.  For instance, in Example `r chapnum`.7, the loss *rv*\ $X\sim Normal(\mu, \sigma^2)$ can be viewed as a linear transformation of a standard normal *rv*\ $Z\sim Normal(0,1)$, namely $X=Z\sigma+\mu$.  By setting $\mu=0$ and $\sigma=1$, it is straightforward for us to check $VaR_q[Z]=\Phi^{-1}(q).$  A useful finding revealed from Example `r chapnum`.7 is that the *VaR* of a linear transformation of the normal *rv*'s is equivalent to the linear transformation of the *VaR* of the original *rv*'s.  This finding can be further generalized to any *rv*'s as long as the transformations are strictly increasing.  The next example highlights the usefulness of the abovementioned finding.

**Example `r chapnum`.2.3. *VaR* for transformed variables.**
Consider an insurance loss *rv*\ $Y\sim lognormal(\mu,\sigma^2)$, for $\mu\in \mathbf{R}$ and $\sigma>0$. Give an expression of the $VaR$ of $Y$ in terms of the standard normal inverse *cdf*.

<h5 style="text-align: center;"><a id="displayTextExamplePortMgt.2.3" 
href="javascript:toggleEX('toggleExamplePortMgt.2.3','displayTextExamplePortMgt.2.3');"><i><strong>Show Example Solution</strong></i></a> </h5>
<div id="toggleExamplePortMgt.2.3" style="display: none">

**Solution.**

Note that $\log Y\sim Normal(\mu,\sigma^2)$, or equivalently let $X\sim Normal(\mu,\sigma^2)$, then $Y\overset{d}{=}e^{X}$ which is strictly increasing transformation.  Here, the notation `$\overset{d}{=}$' means equality in distribution.  The *VaR* of $Y$ is thus given by the exponential transformation of the *VaR* of $X$.  Precisely, for $q\in [0,1]$,
$$
VaR_{q}[Y]= e^{VaR_q[X]}=\exp\{\Phi^{-1}(q)\ \sigma+\mu\}.
$$

</div>

*** 

We have thus far seen a number of examples about the *VaR* for continuous *rv*'s, let us consider an example concerning the *VaR* for a discrete *rv*.

<!-- \label{exm:discrete} -->
**Example `r chapnum`.2.4. *VaR* for a discrete random variable.**
Consider an insurance loss *rv* with the following probability distribution:
$$
\Pr[X=x]=\left\{
                  \begin{array}{ll}
                    1, & \hbox{with probability $0.75$;} \\
                    3, & \hbox{with probability $0.20$;} \\
                    4, & \hbox{with probability $0.05$.}
                  \end{array}
                \right.
$$
Determine the *VaR* at $q = 0.6, 0.9, 0.95, 0.95001$.

<h5 style="text-align: center;"><a id="displayTextExamplePortMgt.2.4" 
href="javascript:toggleEX('toggleExamplePortMgt.2.4','displayTextExamplePortMgt.2.4');"><i><strong>Show Example Solution</strong></i></a> </h5>
<div id="toggleExamplePortMgt.2.4" style="display: none">

**Solution.**


The corresponding *cdf* of $X$ is
$$
F_X(x)=\left\{
         \begin{array}{ll}
           0, & \hbox{ $x<1$;} \\
           0.75, & \hbox{ $1\leq x<3$;} \\
           0.95, & \hbox{ $3\leq x<4$;} \\
           1, & \hbox{ $4\leq x$.}
         \end{array}
       \right.
$$
By the definition of *VaR*, we thus have then

* *$VaR_{0.6}[X]=1$;*
* *$VaR_{0.9}[X]=3$;*
* *$VaR_{0.95}[X]=3$;*
* *$VaR_{0.950001}[X]=4$.*

</div>

*** 

Let us now conclude the current subsection by an open discussion of the *VaR* measure.  Some advantages of utilizing *VaR* include  

* possessing a practically meaningful interpretation;
* relatively simple to compute for many distributions with closed-form distribution functions;
* no additional assumption is required for the computation of *VaR*.

On the other hand, the limitations of *VaR* can be particularly pronounced for some risk management practices.  We report some of them herein:  

* the selection of the confidence level $q\in [0,1]$ is highly subjective, while the *VaR* can be very sensitive to the choice of $q$ (e.g., in Example `r chapnum`.9, $VaR_{0.95}[X]=3$ and $VaR_{0.950001}[X]=4$);
* the scenarios/loss information that are above the $(1-p)\times 100\%$ worst event, are completely neglected;
* *VaR* is not a coherent risk measure (specifically, the *VaR* measure does not satisfy the subadditivity axiom, meaning that diversification benefits may not be fully reflected).


### Tail Value-at-Risk

Recall that the *VaR* represents the $(1-p)\times100\%$ chance maximal loss.  As we mentioned in the previous section, one major drawback of the *VaR* measure is that it does not reflect the extremal losses occurring beyond the $(1-p)\times100\%$ chance worst scenario.  For an illustration purpose, let us consider the following slightly unrealistic yet inspiring example.  

**Example `r chapnum`.2.5.**
Consider two loss *rv*'s $X\sim Uniform [0,100]$, and $Y\sim Exp(31.71)$.  We use *VaR* at $95\%$ confidence level to measure the riskiness of $X$ and $Y$.  Simple calculation yields (see, also, Example `r chapnum`.6),
$$
VaR_{0.95}[X]=VaR_{0.95}[Y]=95,
$$
and thus these two loss distributions have the same level of risk according to $VaR_{0.95}$.  However, it is clear that $Y$ is riskier than $X$ if extremal losses are of major concern since $X$ is bounded above while $Y$ is unbounded. Simply quantifying risk by using *VaR* at a specific confidence level could be misleading and may not reflect the true nature of risk.

As a remedy, the *Tail Value-at-Risk* (*TVaR*) was proposed to measure the extremal losses that are above a given level of *VaR* as an average.  We document the definition of *TVaR* in what follows.  For the sake of simplicity, we are going to confine ourselves to continuous positive *rv*'s only, which are more frequently used in the context of insurance risk management.  We refer the interested reader to @hardy2006 for a more comprehensive discussion of *TVaR* for both discrete and continuous *rv*'s.

<!-- \label{def:TVaR}-->
**Definition  `r chapnum`.4.**
Fix $q\in [0,1]$, the Tail Value-at-Risk of a (continuous) *rv* $X$ is formulated as

\begin{eqnarray*}
  TVaR_q[X] &:=& \mathrm{E}[X|X>VaR_q[X]],
\end{eqnarray*}

given that the expectation exists.

In light of Definition  `r chapnum`.4, the computation of *TVaR* typically consists of two major components - the VaR and the average of losses that are above the VaR. The *TVaR* can be computed via  a number of formulas. Consider a continuous positive *rv*\ $X$, for notional convenience, henceforth let us write $\pi_q:=VaR_q[X]$. By definition, the *TVaR* can be computed via
<!-- \label{eqn:cte-pdf} -->

\begin{eqnarray}
TVaR_{q}[X]=\frac{1}{(1-q)}\int_{\pi_q}^{\infty}xf_X(x)dx.
(\#eq:cte-pdf)
\end{eqnarray}


**Example `r chapnum`.2.6. *TVaR* for a normal distribution.**
Consider an insurance loss *rv*\ $X\sim Normal (\mu,\sigma^2)$ with $\mu\in \mathbf{R}$ and $\sigma>0$. Give an expression for *TVaR*.

<h5 style="text-align: center;"><a id="displayTextExamplePortMgt.2.6" 
href="javascript:toggleEX('toggleExamplePortMgt.2.6','displayTextExamplePortMgt.2.6');"><i><strong>Show Example Solution</strong></i></a> </h5>
<div id="toggleExamplePortMgt.2.6" style="display: none">

**Solution.**

Let $Z$ be the standard normal *rv*. For $q\in[0,1]$, the *TVaR* of $X$ can be computed via

\begin{eqnarray*}
  TVaR_q[X] &=& \mathrm{E}[X|X>VaR_q[X]]\\
&=&\mathrm{E}[\sigma Z+\mu|\sigma Z+\mu>VaR_q[X]]\\
&=& \sigma\mathrm{E}[Z|Z>(VaR_q[X]-\mu)/\sigma]+\mu\\
&\overset{(1)}{=}& \sigma\mathrm{E}[Z|Z>VaR_q[Z]]+\mu,
\end{eqnarray*}

where `$\overset{(1)}{=}$' holds because of the results reported in Example `r chapnum`.7.  Next, we turn to study $TVaR_q[Z]=\mathrm{E}[Z|Z>VaR_q[Z]]$.  Let $\omega(q)=(\Phi^{-1}(q))^2/2$, we have

\begin{eqnarray*}
  (1-q)\ TVaR_q[Z] &=& \int_{\Phi^{-1}(q)}^{\infty} z \frac{1}{\sqrt{2\pi}} e^{-z^2/2}dz\\
&=& \int_{\omega(q)}^{\infty}  \frac{1}{\sqrt{2\pi}} e^{-x}dx\\
&=& \frac{1}{\sqrt{2\pi}} e^{-\omega(q)}\\
&=& \phi(\Phi^{-1}(q)).
\end{eqnarray*}

Thus,
$$
TVaR_q[X]=\sigma\frac{\phi(\Phi^{-1}(q))}{1-q}+\mu.
$$
</div>

*** 

We mentioned earlier in the previous subsection that the *VaR* of a strictly increasing function of *rv* is equal to the function of VaR of the original *rv*.  Motivated by the results in Example `r chapnum`.11, one can show that the *TVaR* of a strictly increasing linear transformation of *rv* is equal to the function of VaR of the original *rv*  This is due to the linearity property of expectations.  However, the aforementioned  finding cannot be extended to non-linear functions.  The following example of lognormal *rv* serves as a counter example.  

**Example `r chapnum`.2.7. *TVaR* of a lognormal distribution.**
Consider an insurance loss *rv*\ $X\sim lognormal (\mu,\sigma^2)$, with $\mu\in \mathbf{R}$ and $\sigma>0$. Show that

\begin{eqnarray*}
  TVaR_q[X] &=& \frac{e^{\mu+\sigma^2/2}}{(1-q)} \Phi(\Phi^{-1}(q)-\sigma).
\end{eqnarray*}

<h5 style="text-align: center;"><a id="displayTextExamplePortMgt.2.7" 
href="javascript:toggleEX('toggleExamplePortMgt.2.7','displayTextExamplePortMgt.2.7');"><i><strong>Show Example Solution</strong></i></a> </h5>
<div id="toggleExamplePortMgt.2.7" style="display: none">

**Solution.**

Recall that the *pdf* of lognormal distribution is formulated as
$$
f_X(x)=\frac{1}{\sigma\sqrt{2\pi} x}\exp\{-(\ln x-\mu )^2/2\sigma^2 \}, \text{ for } x>0.
$$
Fix $q\in[0,1]$, then the *TVaR* of $X$ can be computed via

<!-- \label{eqn:cte-normal} -->

\begin{eqnarray}
  TVaR_q[X] &=& \frac{1}{(1-q)} \int_{\pi_q}^{\infty} x f_X(x)dx \nonumber\\
&=&\frac{1}{(1-q)} \int_{\pi_q}^{\infty} \frac{1}{\sigma \sqrt{2\pi}} \exp\left\{ -\frac{(\log x-\mu)^2}{2\sigma^2}
\right\}dx\nonumber\\
&\overset{(1)}{=}&\frac{1}{(1-q)} \int_{\omega(q)}^{\infty} \frac{1}{\sqrt{2\pi}} e^{ -\frac{1}{2}w^2+\sigma w+\mu}dw\nonumber\\
&=&\frac{e^{\mu+\sigma^2/2}}{(1-q)} \int_{\omega(q)}^{\infty} \frac{1}{\sqrt{2\pi}} e^{ -\frac{1}{2}(w-\sigma)^2}dw\nonumber\\
&=&\frac{e^{\mu+\sigma^2/2}}{(1-q)} \Phi(\omega(q)-\sigma),
(\#eq:cte-normal)
\end{eqnarray}

where `$\overset{(1)}{=}$' holds by applying change of variable $w=(\log x-\mu)/\sigma$, and $\omega(q)=(\log \pi_q-\mu)/\sigma$.  Evoking the formula of VaR for lognormal *rv*\ reported in Example  `r chapnum`.7, we can simplify the expression \@ref(eq:cte-normal) into

\begin{eqnarray*}
  TVaR_q[X] &=& \frac{e^{\mu+\sigma^2/2}}{(1-q)} \Phi(\Phi^{-1}(q)-\sigma).
\end{eqnarray*}

</div>

*** 

Clearly, the *TVaR* of lognormal *rv* is not the exponential of the *TVaR* of normal *rv*.

For distributions of which the distribution functions are more tractable to work with, we may apply integration by parts technique to rewrite equation \@ref(eq:cte-pdf) as

\begin{eqnarray*}
TVaR_{q}[X]&=&\left[-x S_X(x)\big |_{\pi_q}^{\infty}+\int_{\pi_q}^{\infty}S_X(x)dx\right]\frac{1}{(1-q)}\\
&=& \pi_q +\frac{1}{(1-q)}\int_{\pi_q}^{\infty}S_X(x)dx.
\end{eqnarray*}


**Example  `r chapnum`.2.8. *TVaR* of an exponential distribution.**
Consider an insurance loss *rv*\ $X\sim Exp(\theta)$ for $\theta>0$. Give an expression for the *TVaR*.

<h5 style="text-align: center;"><a id="displayTextExamplePortMgt.2.8" 
href="javascript:toggleEX('toggleExamplePortMgt.2.8','displayTextExamplePortMgt.2.8');"><i><strong>Show Example Solution</strong></i></a> </h5>
<div id="toggleExamplePortMgt.2.8" style="display: none">

**Solution.**

We have seen from the previous subsection that
$$
\pi_q=-\theta[\log(1-q)].
$$
Let us now consider the *TVaR*:

\begin{eqnarray*}
  TVaR_q[X] &=& \pi_q+\int_{\pi_q}^{\infty} e^{-x/\theta}dx/(1-q)\\
&=& \pi_q+\theta e^{-\pi_q/\theta}/(1-q)\\
&=& \pi_q+\theta.
\end{eqnarray*}

</div>

*** 

It can also be helpful to express the *TVaR* in terms of limited expected values.  Specifically, we have


\begin{eqnarray}
  TVaR_q[X] &=& \int_{\pi_q}^{\infty} (x-\pi_q+\pi_q)f_X(x)dx/(1-q) \nonumber\\
&=& \pi_q+\frac{1}{(1-q)}\int_{\pi_q}^{\infty} (x-\pi_q)f_X(x)dx\nonumber\\
&=& \pi_q+e_X(\pi_q)\nonumber\\
&=& \pi_q +\frac{\left({\mathrm{E}[X]-\mathrm{E}[X\wedge\pi_q]}\right)}{(1-q)},
(\#eq:cte-expectation)
\end{eqnarray}
where $e_X(d):=\mathrm{E}[X-d|X>d]$ for $d>0$ denotes the *mean excess loss function*. For many commonly used parametric distributions, the formulas for calculating $\mathrm{E}[X]$ and $\mathrm{E}[X\wedge\pi_q]$ can be found in a table of distributions.


**Example  `r chapnum`.2.9. *TVaR* of the Pareto distribution.**
Consider a loss *rv*\ $X\sim Pareto(\theta,\alpha)$ with $\theta>0$ and $\alpha>0$.  The *cdf*\ of $X$ is given by
$$
F_X(x)=1-\left(\frac{\theta}{\theta+x} \right)^{\alpha}, \text{ for } x>0 .
$$ 

Fix $q\in [0,1]$ and set $F_X(\pi_q)=q$, we readily obtain
<!-- \label{eqn:var-pareto} -->

\begin{eqnarray}
\pi_q=\theta\left[(1-q)^{-1/\alpha}-1 \right].
(\#eq:var-pareto)
\end{eqnarray}
According to the distribution table provided in the SOA exam C, we know
$$
\mathrm{E}[X]=\frac{\theta}{\alpha-1},
$$
and 
$$
\mathrm{E}[X\wedge \pi_q]=\frac{\theta}{\alpha-1}\left[
1-\left(\frac{\theta}{\theta+\pi_q}\right)^{\alpha-1}
\right].
$$
Evoking equation \@ref(eq:cte-expectation) yields

\begin{eqnarray*}
  TVaR_q[X] &=& \pi_q+\frac{\theta}{\alpha-1} \frac{(\theta/(\theta+\pi_q))^{\alpha-1}}
{(\theta/(\theta+\pi_q))^{\alpha}}\\
&=&\pi_q +\frac{\theta}{\alpha-1}\left( \frac{\pi_q+\theta}{\theta} \right)\\
&=& \pi_q+\frac{\pi_q+\theta}{\alpha-1},
\end{eqnarray*}

where $\pi_q$ is given by \@ref(eq:var-pareto).  

Via a change of variables, we can also rewrite equation \@ref(eq:cte-pdf) as


\begin{eqnarray}
  TVaR_{q}[X] &=& \frac{1}{(1-q)}\int_{q}^{1} VaR_{\alpha}[X]\ d\alpha.
  (\#eq:cte-var)
\end{eqnarray}
What this alternative formula \@ref(eq:cte-var) tells is that *TVaR* in fact is the average of $VaR_{\alpha}[X]$ with varying degree of confidence level over $\alpha\in [q,1]$.  Therefore, the *TVaR* effectively resolves most of the limitations of *VaR* outlined in the previous subsection.  First, due to the averaging effect, the *TVaR* may be less sensitive to the change of confidence level compared with *VaR*.  Second, all the extremal losses that are above the $(1-q)\times 100\%$ worst probable event are taken in account.

In this respect, it is a simple matter for us to see that for any given $q\in [0,1]$ 
$$
TVaR_q[X]\geq VaR_q[X].
$$
Third and perhaps foremost, *TVaR* is a coherent risk measure and thus is able to more accurately capture the diversification effects of insurance portfolio.  Herein, we do not intend to provide  the proof of the coherent feature for *TVaR*, which is considered to be challenging technically.


##Reinsurance {#S:Reinsurance}

Recall that *reinsurance* is simply insurance purchased by an insurer. Insurance purchased by non-insurers is sometimes known as *primary* insurance to distinguish it from reinsurance. Reinsurance differs from personal insurance purchased by individuals, such as auto and homeowners insurance, in contract flexibility. Like insurance purchased by major corporations, reinsurance programs are generally tailored more closely to the buyer. For contrast, in personal insurance buyers typically cannot negotiate on the contract terms although they may have a variety of different options (contracts) from which to choose.

The two broad types are *proportional* and *non-proportional* reinsurance. A proportional reinsurance contract is an agreement between a reinsurer and a *ceding* company (also known as the *reinsured*) in which the reinsurer assumes a given percent of losses and premium. A reinsurance contract is also known as a *treaty*. Non-proportional agreements are simply everything else. As examples of non-proportional agreements, this chapter focuses on *stop-loss* and *excess of loss* contracts. For all types of agreements, we split the total risk $S$ into the portion taken on by the reinsurer, $Y_{reinsurer}$, and that retained by the insurer, $Y_{insurer}$, that is, $S= Y_{insurer}+Y_{reinsurer}$.

The mathematical structure of a basic reinsurance treaty is the same as the coverage modifications of personal insurance introduced in Chapter 3. For a proportional reinsurance, the transformation $Y_{insurer} = c S$ is identical to a coinsurance adjustment in personal insurance. For stop-loss reinsurance, the transformation $Y_{reinsurer} = \max(0,S-M)$ is the same as an insurer's payment with a deductible $M$ and $Y_{insurer} = \min(S,M) = S \wedge M$ is equivalent to what a policyholder pays with deductible $M$. For practical applications of the mathematics, in personal insurance the focus is generally upon the expectation as this is a key ingredient used in pricing. In contrast, for reinsurance the focus is on the entire distribution of the risk, as the extreme events are a primary concern of the financial stability of the insurer and reinsurer.

This chapter describes the foundational and most basic of reinsurance treaties: Section \@ref(S:ProportionalRe) for proportional and Section \@ref(S:NonProportionalRe) for non-proportional reinsurance. Section \@ref(S:AdditionalRe) gives a flavor of more complex contracts.


### Proportional Reinsurance {#S:ProportionalRe}

The simplest example of a proportional treaty is called *quota share*.

-   In a quota share treaty, the reinsurer receives a flat percent, say 50%, of the premium for the book of business reinsured.

-   In exchange, the reinsurer pays 50% of losses, including allocated loss adjustment expenses

-   The reinsurer also pays the ceding company a ceding commission which is designed to reflect the differences in underwriting expenses incurred.
        
The amounts paid by the direct insurer and the reinsurer are summarized as
$$
Y_{insurer} = c S \ \ \text{and} \ \ \ Y_{reinsurer} = (1-c) S,
$$
where $c\in [0,1]$ denotes the proportion retained by the insurer.
Note that $Y_{insurer}+Y_{reinsurer}=S$.

**Example `r chapnum`.3.1. Distribution of losses under quota share.** To develop an intuition for the effect of quota-share agreement on the distribution of losses, the following is a short `R` demonstration using simulation. Note the relative shapes of the distributions of total losses, the retained portion (of the insurer), and the reinsurer's portion.

```{r comment="", message=FALSE, echo=FALSE, fig.width=10, fig.height=4, fig.align='center'}
set.seed(2018)
theta = 1000
alpha = 3
nSim = 10000
library(actuar)
S <-  rpareto(nSim, shape = alpha, scale = theta)

par(mfrow=c(1,3))
plot(density(S), xlim=c(0,3*theta), main="Total Loss", xlab="Losses")
plot(density(0.75*S), xlim=c(0,3*theta), main="Insurer (75%)", xlab="Losses")
plot(density(0.25*S), xlim=c(0,3*theta), main="Reinsurer (25%)", xlab="Losses")
```


<h6 style="text-align: center;"><a id="displayQuotaShare" href="javascript:togglecode('toggleQuotaShare','displayQuotaShare');"><i><strong>Show the R Code</strong></i></a> </h6>
<div id="toggleQuotaShare" style="display: none">

```{r comment="", message=FALSE, eval=FALSE, fig.width=10, fig.height=4, fig.align='center'}
set.seed(2018)
theta = 1000
alpha = 3
nSim = 10000
library(actuar)
S <-  rpareto(nSim, shape = alpha, scale = theta)

par(mfrow=c(1,3))
plot(density(S), xlim=c(0,3*theta), main="Total Loss", xlab="Losses")
plot(density(0.75*S), xlim=c(0,3*theta), main="Insurer (75%)", xlab="Losses")
plot(density(0.25*S), xlim=c(0,3*theta), main="Reinsurer (25%)", xlab="Losses")
```


</div>

#### Quota Share is Desirable for Reinsurers

The quota share contract is particularly desirable for the reinsurer. To see this, suppose that an insurer and reinsurer wish to enter a contract to share total losses $S$ such that $$Y_{insurer}=g(S) \ \ \ \text{and} \ \ \ \ Y_{reinsurer}=S-g(S),$$
for some generic function $g(\cdot)$ (known as the *retention* function). Suppose further that the insurer only cares about the variability of retained claims and is indifferent to the choice of $g$ as long as $Var(Y_{insurer})$ stays the same and equals, say, $Q$. Then, the following result shows that the quota share reinsurance treaty minimizes the reinsurer's uncertainty as measured by $Var(Y_{reinsurer})$.

**Proposition**. Suppose that $Var(Y_{insurer})=Q.$ Then, $Var ((1-c)S) \le Var(g(S))$ for all $g(.)$, where $c=Q/Var(S)$.

<h6 style="text-align: center;"><a id="displayProof" href="javascript:togglecode('toggleProof','displayProof');"><i><strong>Show the Justification of the Proposition</strong></i></a> </h6>
<div id="toggleProof" style="display: none">

**Proof of the Proposition**. With $Y_{reinsurer} = S - Y_{insurer}$ and the law of total variation

$$
\begin{array}{ll}
Var (Y_{reinsurer}) &= Var (S-Y_{insurer}) \\
&= Var (S) + Var (Y_{insurer})  - 2 Cov (S,Y_{insurer}) \\
&=Var (S) + Q - 2 Corr (S,Y_{insurer}) \times \sqrt{Q} \sqrt{Var (S)}
\end{array}
$$
In this expression, we see that $Q$ and $Var(S)$ do not change with the choice of $g$. Thus, we can minimize $Var (Y_{reinsurer})$ by maximizing the correlation $Corr (S,Y_{insurer})$. If we use a quota share reinsurance agreement, then $Corr (S,Y_{insurer})=Corr (S,(1-c)S)=1$, the maximum possible correlation. This establishes the proposition.
<p style="text-align:right;">$\Box$`</p>
</div>

The proposition is intuitively appealing - with quota share insurance, the reinsurer shares the responsibility for very large claims in the tail of the distribution. This is in contrast to non-proportional agreements where reinsurers take responsibility for the very large claims.

#### Optimizing Quota Share Agreements for Insurers

Now assume $n$ risks in the porfolio, $X_1, \ldots, X_n,$ so that the portfolio sum is $S= X_1 + \cdots + X_n$. For simplicity, we focus on the case of independent risks. Let us consider a variation of the basic quota share agreement where the amount retained by the insurer may vary with each risk, say $c_i$. Thus, the insurer's portion of the portfolio risk is $Y_{insurer} = \sum_{i=1}^n c_i X_i$. What is the best choice of the proportions $c_i$?

To formalize this question, we seek to find those values of $c_i$ that minimize $Var  (Y_{insurer})$ subject to the constraint that $E (Y_{insurer}) = K.$ The requirement that $E (Y_{insurer}) = K$ suggests that the insurers wishes to retain a revenue in at least the amount of the constant $K$. Subject to this revenue constraint, the insurer wishes to minimize the uncertainty of the retained risks as measured by the variance.

<h6 style="text-align: center;"><a id="displayDerivationProof" href="javascript:togglecode('toggleDerivationProof','displayDerivationProof');"><i><strong>Show the Optimal Retention Proportions</strong></i></a> </h6>
<div id="toggleDerivationProof" style="display: none">

**The Optimal Retention Proportions**

Minimizing $Var(Y_{insurer})$ subject to  $E(Y_{insurer}) = K$ is a constrained optimization problem - we can use the method of Lagrange multipliers, a calculus technique, to solve this. To this end, define the Lagrangian

$$
\begin{array}{ll}
L &= Var (Y_{insurer}) - \lambda (E (Y_{insurer}) - K) \\
&= \sum_{i=1}^n c_i^2 ~Var(X_i) - \lambda (\sum_{i=1}^n c_i ~E(X_i) - K) 
\end{array}
$$
Taking a partial derivative with respect to $\lambda$ and setting this equal to zero simply means that the constraint, $E(Y_{insurer}) = K$, is enforced and we have to choose the proportions $c_i$ to satisfy this constraint. Moreover, taking the partial derivative with respect to each proportion $c_i$ yields
$$
\frac{\partial}{\partial c_i} L = 2 c_i ~Var(X_i) - \lambda ~E(X_i) = 0 
$$

so that

$$
c_i  =  \frac{\lambda}{2} \frac{E(X_i)}{Var(X_i)} .
$$
</div>

From the math, it turns out that the constant for the $i$th risk, $c_i$ is proportional to $\frac{E(X_i)}{Var (X_i)}$. This is intuitively appealing. Other things being equal, a higher revenue as measured by $E (X_i)$ means a higher value of $c_i$. In the same way, a higher value of uncertainty as measured by $Var(X_i)$ means a lower value of $c_i$. The proportional scaling factor is determined by the revenue requirement $E(Y_{insurer}) = K$. The following example helps to develop a feel for this relationship.

**Example `r chapnum`.3.2. Three Pareto risks.** Consider three risks that have a Pareto distribution. Provide a graph, and supporting code, that give values of $c_1$, $c_2$, and $c_3$ for a required revenue $K$. Note that these values increase linearly with $K$.

<h6 style="text-align: center;"><a id="displayParetoRisksProp" href="javascript:togglecode('toggleParetoRisksProp','displayParetoRisksProp');"><i><strong>Show an Example with Three Pareto Risks</strong></i></a> </h6>
<div id="toggleParetoRisksProp" style="display: none">


```{r comment="", message=FALSE,  fig.width=8, fig.height=4, fig.align='center'}


theta1 = 1000;theta2 = 2000;theta3 = 3000;
alpha1 = 3;alpha2 = 3;alpha3 = 4;
library(actuar)
propnfct <- function(alpha,theta){
  mu    <- mpareto(shape=alpha, scale=theta, order=1)
  var   <- mpareto(shape=alpha, scale=theta, order=2) - mu^2
  ratio <- mu/var
  ratio
}
c1 <- propnfct(alpha1, theta1)
c2 <- propnfct(alpha2, theta2)
c3 <- propnfct(alpha3, theta3)
summeans = mpareto(shape=alpha1, scale=theta1, order=1)+
           mpareto(shape=alpha2, scale=theta2, order=1)+
           mpareto(shape=alpha3, scale=theta3, order=1)  
temp = c1*mpareto(shape=alpha1, scale=theta1, order=1)+
       c2*mpareto(shape=alpha2, scale=theta2, order=1)+
       c3*mpareto(shape=alpha3, scale=theta3, order=1)  
KVec = seq(100,summeans,length.out=20)
c1Vec <- c2Vec <-c3Vec <- 0*KVec 
for (j in 1:20) {
  c1Vec[j] = c1 * KVec[j]/temp
  c2Vec[j] = c2 * KVec[j]/temp
  c3Vec[j] = c3 * KVec[j]/temp
  }
plot(KVec,c1Vec, type="l", ylab="proportion", xlab="required revenue", ylim=c(0,1))
lines(KVec,c2Vec)
lines(KVec,c3Vec)
text(1200,.8,expression(c[1]))
text(2000,.75,expression(c[2]))
text(1500,.3,expression(c[3]))

```

</div>

### Non-Proportional Reinsurance {#S:NonProportionalRe}

####The Optimality of Stop Loss Insurance

Under a **stop loss** arrangement, the insurer sets a retention level $M (>0)$ and pays in full total claims for which $S  \le M$. Further, for claims for which $S > M$, the direct insurer pays $M$ and the reinsurer pays the remaining amount $S-M$. Thus, the insurer retains an amount $M$ of the risk. Summarizing, the amounts paid by the direct insurer and the reinsurer are
    
$$
Y_{insurer} =
\begin{cases}
S & \text{for } S \le M\\
M & \text{for } S >M \\
\end{cases} \ \ \ \ = \min(S,M) = S \wedge M
$$

and

$$
Y_{reinsurer} =
\begin{cases}
0 & \text{for } S \le M\\
S- M &  \text{for } S >M \\
\end{cases} \ \ \ \  = \max(0,S-M) .
$$

As before, note that $Y_{insurer}+Y_{reinsurer}=S$.

The stop loss type of contract is particularly desirable for the insurer. Similar to earlier, suppose that an insurer and reinsurer wish to enter a contract so that $Y_{insurer}=g(S)$ and $Y_{reinsurer}=S-g(S)$ for some generic retention function $g(\cdot)$. Suppose further that the insurer only cares about the variability of retained claims and is indifferent to the choice of $g$ as long as $Var(Y_{insurer})$ can be minimized. Again, we impose the constraint that $E(Y_{insurer}) = K$; the insurer needs to retain a revenue $K$. Subject to this revenue constraint, the insurer wishes to minimize uncertainty of the retained risks (as measured by the variance). Then, the following result shows that the stop loss reinsurance treaty minimizes the reinsurer's uncertainty as measured by $Var(Y_{reinsurer})$.


**Proposition**. Suppose that $E(Y_{insurer})=K.$ Then, $Var (S \wedge M) \le Var(g(S))$ for all $g(.)$, where $M$ is such that $E(S \wedge M)=K$.

<h6 style="text-align: center;"><a id="displayProofStopLoss" href="javascript:togglecode('toggleProofStopLoss','displayProofStopLoss');"><i><strong>Show the Justification of the Proposition</strong></i></a> </h6>
<div id="toggleProofStopLoss" style="display: none">

**Proof of the Proposition**. Add and subtract a constant $M$ and expand the square to get
$$
\begin{array}{ll}
Var(g(S)) &= E (g(S) - K)^2 = E (g(S) -M +M- K)^2 \\
&= E (g(S) -M)^2 +  (M- K)^2 +2 E (g(S) -M)(M- K) \\
&= E (g(S) -M)^2 -  (M- K)^2 ,
\end{array}
$$
because $E(g(S))= K.$

Now, for any retention function, we have $g(S) \le S$, that is, the insurer's retained claims are less than or equal to total claims. Using the notation $g_{SL}(S) = S \wedge M$ for stop loss insurance, we have

$$
\begin{array}{ll}
M- g_{SL}(S) &= M-(S \wedge M) \\
&= (M-S) \wedge 0 \\
&\le (M-g(S)) \wedge 0 .
\end{array}
$$
Squaring each side yields 
$$(M- g_{SL}(S))^2 \le (M-g(S))^2 \wedge 0 \le (M-g(S))^2.$$

Returning to our expression for the variance, we have
$$
\begin{array}{ll}
Var(g_{SL}(S)) &= E (g_{SL}(S) -M)^2 -  (M- K)^2 \\
&\le E (g(S) -M)^2 -  (M- K)^2 = Var(g(S)) ,
\end{array}
$$
for any retention function $g$. This establishes the proposition.
<p style="text-align:right;">$\Box$`</p>

</div>

The proposition is intuitively appealing - with stop loss insurance, the reinsurer takes the responsibility for very large claims in the tail of the distribution, not the insurer. 

#### Excess of Loss

A closely related form of non-proportional reinsurance is the **excess of loss** coverage. Under this contract, we assume that the total risk $S$ can be thought of as composed as $n$ separate risks $X_1, \ldots, X_n$ and that each of these risks are subject to an upper limit, say, $M_i$. So the insurer retains

$$
Y_{i,insurer} = X_i \wedge M_i \ \ \ \ Y_{insurer} = \sum_{i=1}^n Y_{i,insurer}
$$
and the reinsurer is responsible for the excess, $Y_{reinsurer}=S - Y_{insurer}$. The retention limits may vary by risk or may be the same for all risks, $M_i =M$, for all $i$.

####Optimal Choice for Excess of Loss Retention Limits

What is the best choice of the excess of loss retention limits $M_i$? To formalize this question, we seek to find those values of $M_i$ that minimize $Var(Y_{insurer})$ subject to the constraint that $E(Y_{insurer}) = K.$ Subject to this revenue constraint, the insurer wishes to minimize the uncertainty of the retained risks (as measured by the variance).

<h6 style="text-align: center;"><a id="displayDerivationProofExcess" href="javascript:togglecode('toggleDerivationProofExcess','displayDerivationProofExcess');"><i><strong>Show the Optimal Retention Proportions</strong></i></a> </h6>
<div id="toggleDerivationProofExcess" style="display: none">

**The Optimal Retention Limits**

Minimizing $Var(Y_{insurer})$ subject to  $E(Y_{insurer}) = K$ is a constrained optimization problem - we can use the method of Lagrange multipliers, a calculus technique, to solve this. As before, define the Lagrangian
$$
\begin{array}{ll}
L &= Var (Y_{insurer}) - \lambda (E(Y_{insurer}) - K) \\
&= \sum_{i=1}^n ~Var (X_i \wedge M_i) - \lambda (\sum_{i=1}^n ~E(X_i \wedge M_i)- K).
\end{array}
$$

We first recall the relationships

$$
E(S \wedge M) = \int_0^M ~(1- F(S))dx
$$
and

$$
E(S \wedge M)^2 = 2\int_0^M ~x(1- F(x))dx.
$$

Taking a partial derivative with respect to $\lambda$ and setting this equal to zero simply means that the constraint, $E(Y_{insurer}) = K$, is enforced and we have to choose the limits $M_i$ to satisfy this constraint. Moreover, taking the partial derivative with respect to each limit $M_i$ yields

$$
\begin{array}{ll}
\frac{\partial}{\partial M_i} L 
&= \frac{\partial}{\partial M_i}  ~Var(X_i \wedge M_i)  - \lambda \frac{\partial}{\partial M_i} ~E(X_i \wedge M_i) \\
&= \frac{\partial}{\partial M_i} \left(E(X_i \wedge M_i)^2 -(E(X_i \wedge M_i))^2\right) - \lambda (1-F_i(M_i)) \\
&= 2 M_i (1-F_i(M_i)) - 2 E(X_i \wedge M_i) (1-F_i(M_i))-
\lambda (1-F_i(M_i)).
\end{array}
$$

Setting $\frac{\partial}{\partial M_i} L =0$ and solving for $\lambda$, we get

$$
\lambda = 2 (M_i - E(X_i \wedge M_i)) .
$$
</div>

From the math, it turns out that the retention limit less the expected insurer's claims, $M_i - E(X_i \wedge M_i)$, is the same for *all* risks. This is intuitively appealing.


**Example `r chapnum`.3.3. Excess of loss for three Pareto risks.** Consider three risks that have a Pareto distribution, each having a different set of parameters (so they are independent but non-identical). Show numerically that the optimal retention limits $M_1$, $M_2$, and $M_3$ resulting retention limit minus expected insurer's claims, $M_i - E(X_i \wedge M_i)$, is the same for all risks, as we derived theoretically. Further, graphically compare the distribution of total risks to that retained by the insurer and by the reinsurer.

<h6 style="text-align: center;"><a id="displayParetoRisksExcess" href="javascript:togglecode('toggleParetoRisksExcess','displayParetoRisksExcess');"><i><strong>Show an Example with Three Pareto Risks</strong></i></a> </h6>
<div id="toggleParetoRisksExcess" style="display: none">


We first optimize the Lagrangian using the `R` package `alabama` for *Augmented Lagrangian Adaptive Barrier Minimization Algorithm*. 


```{r comment="", message=FALSE, warning=FALSE, fig.width=8, fig.height=4, fig.align='center'}

theta1 = 1000;theta2 = 2000;theta3 = 3000;
alpha1 = 3;   alpha2 = 3;   alpha3 = 4;
Pmin <- 2000
library(actuar)
VarFct <- function(M){
  M1=M[1];M2=M[2];M3=M[3]
  mu1    <- levpareto(limit=M1,shape=alpha1, scale=theta1, order=1)
  var1   <- levpareto(limit=M1,shape=alpha1, scale=theta1, order=2)-mu1^2
  mu2    <- levpareto(limit=M2,shape=alpha2, scale=theta2, order=1)
  var2   <- levpareto(limit=M2,shape=alpha2, scale=theta2, order=2)-mu2^2
  mu3    <- levpareto(limit=M3,shape=alpha3, scale=theta3, order=1)
  var3   <- levpareto(limit=M3,shape=alpha3, scale=theta3, order=2)-mu3^2
  varFct <- var1 +var2+var3
  meanFct <- mu1+mu2+mu3
  c(meanFct,varFct)
  }
f <- function(M){VarFct(M)[2]}
h <- function(M){VarFct(M)[1] - Pmin}
library(alabama)
par0=rep(1000,3)
op <- auglag(par=par0,fn=f,hin=h,control.outer=list(trace=FALSE))
```


The optimal retention limits $M_1$, $M_2$, and $M_3$ resulting retention limit minus expected insurer's claims, $M_i - E(X_i \wedge M_i)$, is the same for all risks, as we derived theoretically. 

```{r comment="", message=FALSE, warning=FALSE, fig.width=8, fig.height=4, fig.align='center'}

M1star = op$par[1];M2star = op$par[2];M3star = op$par[3]
M1star -levpareto(M1star,shape=alpha1, scale=theta1,order=1)
M2star -levpareto(M2star,shape=alpha2, scale=theta2,order=1)
M3star -levpareto(M3star,shape=alpha3, scale=theta3,order=1)
```

We graphically compare the distribution of total risks to that retained by the insurer and by the reinsurer.

```{r comment="", message=FALSE, warning=FALSE, fig.width=8, fig.height=4, fig.align='center'}
set.seed(2018)
nSim = 10000
library(actuar)
Y1 <- rpareto(nSim, shape = alpha1, scale = theta1)
Y2 <- rpareto(nSim, shape = alpha2, scale = theta2)
Y3 <- rpareto(nSim, shape = alpha3, scale = theta3)
YTotal <- Y1 + Y2 + Y3
Yinsur <-  pmin(Y1,M1star)+pmin(Y2,M2star)+pmin(Y3,M3star)
Yreinsur <- YTotal - Yinsur

par(mfrow=c(1,3))
plot(density(YTotal),   xlim=c(0,10000), main="Total Loss", xlab="Losses")
plot(density(Yinsur),   xlim=c(0,10000), main="Insurer",    xlab="Losses")
plot(density(Yreinsur), xlim=c(0,10000), main="Reinsurer",  xlab="Losses")
```

</div>

***

### Additional Reinsurance Treaties  {#S:AdditionalRe}

#### Surplus Share Proportional Treaty

Another proportional treaty is known as **surplus share**; this type of contract is common in commercial property insurance.

-   A surplus share treaty allows the reinsured to limit its exposure on any one risk to a given amount (the *retained line*).
-   The reinsurer assumes a part of the risk in proportion to the amount that the insured value exceeds the retained line, up to a given
    limit (expressed as a multiple of the retained line, or number of lines).

For example, let the retained line be \$100,000 and the given limit be 4 lines (\$400,000). Then, if $S$ is the loss, the reinsurer's portion is $\min(400000, (S-100000)_+)$.


#### Layers of Coverage

One can also extend non-proportional stop loss treaties by introducing additional parties to the contract. For example, instead of simply an insurer and reinsurer or an insurer and a policyholder, think about the situation with all three parties, a policyholder, insurer, and reinsurer, who agree on how to share a risk. More generally, we consider $k$ parties. If $k=4$, it could be an insurer and three different reinsurers.


**Example `r chapnum`.3.4. Layers of coverage for three parties.**

-   Suppose that there are $k=3$ parties. The first party is responsible for the first 100 of claims, the second responsible for claims from 100 to 3000, and the third responsible for claims above 3000.

-   If there are four claims in the amounts 50, 600, 1800 and 4000, then they would be allocated to the parties as follows:

  Layer               Claim 1   Claim 2   Claim 3   Claim 4  Total
  ------------------ --------- --------- --------- --------- -------
  (0, 100\]             50        100       100       100    350
  (100, 3000\]           0        500      1700      2900    5100
  (3000, $\infty$)       0         0         0       1000    1000
  Total                 50        600      1800      4000    6450


***

To handle the general situation with $k$ groups, partition the positive real line into $k$ intervals using the cut-points
$$0 = M_0 < M_1 < \cdots < M_{k-1} < M_k = \infty.$$

Note that the $j$th interval is $(M_{j-1}, M_j]$. Now let $Y_j$ be the amount of risk shared by the $j$th party. To illustrate, if a loss $x$ is such that $M_{j-1} <x \le M_j$, then
$$\left(\begin{array}{c}
    Y_1\\ Y_2 \\ \vdots \\ Y_j \\Y_{j+1} \\ \vdots \\Y_k
    \end{array}\right)
    =\left(\begin{array}{c}
    M_1-M_0 \\ M_2-M_1  \\ \vdots \\ x-M_{j-1}  \\ 0 \\ \vdots \\0
    \end{array}\right)$$

More succinctly, we can write
    $$Y_j = \min(S,M_j) - \min(S,M_{j-1}) .$$

With the expression $Y_j = \min(S,M_j) - \min(S,M_{j-1})$, we see that the $j$th party is responsible for claims in the interval  $(M_{j-1}, M_j].$ With this, it is easy to check that $S = Y_1 + Y_2 + \cdots + Y_k.$ As emphasized in the following example, we also remark that the parties need not be different.


**Example `r chapnum`.3.5.**
-   Suppose that a policyholder is responsible for the
        first 500 of claims and all claims in excess of 100,000. The
        insurer takes claims between 100 and 100,000.
-   Then, we would use $M_1 = 100$, $M_2 =100000$.
-   The policyholder is responsible for $Y_1 =\min(S,100)$ and
        $Y_3 = S - \min(S,100000) = \max(0, S-100000)$.


For additional reading, see the [Wisconsin Property Fund site](https://sites.google.com/a/wisc.edu/local-government-property-insurance-fund/home/reinsurance) for more info on layers of reinsurance.
    

####Portfolio Management Example

Many other variations of the foundational contracts are possible. For one more illustration, consider the following.


```{r warning=FALSE, message=FALSE, comment="", echo=FALSE}
# For the gamma distributions, use
alpha1 <- 2;      theta1 <- 100
alpha2 <- 2;      theta2 <- 200
# For the Pareto distributions, use
alpha3 <- 2;      theta3 <- 1000
alpha4 <- 3;      theta4 <- 2000
# Deductibles
M1 <- 100
M2 <- 200
```

**Example. `r chapnum`.3.6. Portfolio management.** You are the Chief Risk Officer of a telecommunications firm. Your firm has several property and liability risks. We will consider:

- $X_1$ - buildings, modeled using a gamma distribution with mean `r alpha1*theta1` and scale parameter `r theta1`.
- $X_2$ - motor vehicles, modeled using a gamma distribution with mean `r alpha2*theta2` and scale parameter `r theta2`.
- $X_3$ - directors and executive officers risk, modeled using a Pareto distribution with mean `r round(theta3/(alpha3-1),digits=8)` and scale parameter `r theta3`.
- $X_4$ - cyber risks, modeled using a Pareto distribution with mean `r theta4/(alpha4-1)` and scale parameter `r theta4`.

Denote the total risk as $$S = X_1 + X_2 + X_3 + X_4 .$$

For simplicity, you assume that these risks are independent. 

To manage the risk, you seek some insurance protection. You wish to manage internally small building and motor vehicles amounts, up to $M_1$ and $M_2$, respectively. You seek insurance to cover all other risks. Specifically, the insurer's portion is
$$ Y_{insurer} = (X_1 - M_1)_+ + (X_2 - M_2)_+ + X_3 + X_4 ,$$
so that your retained risk is $Y_{retained}= S- Y_{insurer} = \min(X_1,M_1) +  \min(X_2,M_2)$. Using deductibles $M_1=$ `r M1` and $M_2=$ `r M2`:

a. Determine the expected claim amount of (i) that retained, (ii) that accepted by the insurer, and (iii) the total overall amount.
b. Determine the 80th, 90th, 95th, and 99th percentiles for (i) that retained, (ii) that accepted by the insurer, and (iii) the total overall amount. 
c. Compare the distributions by plotting the densities for (i) that retained, (ii) that accepted by the insurer, and (iii) the total overall amount.


<h6 style="text-align: center;"><a id="displayPortMgtExample" href="javascript:togglecode('togglePortMgtExample','displayPortMgtExample');"><i><strong>Show Example Solution with R Code</strong></i></a> </h6>
<div id="togglePortMgtExample" style="display: none">

In preparation, here is the code needed to set the parameters.

```{r warning=FALSE, message=FALSE, comment="", eval=FALSE}
# For the gamma distributions, use
alpha1 <- 2;      theta1 <- 100
alpha2 <- 2;      theta2 <- 200
# For the Pareto distributions, use
alpha3 <- 2;      theta3 <- 1000
alpha4 <- 3;      theta4 <- 2000
# Limits
M1     <- 100
M2     <- 200
```

With these parameters, we can now simulate realizations of the portfolio risks.

```{r warning=FALSE, message=FALSE, fig.width=8, fig.height=4, fig.align='center', comment=""}
# Simulate the risks
nSim <- 10000  #number of simulations
set.seed(2017) #set seed to reproduce work 
X1 <- rgamma(nSim,alpha1,scale = theta1)  
X2 <- rgamma(nSim,alpha2,scale = theta2)  
# For the Pareto Distribution, use
library(actuar)
X3 <- rpareto(nSim,scale=theta3,shape=alpha3)
X4 <- rpareto(nSim,scale=theta4,shape=alpha4)
# Portfolio Risks
S         <- X1 + X2 + X3 + X4
Yretained <- pmin(X1,M1) + pmin(X2,M2)
Yinsurer  <- S - Yretained
```

**(a)** Here is the code for the expected claim amounts.

```{r warning=FALSE, message=FALSE, fig.width=8, fig.height=4, fig.align='center', comment=""}
# Expected Claim Amounts
ExpVec <- t(as.matrix(c(mean(Yretained),mean(Yinsurer),mean(S))))
colnames(ExpVec) <- c("Retained", "Insurer","Total")
round(ExpVec,digits=2)
```

**(b)** Here is the code for the quantiles.

```{r warning=FALSE, message=FALSE, fig.width=8, fig.height=4, fig.align='center', comment=""}
# Quantiles
quantMat <- rbind(
  quantile(Yretained, probs=c(0.80, 0.90, 0.95, 0.99)),
  quantile(Yinsurer,  probs=c(0.80, 0.90, 0.95, 0.99)),
  quantile(S       ,  probs=c(0.80, 0.90, 0.95, 0.99)))
rownames(quantMat) <- c("Retained", "Insurer","Total")
round(quantMat,digits=2)
```

**(c)** Here is the code for the density plots of the retained, insurer, and total portfolio risk.

```{r warning=FALSE, message=FALSE, fig.width=8, fig.height=4, fig.align='center', comment=""}

par(mfrow=c(1,3))
plot(density(Yretained), xlim=c(0,500), main="Retained Portfolio Risk", xlab="Loss (Note the different horizontal scale)")
plot(density(Yinsurer), xlim=c(0,15000), main="Insurer Portfolio Risk", xlab="Loss")
plot(density(S), xlim=c(0,15000), main="Total Portfolio Risk", xlab="Loss")
```

</div>

```{js echo=FALSE}
function togglecode(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show";}
      else {ele.style.display = "block"; text.innerHTML = "Hide";}}
```
