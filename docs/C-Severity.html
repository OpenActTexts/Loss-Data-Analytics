<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Loss Data Analytics</title>
  <meta name="description" content="Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Loss Data Analytics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience." />
  <meta name="github-repo" content="<a href="https://github.com/openacttexts/Loss-Data-Analytics" class="uri">https://github.com/openacttexts/Loss-Data-Analytics</a>" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Loss Data Analytics" />
  
  <meta name="twitter:description" content="Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience." />
  

<meta name="author" content="An open text authored by the Actuarial Community">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="C-Frequency-Modeling.html">
<link rel="next" href="C-ModelSelection.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script language="javascript">
function toggle(id1,id2) {
	var ele = document.getElementById(id1); var text = document.getElementById(id2);
	if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
		else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}
</script>

<script language="javascript">
function togglecode(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show R Code";}
      else {ele.style.display = "block"; text.innerHTML = "Hide R Code";}}
</script>
<script language="javascript">
function toggleEX(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Example";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Example";}}
</script>
<script language="javascript">
function toggleTheory(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Theory";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Theory";}}
</script>

<script language="javascript">
$(document).ready(function(){
    $('[data-toggle="tooltip"]').tooltip();
});
</script>


<script>
$(document).ready(function(){
    $('[data-toggle="popover"]').popover(); 
});
</script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-125587869-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-125587869-1');
</script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Loss Data Analytics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#contributors"><i class="fa fa-check"></i>Contributors</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#reviewers"><i class="fa fa-check"></i>Reviewers</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#for-our-readers"><i class="fa fa-check"></i>For our Readers</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="C-Intro.html"><a href="C-Intro.html"><i class="fa fa-check"></i><b>1</b> Introduction to Loss Data Analytics</a><ul>
<li class="chapter" data-level="1.1" data-path="C-Intro.html"><a href="C-Intro.html#S:Intro"><i class="fa fa-check"></i><b>1.1</b> Relevance of Analytics</a><ul>
<li class="chapter" data-level="1.1.1" data-path="C-Intro.html"><a href="C-Intro.html#what-is-analytics"><i class="fa fa-check"></i><b>1.1.1</b> What is Analytics?</a></li>
<li class="chapter" data-level="1.1.2" data-path="C-Intro.html"><a href="C-Intro.html#short-and-long-term-insurance"><i class="fa fa-check"></i><b>1.1.2</b> Short and Long-term Insurance</a></li>
<li class="chapter" data-level="1.1.3" data-path="C-Intro.html"><a href="C-Intro.html#S:InsProcesses"><i class="fa fa-check"></i><b>1.1.3</b> Insurance Processes</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="C-Intro.html"><a href="C-Intro.html#S:PredModApps"><i class="fa fa-check"></i><b>1.2</b> Insurance Company Operations</a><ul>
<li class="chapter" data-level="1.2.1" data-path="C-Intro.html"><a href="C-Intro.html#initiating-insurance"><i class="fa fa-check"></i><b>1.2.1</b> Initiating Insurance</a></li>
<li class="chapter" data-level="1.2.2" data-path="C-Intro.html"><a href="C-Intro.html#renewing-insurance"><i class="fa fa-check"></i><b>1.2.2</b> Renewing Insurance</a></li>
<li class="chapter" data-level="1.2.3" data-path="C-Intro.html"><a href="C-Intro.html#claims-and-product-management"><i class="fa fa-check"></i><b>1.2.3</b> Claims and Product Management</a></li>
<li class="chapter" data-level="1.2.4" data-path="C-Intro.html"><a href="C-Intro.html#S:Reserving"><i class="fa fa-check"></i><b>1.2.4</b> Loss Reserving</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="C-Intro.html"><a href="C-Intro.html#S:LGPIF"><i class="fa fa-check"></i><b>1.3</b> Case Study: Wisconsin Property Fund</a><ul>
<li class="chapter" data-level="1.3.1" data-path="C-Intro.html"><a href="C-Intro.html#S:OutComes"><i class="fa fa-check"></i><b>1.3.1</b> Fund Claims Variables: Frequency and Severity</a></li>
<li class="chapter" data-level="1.3.2" data-path="C-Intro.html"><a href="C-Intro.html#S:FundVariables"><i class="fa fa-check"></i><b>1.3.2</b> Fund Rating Variables</a></li>
<li class="chapter" data-level="1.3.3" data-path="C-Intro.html"><a href="C-Intro.html#fund-operations"><i class="fa fa-check"></i><b>1.3.3</b> Fund Operations</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="C-Intro.html"><a href="C-Intro.html#Intro-further-reading-and-resources"><i class="fa fa-check"></i><b>1.4</b> Further Resources and Contributors</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html"><i class="fa fa-check"></i><b>2</b> Frequency Modeling</a><ul>
<li class="chapter" data-level="2.1" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:frequency-distributions"><i class="fa fa-check"></i><b>2.1</b> Frequency Distributions</a><ul>
<li class="chapter" data-level="2.1.1" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:how-frequency-augments-severity-information"><i class="fa fa-check"></i><b>2.1.1</b> How Frequency Augments Severity Information</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:basic-frequency-distributions"><i class="fa fa-check"></i><b>2.2</b> Basic Frequency Distributions</a><ul>
<li class="chapter" data-level="2.2.1" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:foundations"><i class="fa fa-check"></i><b>2.2.1</b> Foundations</a></li>
<li class="chapter" data-level="2.2.2" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:generating-functions"><i class="fa fa-check"></i><b>2.2.2</b> Moment and Probability Generating Functions</a></li>
<li class="chapter" data-level="2.2.3" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:important-frequency-distributions"><i class="fa fa-check"></i><b>2.2.3</b> Important Frequency Distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:the-a-b-0-class"><i class="fa fa-check"></i><b>2.3</b> The (a, b, 0) Class</a></li>
<li class="chapter" data-level="2.4" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:estimating-frequency-distributions"><i class="fa fa-check"></i><b>2.4</b> Estimating Frequency Distributions</a><ul>
<li class="chapter" data-level="2.4.1" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:parameter-estimation"><i class="fa fa-check"></i><b>2.4.1</b> Parameter estimation</a></li>
<li class="chapter" data-level="2.4.2" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:frequency-distributions-mle"><i class="fa fa-check"></i><b>2.4.2</b> Frequency Distributions MLE</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:other-frequency-distributions"><i class="fa fa-check"></i><b>2.5</b> Other Frequency Distributions</a><ul>
<li class="chapter" data-level="2.5.1" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:zero-truncation-or-modification"><i class="fa fa-check"></i><b>2.5.1</b> Zero Truncation or Modification</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:mixture-distributions"><i class="fa fa-check"></i><b>2.6</b> Mixture Distributions</a></li>
<li class="chapter" data-level="2.7" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:goodness-of-fit"><i class="fa fa-check"></i><b>2.7</b> Goodness of Fit</a></li>
<li class="chapter" data-level="2.8" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#S:exercises"><i class="fa fa-check"></i><b>2.8</b> Exercises</a></li>
<li class="chapter" data-level="2.9" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#r-code-for-plots-in-this-chapter"><i class="fa fa-check"></i><b>2.9</b> R Code for Plots in this Chapter</a></li>
<li class="chapter" data-level="2.10" data-path="C-Frequency-Modeling.html"><a href="C-Frequency-Modeling.html#Freq-further-reading-and-resources"><i class="fa fa-check"></i><b>2.10</b> Further Resources and Contributors</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="C-Severity.html"><a href="C-Severity.html"><i class="fa fa-check"></i><b>3</b> Modeling Loss Severity</a><ul>
<li class="chapter" data-level="3.1" data-path="C-Severity.html"><a href="C-Severity.html#S:BasicQuantities"><i class="fa fa-check"></i><b>3.1</b> Basic Distributional Quantities</a><ul>
<li class="chapter" data-level="3.1.1" data-path="C-Severity.html"><a href="C-Severity.html#S:Chap3Moments"><i class="fa fa-check"></i><b>3.1.1</b> Moments</a></li>
<li class="chapter" data-level="3.1.2" data-path="C-Severity.html"><a href="C-Severity.html#quantiles"><i class="fa fa-check"></i><b>3.1.2</b> Quantiles</a></li>
<li class="chapter" data-level="3.1.3" data-path="C-Severity.html"><a href="C-Severity.html#moment-generating-function"><i class="fa fa-check"></i><b>3.1.3</b> Moment Generating Function</a></li>
<li class="chapter" data-level="3.1.4" data-path="C-Severity.html"><a href="C-Severity.html#probability-generating-function"><i class="fa fa-check"></i><b>3.1.4</b> Probability Generating Function</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="C-Severity.html"><a href="C-Severity.html#S:ContinuousDistn"><i class="fa fa-check"></i><b>3.2</b> Continuous Distributions for Modeling Loss Severity</a><ul>
<li class="chapter" data-level="3.2.1" data-path="C-Severity.html"><a href="C-Severity.html#gamma-distribution"><i class="fa fa-check"></i><b>3.2.1</b> Gamma Distribution</a></li>
<li class="chapter" data-level="3.2.2" data-path="C-Severity.html"><a href="C-Severity.html#pareto-distribution"><i class="fa fa-check"></i><b>3.2.2</b> Pareto Distribution</a></li>
<li class="chapter" data-level="3.2.3" data-path="C-Severity.html"><a href="C-Severity.html#weibull-distribution"><i class="fa fa-check"></i><b>3.2.3</b> Weibull Distribution</a></li>
<li class="chapter" data-level="3.2.4" data-path="C-Severity.html"><a href="C-Severity.html#the-generalized-beta-distribution-of-the-second-kind"><i class="fa fa-check"></i><b>3.2.4</b> The Generalized Beta Distribution of the Second Kind</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="C-Severity.html"><a href="C-Severity.html#MethodsCreation"><i class="fa fa-check"></i><b>3.3</b> Methods of Creating New Distributions</a><ul>
<li class="chapter" data-level="3.3.1" data-path="C-Severity.html"><a href="C-Severity.html#functions-of-random-variables-and-their-distributions"><i class="fa fa-check"></i><b>3.3.1</b> Functions of Random Variables and their Distributions</a></li>
<li class="chapter" data-level="3.3.2" data-path="C-Severity.html"><a href="C-Severity.html#multiplication-by-a-constant"><i class="fa fa-check"></i><b>3.3.2</b> Multiplication by a Constant</a></li>
<li class="chapter" data-level="3.3.3" data-path="C-Severity.html"><a href="C-Severity.html#raising-to-a-power"><i class="fa fa-check"></i><b>3.3.3</b> Raising to a Power</a></li>
<li class="chapter" data-level="3.3.4" data-path="C-Severity.html"><a href="C-Severity.html#exponentiation"><i class="fa fa-check"></i><b>3.3.4</b> Exponentiation</a></li>
<li class="chapter" data-level="3.3.5" data-path="C-Severity.html"><a href="C-Severity.html#finite-mixtures"><i class="fa fa-check"></i><b>3.3.5</b> Finite Mixtures</a></li>
<li class="chapter" data-level="3.3.6" data-path="C-Severity.html"><a href="C-Severity.html#continuous-mixtures"><i class="fa fa-check"></i><b>3.3.6</b> Continuous Mixtures</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="C-Severity.html"><a href="C-Severity.html#S:CoverageModifications"><i class="fa fa-check"></i><b>3.4</b> Coverage Modifications</a><ul>
<li class="chapter" data-level="3.4.1" data-path="C-Severity.html"><a href="C-Severity.html#S:PolicyDeduct"><i class="fa fa-check"></i><b>3.4.1</b> Policy Deductibles</a></li>
<li class="chapter" data-level="3.4.2" data-path="C-Severity.html"><a href="C-Severity.html#S:PolicyLimits"><i class="fa fa-check"></i><b>3.4.2</b> Policy Limits</a></li>
<li class="chapter" data-level="3.4.3" data-path="C-Severity.html"><a href="C-Severity.html#coinsurance"><i class="fa fa-check"></i><b>3.4.3</b> Coinsurance</a></li>
<li class="chapter" data-level="3.4.4" data-path="C-Severity.html"><a href="C-Severity.html#S:Chap3Reinsurance"><i class="fa fa-check"></i><b>3.4.4</b> Reinsurance</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="C-Severity.html"><a href="C-Severity.html#S:MaxLikeEstimation"><i class="fa fa-check"></i><b>3.5</b> Maximum Likelihood Estimation</a><ul>
<li class="chapter" data-level="3.5.1" data-path="C-Severity.html"><a href="C-Severity.html#maximum-likelihood-estimators-for-complete-data"><i class="fa fa-check"></i><b>3.5.1</b> Maximum Likelihood Estimators for Complete Data</a></li>
<li class="chapter" data-level="3.5.2" data-path="C-Severity.html"><a href="C-Severity.html#MLEGrouped"><i class="fa fa-check"></i><b>3.5.2</b> Maximum Likelihood Estimators for Grouped Data</a></li>
<li class="chapter" data-level="3.5.3" data-path="C-Severity.html"><a href="C-Severity.html#maximum-likelihood-estimators-for-censored-data"><i class="fa fa-check"></i><b>3.5.3</b> Maximum Likelihood Estimators for Censored Data</a></li>
<li class="chapter" data-level="3.5.4" data-path="C-Severity.html"><a href="C-Severity.html#maximum-likelihood-estimators-for-truncated-data"><i class="fa fa-check"></i><b>3.5.4</b> Maximum Likelihood Estimators for Truncated Data</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="C-Severity.html"><a href="C-Severity.html#LM-further-reading-and-resources"><i class="fa fa-check"></i><b>3.6</b> Further Resources and Contributors</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html"><i class="fa fa-check"></i><b>4</b> Model Selection and Estimation</a><ul>
<li class="chapter" data-level="4.1" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#S:MS:NonParInf"><i class="fa fa-check"></i><b>4.1</b> Nonparametric Inference</a><ul>
<li class="chapter" data-level="4.1.1" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#nonparametric-estimation"><i class="fa fa-check"></i><b>4.1.1</b> Nonparametric Estimation</a></li>
<li class="chapter" data-level="4.1.2" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#S:MS:ToolsModelSelection"><i class="fa fa-check"></i><b>4.1.2</b> Tools for Model Selection and Diagnostics</a></li>
<li class="chapter" data-level="4.1.3" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#starting-values"><i class="fa fa-check"></i><b>4.1.3</b> Starting Values</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#S:MS:ModelSelection"><i class="fa fa-check"></i><b>4.2</b> Model Selection</a><ul>
<li class="chapter" data-level="4.2.1" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#iterative-model-selection"><i class="fa fa-check"></i><b>4.2.1</b> Iterative Model Selection</a></li>
<li class="chapter" data-level="4.2.2" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#model-selection-based-on-a-training-dataset"><i class="fa fa-check"></i><b>4.2.2</b> Model Selection Based on a Training Dataset</a></li>
<li class="chapter" data-level="4.2.3" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#model-selection-based-on-a-test-dataset"><i class="fa fa-check"></i><b>4.2.3</b> Model Selection Based on a Test Dataset</a></li>
<li class="chapter" data-level="4.2.4" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#model-selection-based-on-cross-validation"><i class="fa fa-check"></i><b>4.2.4</b> Model Selection Based on Cross-Validation</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#S:MS:ModifiedData"><i class="fa fa-check"></i><b>4.3</b> Estimation using Modified Data</a><ul>
<li class="chapter" data-level="4.3.1" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#parametric-estimation-using-modified-data"><i class="fa fa-check"></i><b>4.3.1</b> Parametric Estimation using Modified Data</a></li>
<li class="chapter" data-level="4.3.2" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#nonparametric-estimation-using-modified-data"><i class="fa fa-check"></i><b>4.3.2</b> Nonparametric Estimation using Modified Data</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#S:MS:BayesInference"><i class="fa fa-check"></i><b>4.4</b> Bayesian Inference</a><ul>
<li class="chapter" data-level="4.4.1" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#S:IntroBayes"><i class="fa fa-check"></i><b>4.4.1</b> Introduction to Bayesian Inference</a></li>
<li class="chapter" data-level="4.4.2" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#bayesian-model"><i class="fa fa-check"></i><b>4.4.2</b> Bayesian Model</a></li>
<li class="chapter" data-level="4.4.3" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#bayesian-inference"><i class="fa fa-check"></i><b>4.4.3</b> Bayesian Inference</a></li>
<li class="chapter" data-level="4.4.4" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#S:ConjugateDistributions"><i class="fa fa-check"></i><b>4.4.4</b> Conjugate Distributions</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#MS:further-reading-and-resources"><i class="fa fa-check"></i><b>4.5</b> Further Resources and Contributors</a></li>
<li class="chapter" data-level="" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#technical-supplement-a.-gini-statistic"><i class="fa fa-check"></i>Technical Supplement A. Gini Statistic</a><ul>
<li class="chapter" data-level="" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#ts-a.1.-the-classic-lorenz-curve"><i class="fa fa-check"></i>TS A.1. The Classic Lorenz Curve</a></li>
<li class="chapter" data-level="" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#ts-a.2.-ordered-lorenz-curve-and-the-gini-index"><i class="fa fa-check"></i>TS A.2. Ordered Lorenz Curve and the Gini Index</a></li>
<li class="chapter" data-level="" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#ts-a.3.-out-of-sample-validation"><i class="fa fa-check"></i>TS A.3. Out-of-Sample Validation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html"><i class="fa fa-check"></i><b>5</b> Aggregate Loss Models</a><ul>
<li class="chapter" data-level="5.1" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#introduction"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#individual-risk-model"><i class="fa fa-check"></i><b>5.2</b> Individual Risk Model</a></li>
<li class="chapter" data-level="5.3" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#collective-risk-model"><i class="fa fa-check"></i><b>5.3</b> Collective Risk Model</a><ul>
<li class="chapter" data-level="5.3.1" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#moments-and-distribution"><i class="fa fa-check"></i><b>5.3.1</b> Moments and Distribution</a></li>
<li class="chapter" data-level="5.3.2" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#stop-loss-insurance"><i class="fa fa-check"></i><b>5.3.2</b> Stop-loss Insurance</a></li>
<li class="chapter" data-level="5.3.3" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#analytic-results"><i class="fa fa-check"></i><b>5.3.3</b> Analytic Results</a></li>
<li class="chapter" data-level="5.3.4" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#tweedie-distribution"><i class="fa fa-check"></i><b>5.3.4</b> Tweedie Distribution</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#computing-the-aggregate-claims-distribution"><i class="fa fa-check"></i><b>5.4</b> Computing the Aggregate Claims Distribution</a><ul>
<li class="chapter" data-level="5.4.1" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#recursive-method"><i class="fa fa-check"></i><b>5.4.1</b> Recursive Method</a></li>
<li class="chapter" data-level="5.4.2" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#simulation"><i class="fa fa-check"></i><b>5.4.2</b> Simulation</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#effects-of-coverage-modifications"><i class="fa fa-check"></i><b>5.5</b> Effects of Coverage Modifications</a><ul>
<li class="chapter" data-level="5.5.1" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#impact-of-exposure-on-frequency"><i class="fa fa-check"></i><b>5.5.1</b> Impact of Exposure on Frequency</a></li>
<li class="chapter" data-level="5.5.2" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#S:MS:DedImpactClmFreq"><i class="fa fa-check"></i><b>5.5.2</b> Impact of Deductibles on Claim Frequency</a></li>
<li class="chapter" data-level="5.5.3" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#impact-of-policy-modifications-on-aggregate-claims"><i class="fa fa-check"></i><b>5.5.3</b> Impact of Policy Modifications on Aggregate Claims</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#AL-further-reading-and-resources"><i class="fa fa-check"></i><b>5.6</b> Further Resources and Contributors</a></li>
<li class="chapter" data-level="" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#technical-supplement-b.-aggregate-loss-models"><i class="fa fa-check"></i>Technical Supplement B. Aggregate Loss Models</a><ul>
<li class="chapter" data-level="" data-path="C-AggLossModels.html"><a href="C-AggLossModels.html#ts-b.1.-individual-risk-model-properties"><i class="fa fa-check"></i>TS B.1. Individual Risk Model Properties</a></li>
<li><a href="C-AggLossModels.html#ts-b.2.-relationship-between-probability-generating-functions-of-x_i-and-x_it">TS B.2. Relationship Between Probability Generating Functions of <span class="math inline">\(X_i\)</span> and <span class="math inline">\(X_i^T\)</span></a></li>
<li><a href="C-AggLossModels.html#ts-b.3.-example-5.3.8-moment-generating-function-of-aggregate-loss-s_n">TS B.3. Example 5.3.8 Moment Generating Function of Aggregate Loss <span class="math inline">\(S_N\)</span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="C-Simulation.html"><a href="C-Simulation.html"><i class="fa fa-check"></i><b>6</b> Simulation</a><ul>
<li class="chapter" data-level="6.1" data-path="C-Simulation.html"><a href="C-Simulation.html#generating-independent-uniform-observations"><i class="fa fa-check"></i><b>6.1</b> Generating Independent Uniform Observations</a></li>
<li class="chapter" data-level="6.2" data-path="C-Simulation.html"><a href="C-Simulation.html#inverse-transform"><i class="fa fa-check"></i><b>6.2</b> Inverse Transform</a></li>
<li class="chapter" data-level="6.3" data-path="C-Simulation.html"><a href="C-Simulation.html#how-many-simulated-values"><i class="fa fa-check"></i><b>6.3</b> How Many Simulated Values?</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="C-PremCalc.html"><a href="C-PremCalc.html"><i class="fa fa-check"></i><b>7</b> Premium Calculation Fundamentals</a></li>
<li class="chapter" data-level="8" data-path="C-RiskClass.html"><a href="C-RiskClass.html"><i class="fa fa-check"></i><b>8</b> Risk Classification</a><ul>
<li class="chapter" data-level="8.1" data-path="C-RiskClass.html"><a href="C-RiskClass.html#S:RC:Introduction"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="C-RiskClass.html"><a href="C-RiskClass.html#S:RC:PoissonRegression"><i class="fa fa-check"></i><b>8.2</b> Poisson Regression Model</a><ul>
<li class="chapter" data-level="8.2.1" data-path="C-RiskClass.html"><a href="C-RiskClass.html#S:RC:Need.Poi.reg"><i class="fa fa-check"></i><b>8.2.1</b> Need for Poisson Regression</a></li>
<li class="chapter" data-level="8.2.2" data-path="C-RiskClass.html"><a href="C-RiskClass.html#poisson-regression"><i class="fa fa-check"></i><b>8.2.2</b> Poisson Regression</a></li>
<li class="chapter" data-level="8.2.3" data-path="C-RiskClass.html"><a href="C-RiskClass.html#incorporating-exposure"><i class="fa fa-check"></i><b>8.2.3</b> Incorporating Exposure</a></li>
<li class="chapter" data-level="8.2.4" data-path="C-RiskClass.html"><a href="C-RiskClass.html#exercises-4"><i class="fa fa-check"></i><b>8.2.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="C-RiskClass.html"><a href="C-RiskClass.html#S:CatVarMultiTarriff"><i class="fa fa-check"></i><b>8.3</b> Categorical Variables and Multiplicative Tariff</a><ul>
<li class="chapter" data-level="8.3.1" data-path="C-RiskClass.html"><a href="C-RiskClass.html#rating-factors-and-tariff"><i class="fa fa-check"></i><b>8.3.1</b> Rating Factors and Tariff</a></li>
<li class="chapter" data-level="8.3.2" data-path="C-RiskClass.html"><a href="C-RiskClass.html#multiplicative-tariff-model"><i class="fa fa-check"></i><b>8.3.2</b> Multiplicative Tariff Model</a></li>
<li class="chapter" data-level="8.3.3" data-path="C-RiskClass.html"><a href="C-RiskClass.html#poisson-regression-for-multiplicative-tariff"><i class="fa fa-check"></i><b>8.3.3</b> Poisson Regression for Multiplicative Tariff</a></li>
<li class="chapter" data-level="8.3.4" data-path="C-RiskClass.html"><a href="C-RiskClass.html#numerical-examples"><i class="fa fa-check"></i><b>8.3.4</b> Numerical Examples</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="C-RiskClass.html"><a href="C-RiskClass.html#RC:further-reading-and-resources"><i class="fa fa-check"></i><b>8.4</b> Contributors and Further Resources</a></li>
<li class="chapter" data-level="8.5" data-path="C-RiskClass.html"><a href="C-RiskClass.html#S:RC:mle-Pois-reg"><i class="fa fa-check"></i><b>8.5</b> Technical Supplement – Estimating Poisson Regression Models</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="C-Credibility.html"><a href="C-Credibility.html"><i class="fa fa-check"></i><b>9</b> Experience Rating Using Credibility Theory</a><ul>
<li class="chapter" data-level="9.1" data-path="C-Credibility.html"><a href="C-Credibility.html#introduction-to-applications-of-credibility-theory"><i class="fa fa-check"></i><b>9.1</b> Introduction to Applications of Credibility Theory</a></li>
<li class="chapter" data-level="9.2" data-path="C-Credibility.html"><a href="C-Credibility.html#limited-fluctuation-credibility"><i class="fa fa-check"></i><b>9.2</b> Limited Fluctuation Credibility</a><ul>
<li class="chapter" data-level="9.2.1" data-path="C-Credibility.html"><a href="C-Credibility.html#S:frequency"><i class="fa fa-check"></i><b>9.2.1</b> Full Credibility for Claim Frequency</a></li>
<li class="chapter" data-level="9.2.2" data-path="C-Credibility.html"><a href="C-Credibility.html#full-credibility-for-aggregate-losses-and-pure-premium"><i class="fa fa-check"></i><b>9.2.2</b> Full Credibility for Aggregate Losses and Pure Premium</a></li>
<li class="chapter" data-level="9.2.3" data-path="C-Credibility.html"><a href="C-Credibility.html#full-credibility-for-severity"><i class="fa fa-check"></i><b>9.2.3</b> Full Credibility for Severity</a></li>
<li class="chapter" data-level="9.2.4" data-path="C-Credibility.html"><a href="C-Credibility.html#partial-credibility"><i class="fa fa-check"></i><b>9.2.4</b> Partial Credibility</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="C-Credibility.html"><a href="C-Credibility.html#buhlmann-credibility"><i class="fa fa-check"></i><b>9.3</b> Bühlmann Credibility</a><ul>
<li class="chapter" data-level="9.3.1" data-path="C-Credibility.html"><a href="C-Credibility.html#S:EPV-VHM-Z"><i class="fa fa-check"></i><b>9.3.1</b> Credibility Z, <em>EPV</em>, and <em>VHM</em></a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="C-Credibility.html"><a href="C-Credibility.html#buhlmann-straub-credibility"><i class="fa fa-check"></i><b>9.4</b> Bühlmann-Straub Credibility</a></li>
<li class="chapter" data-level="9.5" data-path="C-Credibility.html"><a href="C-Credibility.html#bayesian-inference-and-buhlmann"><i class="fa fa-check"></i><b>9.5</b> Bayesian Inference and Bühlmann</a><ul>
<li class="chapter" data-level="9.5.1" data-path="C-Credibility.html"><a href="C-Credibility.html#S:Gamma-Poisson"><i class="fa fa-check"></i><b>9.5.1</b> Gamma-Poisson Model</a></li>
<li class="chapter" data-level="9.5.2" data-path="C-Credibility.html"><a href="C-Credibility.html#exact-credibility"><i class="fa fa-check"></i><b>9.5.2</b> Exact Credibility</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="C-Credibility.html"><a href="C-Credibility.html#estimating-credibility-parameters"><i class="fa fa-check"></i><b>9.6</b> Estimating Credibility Parameters</a><ul>
<li class="chapter" data-level="9.6.1" data-path="C-Credibility.html"><a href="C-Credibility.html#full-credibility-standard-for-limited-fluctuation-credibility"><i class="fa fa-check"></i><b>9.6.1</b> Full Credibility Standard for Limited Fluctuation Credibility</a></li>
<li class="chapter" data-level="9.6.2" data-path="C-Credibility.html"><a href="C-Credibility.html#nonparametric-estimation-for-buhlmann-and-buhlmann-straub-models"><i class="fa fa-check"></i><b>9.6.2</b> Nonparametric Estimation for Bühlmann and Bühlmann-Straub Models</a></li>
<li class="chapter" data-level="9.6.3" data-path="C-Credibility.html"><a href="C-Credibility.html#semiparametric-estimation-for-buhlmann-and-buhlmann-straub-models"><i class="fa fa-check"></i><b>9.6.3</b> Semiparametric Estimation for Bühlmann and Bühlmann-Straub Models</a></li>
<li class="chapter" data-level="9.6.4" data-path="C-Credibility.html"><a href="C-Credibility.html#balancing-credibility-estimators"><i class="fa fa-check"></i><b>9.6.4</b> Balancing Credibility Estimators</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="C-Credibility.html"><a href="C-Credibility.html#Cred-further-reading-and-resources"><i class="fa fa-check"></i><b>9.7</b> Further Resources and Contributors</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="C-PortMgt.html"><a href="C-PortMgt.html"><i class="fa fa-check"></i><b>10</b> Insurance Portfolio Management including Reinsurance</a><ul>
<li class="chapter" data-level="" data-path="C-PortMgt.html"><a href="C-PortMgt.html#overview"><i class="fa fa-check"></i>Overview</a></li>
<li class="chapter" data-level="10.1" data-path="C-PortMgt.html"><a href="C-PortMgt.html#S:Tails"><i class="fa fa-check"></i><b>10.1</b> Tails of Distributions</a><ul>
<li class="chapter" data-level="10.1.1" data-path="C-PortMgt.html"><a href="C-PortMgt.html#classification-based-on-moments"><i class="fa fa-check"></i><b>10.1.1</b> Classification Based on Moments</a></li>
<li class="chapter" data-level="10.1.2" data-path="C-PortMgt.html"><a href="C-PortMgt.html#comparison-based-on-limiting-tail-behavior"><i class="fa fa-check"></i><b>10.1.2</b> Comparison Based on Limiting Tail Behavior</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="C-PortMgt.html"><a href="C-PortMgt.html#S:RiskMeasure"><i class="fa fa-check"></i><b>10.2</b> Risk Measures</a><ul>
<li class="chapter" data-level="10.2.1" data-path="C-PortMgt.html"><a href="C-PortMgt.html#coherent-risk-measures"><i class="fa fa-check"></i><b>10.2.1</b> Coherent Risk Measures</a></li>
<li class="chapter" data-level="10.2.2" data-path="C-PortMgt.html"><a href="C-PortMgt.html#value-at-risk"><i class="fa fa-check"></i><b>10.2.2</b> Value-at-Risk</a></li>
<li class="chapter" data-level="10.2.3" data-path="C-PortMgt.html"><a href="C-PortMgt.html#tail-value-at-risk"><i class="fa fa-check"></i><b>10.2.3</b> Tail Value-at-Risk</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="C-PortMgt.html"><a href="C-PortMgt.html#S:Reinsurance"><i class="fa fa-check"></i><b>10.3</b> Reinsurance</a><ul>
<li class="chapter" data-level="10.3.1" data-path="C-PortMgt.html"><a href="C-PortMgt.html#S:ProportionalRe"><i class="fa fa-check"></i><b>10.3.1</b> Proportional Reinsurance</a></li>
<li class="chapter" data-level="10.3.2" data-path="C-PortMgt.html"><a href="C-PortMgt.html#S:NonProportionalRe"><i class="fa fa-check"></i><b>10.3.2</b> Non-Proportional Reinsurance</a></li>
<li class="chapter" data-level="10.3.3" data-path="C-PortMgt.html"><a href="C-PortMgt.html#S:AdditionalRe"><i class="fa fa-check"></i><b>10.3.3</b> Additional Reinsurance Treaties</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="C-LossReserves.html"><a href="C-LossReserves.html"><i class="fa fa-check"></i><b>11</b> Loss Reserving</a></li>
<li class="chapter" data-level="12" data-path="C-BonusMalus.html"><a href="C-BonusMalus.html"><i class="fa fa-check"></i><b>12</b> Experience Rating using Bonus-Malus</a></li>
<li class="chapter" data-level="13" data-path="C-DataSystems.html"><a href="C-DataSystems.html"><i class="fa fa-check"></i><b>13</b> Data Systems</a><ul>
<li class="chapter" data-level="13.1" data-path="C-DataSystems.html"><a href="C-DataSystems.html#data"><i class="fa fa-check"></i><b>13.1</b> Data</a><ul>
<li class="chapter" data-level="13.1.1" data-path="C-DataSystems.html"><a href="C-DataSystems.html#data-types-and-sources"><i class="fa fa-check"></i><b>13.1.1</b> Data Types and Sources</a></li>
<li class="chapter" data-level="13.1.2" data-path="C-DataSystems.html"><a href="C-DataSystems.html#data-structures-and-storage"><i class="fa fa-check"></i><b>13.1.2</b> Data Structures and Storage</a></li>
<li class="chapter" data-level="13.1.3" data-path="C-DataSystems.html"><a href="C-DataSystems.html#data-quality"><i class="fa fa-check"></i><b>13.1.3</b> Data Quality</a></li>
<li class="chapter" data-level="13.1.4" data-path="C-DataSystems.html"><a href="C-DataSystems.html#data-cleaning"><i class="fa fa-check"></i><b>13.1.4</b> Data Cleaning</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="C-DataSystems.html"><a href="C-DataSystems.html#data-analysis-preliminary"><i class="fa fa-check"></i><b>13.2</b> Data Analysis Preliminary</a><ul>
<li class="chapter" data-level="13.2.1" data-path="C-DataSystems.html"><a href="C-DataSystems.html#S:process"><i class="fa fa-check"></i><b>13.2.1</b> Data Analysis Process</a></li>
<li class="chapter" data-level="13.2.2" data-path="C-DataSystems.html"><a href="C-DataSystems.html#exploratory-versus-confirmatory"><i class="fa fa-check"></i><b>13.2.2</b> Exploratory versus Confirmatory</a></li>
<li class="chapter" data-level="13.2.3" data-path="C-DataSystems.html"><a href="C-DataSystems.html#supervised-versus-unsupervised"><i class="fa fa-check"></i><b>13.2.3</b> Supervised versus Unsupervised</a></li>
<li class="chapter" data-level="13.2.4" data-path="C-DataSystems.html"><a href="C-DataSystems.html#parametric-versus-nonparametric"><i class="fa fa-check"></i><b>13.2.4</b> Parametric versus Nonparametric</a></li>
<li class="chapter" data-level="13.2.5" data-path="C-DataSystems.html"><a href="C-DataSystems.html#S:expred"><i class="fa fa-check"></i><b>13.2.5</b> Explanation versus Prediction</a></li>
<li class="chapter" data-level="13.2.6" data-path="C-DataSystems.html"><a href="C-DataSystems.html#data-modeling-versus-algorithmic-modeling"><i class="fa fa-check"></i><b>13.2.6</b> Data Modeling versus Algorithmic Modeling</a></li>
<li class="chapter" data-level="13.2.7" data-path="C-DataSystems.html"><a href="C-DataSystems.html#big-data-analysis"><i class="fa fa-check"></i><b>13.2.7</b> Big Data Analysis</a></li>
<li class="chapter" data-level="13.2.8" data-path="C-DataSystems.html"><a href="C-DataSystems.html#reproducible-analysis"><i class="fa fa-check"></i><b>13.2.8</b> Reproducible Analysis</a></li>
<li class="chapter" data-level="13.2.9" data-path="C-DataSystems.html"><a href="C-DataSystems.html#ethical-issues"><i class="fa fa-check"></i><b>13.2.9</b> Ethical Issues</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="C-DataSystems.html"><a href="C-DataSystems.html#data-analysis-techniques"><i class="fa fa-check"></i><b>13.3</b> Data Analysis Techniques</a><ul>
<li class="chapter" data-level="13.3.1" data-path="C-DataSystems.html"><a href="C-DataSystems.html#exploratory-techniques"><i class="fa fa-check"></i><b>13.3.1</b> Exploratory Techniques</a></li>
<li class="chapter" data-level="13.3.2" data-path="C-DataSystems.html"><a href="C-DataSystems.html#descriptive-statistics"><i class="fa fa-check"></i><b>13.3.2</b> Descriptive Statistics</a></li>
<li class="chapter" data-level="13.3.3" data-path="C-DataSystems.html"><a href="C-DataSystems.html#cluster-analysis"><i class="fa fa-check"></i><b>13.3.3</b> Cluster Analysis</a></li>
<li class="chapter" data-level="13.3.4" data-path="C-DataSystems.html"><a href="C-DataSystems.html#confirmatory-techniques"><i class="fa fa-check"></i><b>13.3.4</b> Confirmatory Techniques</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="C-DataSystems.html"><a href="C-DataSystems.html#some-r-functions"><i class="fa fa-check"></i><b>13.4</b> Some R Functions</a></li>
<li class="chapter" data-level="13.5" data-path="C-DataSystems.html"><a href="C-DataSystems.html#summary"><i class="fa fa-check"></i><b>13.5</b> Summary</a></li>
<li class="chapter" data-level="13.6" data-path="C-DataSystems.html"><a href="C-DataSystems.html#DS:further-reading-and-resources"><i class="fa fa-check"></i><b>13.6</b> Further Resources and Contributors</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html"><i class="fa fa-check"></i><b>14</b> Dependence Modeling</a><ul>
<li class="chapter" data-level="14.1" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#S:VarTypes"><i class="fa fa-check"></i><b>14.1</b> Variable Types</a><ul>
<li class="chapter" data-level="14.1.1" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#S:QuaVar"><i class="fa fa-check"></i><b>14.1.1</b> Qualitative Variables</a></li>
<li class="chapter" data-level="14.1.2" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#S:QuanVar"><i class="fa fa-check"></i><b>14.1.2</b> Quantitative Variables</a></li>
<li class="chapter" data-level="14.1.3" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#multivariate-variables"><i class="fa fa-check"></i><b>14.1.3</b> Multivariate Variables</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#S:Measures"><i class="fa fa-check"></i><b>14.2</b> Classic Measures of Scalar Associations</a><ul>
<li class="chapter" data-level="14.2.1" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#association-measures-for-quantitative-variables"><i class="fa fa-check"></i><b>14.2.1</b> Association Measures for Quantitative Variables</a></li>
<li class="chapter" data-level="14.2.2" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#rank-based-measures"><i class="fa fa-check"></i><b>14.2.2</b> Rank Based Measures</a></li>
<li class="chapter" data-level="14.2.3" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#nominal-variables"><i class="fa fa-check"></i><b>14.2.3</b> Nominal Variables</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#S:Copula"><i class="fa fa-check"></i><b>14.3</b> Introduction to Copulas</a></li>
<li class="chapter" data-level="14.4" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#S:CopAppl"><i class="fa fa-check"></i><b>14.4</b> Application Using Copulas</a><ul>
<li class="chapter" data-level="14.4.1" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#data-description"><i class="fa fa-check"></i><b>14.4.1</b> Data Description</a></li>
<li class="chapter" data-level="14.4.2" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#marginal-models"><i class="fa fa-check"></i><b>14.4.2</b> Marginal Models</a></li>
<li class="chapter" data-level="14.4.3" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#probability-integral-transformation"><i class="fa fa-check"></i><b>14.4.3</b> Probability Integral Transformation</a></li>
<li class="chapter" data-level="14.4.4" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#joint-modeling-with-copula-function"><i class="fa fa-check"></i><b>14.4.4</b> Joint Modeling with Copula Function</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#S:CopTyp"><i class="fa fa-check"></i><b>14.5</b> Types of Copulas</a><ul>
<li class="chapter" data-level="14.5.1" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#elliptical-copulas"><i class="fa fa-check"></i><b>14.5.1</b> Elliptical Copulas</a></li>
<li class="chapter" data-level="14.5.2" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#archimedian-copulas"><i class="fa fa-check"></i><b>14.5.2</b> Archimedian Copulas</a></li>
<li class="chapter" data-level="14.5.3" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#properties-of-copulas"><i class="fa fa-check"></i><b>14.5.3</b> Properties of Copulas</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#S:CopImp"><i class="fa fa-check"></i><b>14.6</b> Why is Dependence Modeling Important?</a></li>
<li class="chapter" data-level="14.7" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#Dep:further-reading-and-resources"><i class="fa fa-check"></i><b>14.7</b> Further Resources and Contributors</a></li>
<li class="chapter" data-level="" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#technical-supplement-a.-other-classic-measures-of-scalar-associations"><i class="fa fa-check"></i>Technical Supplement A. Other Classic Measures of Scalar Associations</a><ul>
<li class="chapter" data-level="" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#a.1.-blomqvists-beta"><i class="fa fa-check"></i>A.1. Blomqvist’s Beta</a></li>
<li class="chapter" data-level="" data-path="C-DependenceModel.html"><a href="C-DependenceModel.html#a.2.-nonparametric-approach-using-spearman-correlation-with-tied-ranks"><i class="fa fa-check"></i>A.2. Nonparametric Approach Using Spearman Correlation with Tied Ranks</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="C-AppA.html"><a href="C-AppA.html"><i class="fa fa-check"></i><b>15</b> Appendix A: Review of Statistical Inference</a><ul>
<li class="chapter" data-level="15.1" data-path="C-AppA.html"><a href="C-AppA.html#S:AppA:BASIC"><i class="fa fa-check"></i><b>15.1</b> Basic Concepts</a><ul>
<li class="chapter" data-level="15.1.1" data-path="C-AppA.html"><a href="C-AppA.html#random-sampling"><i class="fa fa-check"></i><b>15.1.1</b> Random Sampling</a></li>
<li class="chapter" data-level="15.1.2" data-path="C-AppA.html"><a href="C-AppA.html#sampling-distribution"><i class="fa fa-check"></i><b>15.1.2</b> Sampling Distribution</a></li>
<li class="chapter" data-level="15.1.3" data-path="C-AppA.html"><a href="C-AppA.html#central-limit-theorem"><i class="fa fa-check"></i><b>15.1.3</b> Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="C-AppA.html"><a href="C-AppA.html#S:AppA:PE"><i class="fa fa-check"></i><b>15.2</b> Point Estimation and Properties</a><ul>
<li class="chapter" data-level="15.2.1" data-path="C-AppA.html"><a href="C-AppA.html#method-of-moments-estimation"><i class="fa fa-check"></i><b>15.2.1</b> Method of Moments Estimation</a></li>
<li class="chapter" data-level="15.2.2" data-path="C-AppA.html"><a href="C-AppA.html#S:AppA:MLE"><i class="fa fa-check"></i><b>15.2.2</b> Maximum Likelihood Estimation</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="C-AppA.html"><a href="C-AppA.html#S:AppA:IE"><i class="fa fa-check"></i><b>15.3</b> Interval Estimation</a><ul>
<li class="chapter" data-level="15.3.1" data-path="C-AppA.html"><a href="C-AppA.html#S:AppA:IE:ED"><i class="fa fa-check"></i><b>15.3.1</b> Exact Distribution for Normal Sample Mean</a></li>
<li class="chapter" data-level="15.3.2" data-path="C-AppA.html"><a href="C-AppA.html#large-sample-properties-of-mle"><i class="fa fa-check"></i><b>15.3.2</b> Large-sample Properties of MLE</a></li>
<li class="chapter" data-level="15.3.3" data-path="C-AppA.html"><a href="C-AppA.html#confidence-interval"><i class="fa fa-check"></i><b>15.3.3</b> Confidence Interval</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="C-AppA.html"><a href="C-AppA.html#S:AppA:HT"><i class="fa fa-check"></i><b>15.4</b> Hypothesis Testing</a><ul>
<li class="chapter" data-level="15.4.1" data-path="C-AppA.html"><a href="C-AppA.html#basic-concepts"><i class="fa fa-check"></i><b>15.4.1</b> Basic Concepts</a></li>
<li class="chapter" data-level="15.4.2" data-path="C-AppA.html"><a href="C-AppA.html#student-t-test-based-on-mle"><i class="fa fa-check"></i><b>15.4.2</b> Student-<span class="math inline">\(t\)</span> test based on MLE</a></li>
<li class="chapter" data-level="15.4.3" data-path="C-AppA.html"><a href="C-AppA.html#S:AppA:HT:LRT"><i class="fa fa-check"></i><b>15.4.3</b> Likelihood Ratio Test</a></li>
<li class="chapter" data-level="15.4.4" data-path="C-AppA.html"><a href="C-AppA.html#S:AppA:HT:IC"><i class="fa fa-check"></i><b>15.4.4</b> Information Criteria</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="C-AppB.html"><a href="C-AppB.html"><i class="fa fa-check"></i><b>16</b> Appendix B: Iterated Expectations</a><ul>
<li class="chapter" data-level="16.1" data-path="C-AppB.html"><a href="C-AppB.html#S:AppB:CD"><i class="fa fa-check"></i><b>16.1</b> Conditional Distribution and Conditional Expectation</a><ul>
<li class="chapter" data-level="16.1.1" data-path="C-AppB.html"><a href="C-AppB.html#conditional-distribution"><i class="fa fa-check"></i><b>16.1.1</b> Conditional Distribution</a></li>
<li class="chapter" data-level="16.1.2" data-path="C-AppB.html"><a href="C-AppB.html#conditional-expectation-and-conditional-variance"><i class="fa fa-check"></i><b>16.1.2</b> Conditional Expectation and Conditional Variance</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="C-AppB.html"><a href="C-AppB.html#S:AppB:IE"><i class="fa fa-check"></i><b>16.2</b> Iterated Expectations and Total Variance</a><ul>
<li class="chapter" data-level="16.2.1" data-path="C-AppB.html"><a href="C-AppB.html#law-of-iterated-expectations"><i class="fa fa-check"></i><b>16.2.1</b> Law of Iterated Expectations</a></li>
<li class="chapter" data-level="16.2.2" data-path="C-AppB.html"><a href="C-AppB.html#law-of-total-variance"><i class="fa fa-check"></i><b>16.2.2</b> Law of Total Variance</a></li>
<li class="chapter" data-level="16.2.3" data-path="C-AppB.html"><a href="C-AppB.html#application"><i class="fa fa-check"></i><b>16.2.3</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="C-ModelSelection.html"><a href="C-ModelSelection.html#S:ConjugateDistributions"><i class="fa fa-check"></i><b>16.3</b> Conjugate Distributions</a><ul>
<li class="chapter" data-level="16.3.1" data-path="C-AppB.html"><a href="C-AppB.html#linear-exponential-family"><i class="fa fa-check"></i><b>16.3.1</b> Linear Exponential Family</a></li>
<li class="chapter" data-level="16.3.2" data-path="C-AppB.html"><a href="C-AppB.html#conjugate-distributions"><i class="fa fa-check"></i><b>16.3.2</b> Conjugate Distributions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="C-AppC.html"><a href="C-AppC.html"><i class="fa fa-check"></i><b>17</b> Appendix C: Maximum Likelihood Theory</a><ul>
<li class="chapter" data-level="17.1" data-path="C-AppC.html"><a href="C-AppC.html#S:AppC:LF"><i class="fa fa-check"></i><b>17.1</b> Likelihood Function</a><ul>
<li class="chapter" data-level="17.1.1" data-path="C-AppC.html"><a href="C-AppC.html#likelihood-and-log-likelihood-functions"><i class="fa fa-check"></i><b>17.1.1</b> Likelihood and Log-likelihood Functions</a></li>
<li class="chapter" data-level="17.1.2" data-path="C-AppC.html"><a href="C-AppC.html#properties-of-likelihood-functions"><i class="fa fa-check"></i><b>17.1.2</b> Properties of Likelihood Functions</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="C-AppC.html"><a href="C-AppC.html#S:AppC:MLE"><i class="fa fa-check"></i><b>17.2</b> Maximum Likelihood Estimators</a><ul>
<li class="chapter" data-level="17.2.1" data-path="C-AppC.html"><a href="C-AppC.html#definition-and-derivation-of-mle"><i class="fa fa-check"></i><b>17.2.1</b> Definition and Derivation of MLE</a></li>
<li class="chapter" data-level="17.2.2" data-path="C-AppC.html"><a href="C-AppC.html#asymptotic-properties-of-mle"><i class="fa fa-check"></i><b>17.2.2</b> Asymptotic Properties of MLE</a></li>
<li class="chapter" data-level="17.2.3" data-path="C-AppC.html"><a href="C-AppC.html#use-of-maximum-likelihood-estimation"><i class="fa fa-check"></i><b>17.2.3</b> Use of Maximum Likelihood Estimation</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="C-AppC.html"><a href="C-AppC.html#S:AppC:SI"><i class="fa fa-check"></i><b>17.3</b> Statistical Inference Based on Maximum Likelhood Estimation</a><ul>
<li class="chapter" data-level="17.3.1" data-path="C-AppC.html"><a href="C-AppC.html#hypothesis-testing"><i class="fa fa-check"></i><b>17.3.1</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="17.3.2" data-path="C-AppC.html"><a href="C-AppC.html#S:AppC:MLEModelVal"><i class="fa fa-check"></i><b>17.3.2</b> MLE and Model Validation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="divider"></li>
<li><a href="https://openacttexts.github.io/Loss-Data-Analytics/" target="blank">Loss Data Analytics on GitHub</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Loss Data Analytics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="C:Severity" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Modeling Loss Severity</h1>
<p><em>Chapter Preview.</em> The traditional loss distribution approach to modeling aggregate losses starts by separately fitting a frequency distribution to the number of losses and a severity distribution to the size of losses. The estimated aggregate loss distribution combines the loss frequency distribution and the loss severity distribution by convolution. Discrete distributions often referred to as counting or frequency distributions were used in Chapter <a href="C-Frequency-Modeling.html#C:Frequency-Modeling">2</a> to describe the number of events such as number of accidents to the driver or number of claims to the insurer. Lifetimes, asset values, losses and claim sizes are usually modeled as continuous random variables and as such are modeled using continuous distributions, often referred to as loss or severity distributions. A mixture distribution is a weighted combination of simpler distributions that is used to model phenomenon investigated in a heterogeneous population, such as modelling more than one type of claims in liability insurance (small frequent claims and large relatively rare claims). In this chapter we explore the use of continuous as well as mixture distributions to model the random size of loss. We present key attributes that characterize continuous models and means of creating new distributions from existing ones. We also explore the effect of coverage modifications, which change the conditions that trigger a payment, such as applying deductibles, limits, or adjusting for inflation, on the distribution of individual loss amounts. The frequency distributions from Chapter <a href="C-Frequency-Modeling.html#C:Frequency-Modeling">2</a> will be combined with the ideas from this chapter to describe the aggregate losses over the whole portfolio in Chapter <a href="C-AggLossModels.html#C:AggLossModels">5</a>.</p>
<div id="S:BasicQuantities" class="section level2">
<h2><span class="header-section-number">3.1</span> Basic Distributional Quantities</h2>
<p>In this section we define the basic distributional quantities: moments, percentiles and generating functions.</p>
<div id="S:Chap3Moments" class="section level3">
<h3><span class="header-section-number">3.1.1</span> Moments</h3>
<p>Let <span class="math inline">\(X\)</span> be a continuous random variable with probability density function <span class="math inline">\(f_{X}\left( x \right)\)</span>. The <em>k</em>-th raw moment of <span class="math inline">\(X\)</span>, denoted by <span class="math inline">\(\mu_{k}^{\prime}\)</span>, is the expected value of the <em>k</em>-th power of <span class="math inline">\(X\)</span>, provided it exists. The first raw moment <span class="math inline">\(\mu_{1}^{\prime}\)</span> is the mean of <span class="math inline">\(X\)</span> usually denoted by <span class="math inline">\(\mu\)</span>. The formula for <span class="math inline">\(\mu_{k}^{\prime}\)</span> is given as <span class="math display">\[\mu_{k}^{\prime} = \mathrm{E}\left( X^{k} \right) = \int_{0}^{\infty}{x^{k}f_{X}\left( x \right)dx } .\]</span> The support of the random variable <span class="math inline">\(X\)</span> is assumed to be nonnegative since actuarial phenomena are rarely negative.</p>
<p>The <em>k</em>-th central moment of <span class="math inline">\(X\)</span>, denoted by <span class="math inline">\(\mu_{k}\)</span>, is the expected value of the <em>k</em>-th power of the deviation of <span class="math inline">\(X\)</span> from its mean <span class="math inline">\(\mu\)</span>. The formula for <span class="math inline">\(\mu_{k}\)</span> is given as <span class="math display">\[\mu_{k} = \mathrm{E}\left\lbrack {(X - \mu)}^{k} \right\rbrack = \int_{0}^{\infty}{\left( x - \mu \right)^{k}f_{X}\left( x \right) dx }.\]</span> The second central moment <span class="math inline">\(\mu_{2}\)</span> defines the variance of <span class="math inline">\(X\)</span>, denoted by <span class="math inline">\(\sigma^{2}\)</span>. The square root of the variance is the standard deviation <span class="math inline">\(\sigma\)</span>. A further characterization of the shape of the distribution includes its degree of symmetry as well as its flatness compared to the normal distribution. The ratio of the third central moment to the cube of the standard deviation <span class="math inline">\(\left( \mu_{3} / \sigma^{3} \right)\)</span> defines the coefficient of skewness which is a measure of symmetry. A positive coefficient of skewness indicates that the distribution is skewed to the right (positively skewed). The ratio of the fourth central moment to the fourth power of the standard deviation <span class="math inline">\(\left(\mu_{4} / \sigma^{4} \right)\)</span> defines the coefficient of kurtosis. The normal distribution has a coefficient of kurtosis of 3. Distributions with a coefficient of kurtosis greater than 3 have heavier tails and higher peak than the normal, whereas distributions with a coefficient of kurtosis less than 3 have lighter tails and are flatter.</p>
<p><strong>Example 3.1.1. SOA Exam Question.</strong> Assume that the <em>rv</em> <span class="math inline">\(X\)</span> has a gamma distribution with mean 8 and skewness 1. Find the variance of <span class="math inline">\(X\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleLoss.1.1" href="javascript:toggleEX('toggleExampleLoss.1.1','displayTextExampleLoss.1.1');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExampleLoss.1.1" style="display: none">
<p><strong>Solution.</strong> The probability density function of <span class="math inline">\(X\)</span> is given by <span class="math display">\[f_{X}\left( x \right) = \frac{\left( x / \theta \right)^{\alpha}}{x\Gamma\left( \alpha \right)} e^{- x / \theta} \]</span> for <span class="math inline">\(x &gt; 0\)</span>. For <span class="math inline">\(\alpha&gt;0\)</span>, the <em>k</em>-th raw moment is <span class="math display">\[\mu_{k}^{\prime} = E\left( X^{k} \right) = \int_{0}^{\infty}{\frac{1}{\Gamma\left( \alpha \right)\theta^{\alpha}}x^{k + \alpha - 1}e^{- x / \theta} dx} = \frac{\Gamma\left( k + \alpha \right)}{\Gamma\left( \alpha \right)}\theta^{k}\]</span> Given <span class="math inline">\(\Gamma\left( r + 1 \right) = r\Gamma\left( r \right)\)</span> and <span class="math inline">\(\Gamma\left( 1 \right) = 1\)</span>, then <span class="math inline">\(\mu_{1}^{\prime} = E\left( X \right) = \alpha\theta\)</span>, <span class="math inline">\(\mu_{2}^{\prime} = E\left( X^{2} \right) = \left( \alpha + 1 \right)\alpha\theta^{2}\)</span>, <span class="math inline">\(\mu_{3}^{\prime} = E\left( X^{3} \right) = \left( \alpha + 2 \right)\left( \alpha + 1 \right)\alpha\theta^{3}\)</span>, and <span class="math inline">\(\mathrm{Var}\left( X \right) = (\alpha + 1)\alpha\theta^2 - (\alpha\theta)^2 = \alpha\theta^{2}\)</span>.</p>
<p><span class="math display">\[\text{Skewness}  = \frac{E\left\lbrack {(X - \mu_{1}^{\prime})}^{3} \right\rbrack}{{\mathrm{Var}\left( X \right)}^{3/2}} = \frac{\mu_{3}^{\prime} - 3\mu_{2}^{\prime}\mu_{1}^{\prime} + 2{\mu_{1}^{\prime}}^{3}}{{\mathrm{Var}\left( X \right)}^{3/2}} \\
 = \frac{\left( \alpha + 2 \right)\left( \alpha + 1 \right)\alpha\theta^{3} - 3\left( \alpha + 1 \right)\alpha^{2}\theta^{3} + 2\alpha^{3}\theta^{3}}{\left( \alpha\theta^{2} \right)^{3/2}} = \frac{2}{\alpha^{1/2}} = 1\]</span></p>
<p>Hence, <span class="math inline">\(\alpha = 4\)</span>. Since, <span class="math inline">\(E\left( X \right) = \alpha\theta = 8\)</span>, then <span class="math inline">\(\theta = 2\)</span> and finally, <span class="math inline">\(\mathrm{Var}\left( X \right) = \alpha\theta^{2} = 16\)</span>.</p>
</div>
<hr />
</div>
<div id="quantiles" class="section level3">
<h3><span class="header-section-number">3.1.2</span> Quantiles</h3>
<p>Percentiles can also be used to describe the characteristics of the distribution of <span class="math inline">\(X\)</span>. The 100p<em>th</em> percentile of the distribution of <span class="math inline">\(X\)</span>, denoted by <span class="math inline">\(\pi_{p}\)</span>, is the value of <span class="math inline">\(X\)</span> which satisfies <span class="math display">\[F_{X}\left( {\pi_{p}}- \right) \leq p \leq F_{X}\left( \pi_{p} \right) ,\]</span> for <span class="math inline">\(0 \leq p \leq 1\)</span> where <span class="math inline">\(\pi_{p}-\)</span> refers to the value of X as it increases approaching <span class="math inline">\(\pi_{p}\)</span> from the left or from below.</p>
<p>The 50-th percentile or the middle point of the distribution, <span class="math inline">\(\pi_{0.5}\)</span>, is the median. Unlike discrete random variables, percentiles of continuous variables are distinct.</p>
<p><strong>Example 3.1.1. SOA Exam Question.</strong> Let <span class="math inline">\(X\)</span> be a continuous random variable with density function <span class="math inline">\(f_{X}\left( x \right) = \theta e^{- \theta x}\)</span>, for <span class="math inline">\(x &gt; 0\)</span> and 0 elsewhere. If the median of this distribution is <span class="math inline">\(\frac{1}{3}\)</span>, find <span class="math inline">\(\theta\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleLoss.1.2" href="javascript:toggleEX('toggleExampleLoss.1.2','displayTextExampleLoss.1.2');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExampleLoss.1.2" style="display: none">
<p><strong>Solution.</strong></p>
<p>The distribution function is <span class="math inline">\(F_{X}\left( x \right) = 1 - e^{- \theta x}\)</span>. So, <span class="math inline">\(F_{X}\left( \pi_{0.5} \right) = 1 - e^{- \theta\pi_{0.5}} = 0.5\)</span>. As, <span class="math inline">\(\pi_{0.5} = \frac{1}{3}\)</span>, we have <span class="math inline">\(F_X\left(\frac{1}{3}\right) = 1 - e^{-\theta / 3} = 0.5\)</span> and <span class="math inline">\(\theta = 3 \ln 2\)</span>.</p>
</div>
<hr />
</div>
<div id="moment-generating-function" class="section level3">
<h3><span class="header-section-number">3.1.3</span> Moment Generating Function</h3>
<p>The moment generating function, denoted by <span class="math inline">\(M_{X}\left( t \right)\)</span> uniquely characterizes the distribution of <span class="math inline">\(X\)</span>. While it is possible for two different distributions to have the same moments and yet still differ, this is not the case with the moment generating function. That is, if two random variables have the same moment generating function, then they have the same distribution. The moment generating is a real function whose <em>k</em>-th derivative at zero is equal to the <em>k</em>-th raw moment of <span class="math inline">\(X\)</span>. The moment generating function is given by <span class="math display">\[M_{X}\left( t \right) = \mathrm{E}\left( e^{\text{tX}} \right) = \int_{0}^{\infty}{e^{\text{tx}}f_{X}\left( x \right) dx }\]</span> for all <span class="math inline">\(t\)</span> for which the expected value exists.</p>
<p><strong>Example 3.1.3. SOA Exam Question.</strong> The random variable <span class="math inline">\(X\)</span> has an exponential distribution with mean <span class="math inline">\(\frac{1}{b}\)</span>. It is found that <span class="math inline">\(M_{X}\left( - b^{2} \right) = 0.2\)</span>. Find <span class="math inline">\(b\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleLoss.1.3" href="javascript:toggleEX('toggleExampleLoss.1.3','displayTextExampleLoss.1.3');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExampleLoss.1.3" style="display: none">
<p><strong>Solution.</strong></p>
<p>With <span class="math inline">\(X \sim Exp \left( \frac{1}{b}\right)\)</span>, <span class="math display">\[M_{X}\left( t \right) = E\left( e^{\text{tX}} \right) = \int_{0}^{\infty}{e^{\text{tx}}be^{- bx} dx} = \int_{0}^{\infty}{be^{- x\left( b - t \right)} dx} = \frac{b}{\left( b - t \right)}.\]</span></p>
<p>Then, <span class="math display">\[M_{X}\left( - b^{2} \right) = \frac{b}{\left( b + b^{2} \right)} = \frac{1}{\left( 1 + b \right)} = 0.2.\]</span> Thus, <span class="math inline">\(b = 4\)</span>.</p>
</div>
<hr />
<p><strong>Example 3.1.4. SOA Exam Question.</strong> Let <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span> be independent <span class="math inline">\(\text{Ga}\left( \alpha_{i},\theta \right)\)</span> random variables. Find the distribution of <span class="math inline">\(S = \sum_{i = 1}^{n}X_{i}\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleLoss.1.4" href="javascript:toggleEX('toggleExampleLoss.1.4','displayTextExampleLoss.1.4');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExampleLoss.1.4" style="display: none">
<p><strong>Solution.</strong></p>
<p>The moment generating function of <span class="math inline">\(S\)</span> is <span class="math display">\[M_{S}\left( t \right) = \text{E}\left( e^{\text{tS}} \right) = E\left( e^{t\sum_{i = 1}^{n}X_{i}} \right) \\
= E\left( \prod_{i = 1}^{n}e^{tX_{i}} \right)\]</span> using independence we get<br />
<span class="math display">\[= \prod_{i = 1}^{n}{E\left( e^{tX_{i}} \right) = \prod_{i = 1}^{n}{M_{X_{i}}\left( t \right)}} .\]</span></p>
<p>The moment generating function of <span class="math inline">\(X_{i}\)</span> is <span class="math inline">\(M_{X_{i}}\left( t \right) = \left( 1 - \theta t \right)^{- \alpha_{i}}\)</span>. Then, <span class="math display">\[M_{S}\left( t \right) = \prod_{i = 1}^{n}\left( 1 - \theta t \right)^{- \alpha_{i}} = \left( 1 - \theta t \right)^{- \sum_{i = 1}^{n}\alpha_{i}}, \]</span> indicating that <span class="math inline">\(S\sim Ga\left( \sum_{i = 1}^{n}\alpha_{i},\theta \right)\)</span>. This is a demonstration of how we can use the uniqueness property of the moment generating function to determine the probability distribution of a random variable.</p>
<p>By finding the first and second derivatives of <span class="math inline">\(M_{S}\left( t \right)\)</span> at zero, we can show that <span class="math inline">\(E\left( S \right) = \left. \ \frac{\partial M_{S}\left( t \right)}{\partial t} \right|_{t = 0} = \alpha\theta\)</span> where <span class="math inline">\(\alpha = \sum_{i = 1}^{n}\alpha_{i}\)</span>, and <span class="math display">\[E\left( S^{2} \right) = \left. \ \frac{\partial^{2}M_{S}\left( t \right)}{\partial t^{2}} \right|_{t = 0} = \left( \alpha + 1 \right)\alpha\theta^{2}.\]</span> Hence, <span class="math inline">\(\mathrm{Var}\left( S \right) = \alpha\theta^{2}\)</span>.</p>
</div>
<hr />
</div>
<div id="probability-generating-function" class="section level3">
<h3><span class="header-section-number">3.1.4</span> Probability Generating Function</h3>
<p>The probability generating function, denoted by <span class="math inline">\(P_{X}\left( z \right)\)</span>, also uniquely characterizes the distribution of <span class="math inline">\(X\)</span>. It is defined as <span class="math display">\[P_{X}\left( z \right) = \mathrm{E}\left( z^{X} \right) = \int_{0}^{\infty}{z^{x}f_{X}\left( x \right) dx}\]</span> for all <span class="math inline">\(z\)</span> for which the expected value exists.</p>
<p>We can also use the probability generating function to generate moments of <span class="math inline">\(X\)</span>. By taking the <em>k</em>-th derivative of <span class="math inline">\(P_{X}\left( z \right)\)</span> with respect to <span class="math inline">\(z\)</span> and evaluating it at <span class="math inline">\(z\  = \ 1\)</span>, we get <span class="math inline">\(\mathrm{E}\left\lbrack X\left( X - 1 \right)\cdots\left( X - k + 1 \right) \right\rbrack .\)</span></p>
<p>The probability generating function is more useful for discrete <em>rv</em>s and was introduced in Section <a href="C-Frequency-Modeling.html#S:generating-functions">2.2.2</a>.</p>
</div>
</div>
<div id="S:ContinuousDistn" class="section level2">
<h2><span class="header-section-number">3.2</span> Continuous Distributions for Modeling Loss Severity</h2>
<p>In this section we explain the characteristics of distributions suitable for modeling severity of losses, including gamma, Pareto, Weibull and generalized beta distribution of the second kind. Applications for which each distribution may be used are identified.</p>
<div id="gamma-distribution" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Gamma Distribution</h3>
<p>Recall that the traditional approach in modelling losses is to fit separate models for claim frequency and claim severity. When frequency and severity are modeled separately it is common for actuaries to use the Poisson distribution for claim count and the gamma distribution to model severity. An alternative approach for modelling losses that has recently gained popularity is to create a single model for pure premium (average claim cost) that will be described in Chapter <a href="C-ModelSelection.html#C:ModelSelection">4</a>.</p>
<p>The continuous variable <span class="math inline">\(X\)</span> is said to have the gamma distribution with shape parameter <span class="math inline">\(\alpha\)</span> and scale parameter <span class="math inline">\(\theta\)</span> if its probability density function is given by <span class="math display">\[f_{X}\left( x \right) = \frac{\left( x/ \theta  \right)^{\alpha}}{x\Gamma\left( \alpha \right)}\exp \left( -x/ \theta \right) \ \ \ \text{for } x &gt; 0 .\]</span> Note that <span class="math inline">\(\ \alpha &gt; 0,\ \theta &gt; 0\)</span>.</p>
<p>The two panels in Figure <a href="C-Severity.html#fig:gammapdf">3.1</a> demonstrate the effect of the scale and shape parameters on the gamma density function.</p>
<div class="figure" style="text-align: center"><span id="fig:gammapdf"></span>
<img src="LossDataAnalytics_files/figure-html/gammapdf-1.png" alt="Gamma Densities. The left-hand panel is with shape=2 and Varying Scale. 
 The right-hand panel is with scale=100 and Varying Shape." width="120%" />
<p class="caption">
Figure 3.1: Gamma Densities. The left-hand panel is with shape=2 and Varying Scale. The right-hand panel is with scale=100 and Varying Shape.
</p>
</div>
<h5 style="text-align: center;">
<a id="display.gammascale.1" href="javascript:togglecode('display.gammascale.2','display.gammascale.1');"><i><strong>R Code for Gamma Density Plots</strong></i></a>
</h5>
<div id="display.gammascale.2" style="display: none">
<pre><code>par(mfrow=c(1, 2), mar = c(4, 4, .1, .1))

# Varying Scale Gamma Densities
scaleparam &lt;- seq(100, 250, by = 50)
shapeparam &lt;- 2:5
x &lt;- seq(0, 1000, by = 1)
fgamma &lt;- dgamma(x, shape = 2, scale = scaleparam[1])
plot(x, fgamma, type = &quot;l&quot;, ylab = &quot;Gamma Density&quot;)
for(k in 2:length(scaleparam)){
  fgamma &lt;- dgamma(x,shape = 2, scale = scaleparam[k])
  lines(x,fgamma, col = k)
}
legend(&quot;topright&quot;, c(&quot;scale=100&quot;, &quot;scale=150&quot;, &quot;scale=200&quot;, &quot;scale=250&quot;), lty=1, col = 1:4)

# Varying Shape Gamma Densities
fgamma &lt;- dgamma(x, shape = shapeparam[1], scale = 100)
plot(x, fgamma, type = &quot;l&quot;, ylab = &quot;Gamma Density&quot;)
for(k in 2:length(shapeparam)){
  fgamma &lt;- dgamma(x,shape = shapeparam[k], scale = 100)
  lines(x,fgamma, col = k)
}
legend(&quot;topright&quot;, c(&quot;shape=2&quot;, &quot;shape=3&quot;, &quot;shape=4&quot;, &quot;shape=5&quot;), lty=1, col = 1:4)</code></pre>
</div>
<p>When <span class="math inline">\(\alpha = 1\)</span> the gamma reduces to an exponential distribution and when <span class="math inline">\(\alpha = \frac{n}{2}\)</span> and <span class="math inline">\(\theta = 2\)</span> the gamma reduces to a chi-square distribution with <span class="math inline">\(n\)</span> degrees of freedom. As we will see in Section <a href="C-AppA.html#S:AppA:HT">15.4</a>, the chi-square distribution is used extensively in statistical hypothesis testing.</p>
<p>The distribution function of the gamma model is the incomplete gamma function, denoted by <span class="math inline">\(\Gamma\left(\alpha; \frac{x}{\theta} \right)\)</span>, and defined as <span class="math display">\[F_{X}\left( x \right) = \Gamma\left( \alpha; \frac{x}{\theta} \right) = \frac{1}{\Gamma\left( \alpha \right)}\int_{0}^{x /\theta}t^{\alpha - 1}e^{- t}\text{dt}\]</span> <span class="math inline">\(\alpha &gt; 0,\ \theta &gt; 0\)</span>. For an integer <span class="math inline">\(\alpha\)</span>, it can be written as <span class="math inline">\(\Gamma\left( \alpha; \frac{x}{\theta} \right) = 1 - e^{-x/\theta}\sum_{k = 0}^{\alpha-1}\frac{(x/\theta)^k}{k!}\)</span>.</p>
<p>The <span class="math inline">\(k\)</span>-th moment of the gamma distributed random variable for any positive <span class="math inline">\(k\)</span> is given by <span class="math display">\[\mathrm{E}\left( X^{k} \right) = \theta^{k} \frac{\Gamma\left( \alpha + k \right)}{\Gamma\left( \alpha \right)}  \ \ \ \text{for } k &gt; 0.\]</span> The mean and variance are given by <span class="math inline">\(\mathrm{E}\left( X \right) = \alpha\theta\)</span> and <span class="math inline">\(\mathrm{Var}\left( X \right) = \alpha\theta^{2}\)</span>, respectively.</p>
<p>Since all moments exist for any positive <span class="math inline">\(k\)</span>, the gamma distribution is considered a light tailed distribution, which may not be suitable for modeling risky assets as it will not provide a realistic assessment of the likelihood of severe losses.</p>
</div>
<div id="pareto-distribution" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Pareto Distribution</h3>
<p>The Pareto distribution, named after the Italian economist Vilfredo Pareto (1843-1923), has many economic and financial applications. It is a positively skewed and heavy-tailed distribution which makes it suitable for modeling income, high-risk insurance claims and severity of large casualty losses. The survival function of the Pareto distribution which decays slowly to zero was first used to describe the distribution of income where a small percentage of the population holds a large proportion of the total wealth. For extreme insurance claims, the tail of the severity distribution (losses in excess of a threshold) can be modeled using a Pareto distribution.</p>
<p>The continuous variable <span class="math inline">\(X\)</span> is said to have the Pareto distribution with shape parameter <span class="math inline">\(\alpha\)</span> and scale parameter <span class="math inline">\(\theta\)</span> if its <em>pdf</em> is given by <span class="math display">\[f_{X}\left( x \right) = \frac{\alpha\theta^{\alpha}}{\left( x + \theta \right)^{\alpha + 1}} \ \ \  x  &gt;  0,\ \alpha &gt;  0,\ \theta &gt; 0.\]</span> The two panels in Figure <a href="C-Severity.html#fig:Paretopdf">3.2</a> demonstrate the effect of the scale and shape parameters on the Pareto density function.</p>
<div class="figure" style="text-align: center"><span id="fig:Paretopdf"></span>
<img src="LossDataAnalytics_files/figure-html/Paretopdf-1.png" alt="Pareto Densities. The left-hand panel is with scale=2000 and Varying Shape.  The right-hand panel is with shape=3 and ,Varying Scale" width="120%" />
<p class="caption">
Figure 3.2: Pareto Densities. The left-hand panel is with scale=2000 and Varying Shape. The right-hand panel is with shape=3 and ,Varying Scale
</p>
</div>
<h5 style="text-align: center;">
<a id="display.Paretoscale.1" href="javascript:togglecode('display.Paretoscale.2','display.Paretoscale.1');"><i><strong>R Code for Pareto Density Plots</strong></i></a>
</h5>
<div id="display.Paretoscale.2" style="display: none">
<pre><code>library(VGAM)

par(mfrow=c(1, 2), mar = c(4, 4, .1, .1))

# Varying Shape Pareto Densities
x &lt;- seq(1, 3000, by = 1)
scaleparam &lt;- seq(2000, 3500, 500)
shapeparam &lt;- 1:4

# varying the shape parameter
plot(x, dparetoII(x, loc=0, shape = shapeparam[1], scale = 2000), ylim=c(0,0.002),type = &quot;l&quot;, ylab = &quot;Pareto density&quot;)
for(k in 2:length(shapeparam)){
  lines(x, dparetoII(x, loc=0, shape = shapeparam[k], scale = 2000), col = k)
}
legend(&quot;topright&quot;, c(expression(alpha~&#39;=1&#39;), expression(alpha~&#39;=2&#39;), expression(alpha~&#39;=3&#39;), expression(alpha~&#39;=4&#39;)), lty=1, col = 1:4)

# Varying Scale Pareto Densities
plot(x, dparetoII(x, loc=0, shape = 3, scale = scaleparam[1]), type = &quot;l&quot;, ylab = &quot;Pareto density&quot;)
for(k in 2:length(scaleparam)){
  lines(x, dparetoII(x, loc=0, shape = 3, scale = scaleparam[k]), col = k)
}
legend(&quot;topright&quot;, c(expression(theta~&#39;=2000&#39;), expression(theta~&#39;=2500&#39;), expression(theta~&#39;=3000&#39;), expression(theta~&#39;=3500&#39;)), lty=1, col = 1:4)
</code></pre>
</div>
<p>The distribution function of the Pareto distribution is given by <span class="math display">\[F_{X}\left( x \right) = 1 - \left( \frac{\theta}{x + \theta} \right)^{\alpha}  \ \ \ x &gt; 0,\ \alpha &gt; 0,\ \theta &gt; 0.\]</span> It can be easily seen that the hazard function of the Pareto distribution is a decreasing function in <span class="math inline">\(x\)</span>, another indication that the distribution is heavy tailed. The hazard function reveals information about the tail distribution and is often used to model data distributions in survival analysis. The hazard function is defined as the instantaneous potential that the event of interest occurs within a very narrow time frame.</p>
<p>The <span class="math inline">\(k\)</span>-th moment of the Pareto distributed random variable exists, if and only if, <span class="math inline">\(\alpha &gt; k\)</span>. If <span class="math inline">\(k\)</span> is a positive integer then <span class="math display">\[\mathrm{E}\left( X^{k} \right) = \frac{k!\theta^{k}}{\left( \alpha - 1 \right)\cdots\left( \alpha - k \right)} \ \ \ \alpha &gt; k.\]</span> The mean and variance are given by <span class="math display">\[\mathrm{E}\left( X \right) = \frac{\theta}{\alpha - 1} \ \ \ \text{for } \alpha &gt; 1\]</span> and <span class="math display">\[\mathrm{Var}\left( X \right) = \frac{\alpha\theta^{2}}{\left( \alpha - 1 \right)^{2}\left( \alpha - 2 \right)} \ \ \ \text{for } \alpha &gt; 2,\]</span>respectively.</p>
<strong>Example 3.2.1. </strong> The claim size of an insurance portfolio follows the Pareto distribution with mean and variance of 40 and 1800 respectively. Find
<ol type="a">
<li>
The shape and scale parameters.
</li>
<li>
The 95-th percentile of this distribution.
</li>
</ol>
<h5 style="text-align: center;">
<a id="displayTextExampleLoss.2.1" href="javascript:toggleEX('toggleExampleLoss.2.1','displayTextExampleLoss.2.1');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExampleLoss.2.1" style="display: none">
<p><strong>Solution.</strong></p>
<p><strong>a.</strong> As, <span class="math inline">\(X\sim Pa(\alpha,\theta)\)</span>, we have <span class="math inline">\(\mathrm{E}\left( X \right) = \frac{\theta}{\alpha - 1} = 40\)</span> and <span class="math inline">\(\mathrm{Var}\left( X \right) = \frac{\alpha\theta^{2}}{\left( \alpha - 1 \right)^{2}\left( \alpha - 2 \right)} = 1800\)</span>. By dividing the square of the first equation by the second we get <span class="math inline">\(\frac{\alpha - 2}{\alpha} = \frac{40^{2}}{1800}\)</span>. Thus, <span class="math inline">\(\alpha = 18.02\)</span> and <span class="math inline">\(\theta = 680.72\)</span>.<br />
<strong>b.</strong> The 95-th percentile, <span class="math inline">\(\pi_{0.95}\)</span>, satisfies the equation <span class="math display">\[F_{X}\left( \pi_{0.95} \right) = 1 - \left( \frac{680.72}{\pi_{0.95} + 680.72} \right)^{18.02} = 0.95.\]</span> Thus, <span class="math inline">\(\pi_{0.95} = 122.96\)</span>.</p>
</div>
<hr />
</div>
<div id="weibull-distribution" class="section level3">
<h3><span class="header-section-number">3.2.3</span> Weibull Distribution</h3>
<p>The Weibull distribution, named after the Swedish physicist Waloddi Weibull (1887-1979) is widely used in reliability, life data analysis, weather forecasts and general insurance claims. Truncated data arise frequently in insurance studies. The Weibull distribution is particularly useful in modeling left-truncated claim severity distributions. Weibull was used to model excess of loss treaty over automobile insurance as well as earthquake inter-arrival times.</p>
<p>The continuous variable <span class="math inline">\(X\)</span> is said to have the Weibull distribution with shape parameter <span class="math inline">\(\alpha\)</span> and scale parameter <span class="math inline">\(\theta\)</span> if its probability density function is given by <span class="math display">\[f_{X}\left( x \right) = \frac{\alpha}{\theta}\left( \frac{x}{\theta} \right)^{\alpha - 1} \exp \left(- \left( \frac{x}{\theta} \right)^{\alpha}\right) \ \ \ x &gt; 0,\ \alpha &gt; 0,\ \theta &gt; 0.\]</span> The two panels Figure <a href="C-Severity.html#fig:Weibullpdf">3.3</a> demonstrate the effects of the scale and shape parameters on the Weibull density function.</p>
<div class="figure" style="text-align: center"><span id="fig:Weibullpdf"></span>
<img src="LossDataAnalytics_files/figure-html/Weibullpdf-1.png" alt="Weibull Densities. The left-hand panel is with shape=3 and Varying Scale. The right-hand panel is with scale=100 and Varying Shape." width="120%" />
<p class="caption">
Figure 3.3: Weibull Densities. The left-hand panel is with shape=3 and Varying Scale. The right-hand panel is with scale=100 and Varying Shape.
</p>
</div>
<h5 style="text-align: center;">
<a id="display. Weibullscale.1" href="javascript:togglecode('display. Weibullscale.2','display.Weibullscale.1');"><i><strong>R Code for Weibull Density Plots</strong></i></a>
</h5>
<div id="display. Weibullscale.2" style="display: none">
<pre><code>par(mfrow=c(1, 2), mar = c(4, 4, .1, .1))

# Varying Scale Weibull Densities
z&lt;- seq(0,400,by=1)
scaleparam &lt;- seq(50,200,50)
shapeparam &lt;- seq(1.5,3,0.5)
plot(z, dweibull(z, shape = 3, scale = scaleparam[1]), type = &quot;l&quot;, ylab = &quot;Weibull density&quot;)
for(k in 2:length(scaleparam)){
  lines(z,dweibull(z,shape = 3, scale = scaleparam[k]), col = k)}
legend(&quot;topright&quot;, c(&quot;scale=50&quot;, &quot;scale=100&quot;, &quot;scale=150&quot;, &quot;scale=200&quot;), lty=1, col = 1:4)

# Varying Shape Weibull Densities
plot(z, dweibull(z, shape = shapeparam[1], scale = 100), ylim=c(0,0.012), type = &quot;l&quot;, ylab = &quot;Weibull density&quot;)
for(k in 2:length(shapeparam)){
  lines(z,dweibull(z,shape = shapeparam[k], scale = 100), col = k)}
legend(&quot;topright&quot;, c(&quot;shape=1.5&quot;, &quot;shape=2&quot;, &quot;shape=2.5&quot;, &quot;shape=3&quot;), lty=1, col = 1:4)</code></pre>
</div>
<p>The distribution function of the Weibull distribution is given by <span class="math display">\[F_{X}\left( x \right) = 1 - e^{- \left( x / \theta \right)^{\alpha}}  \ \ \ x &gt;  0,\ \alpha &gt;  0,\ \theta &gt; 0.\]</span></p>
<p>It can be easily seen that the shape parameter <span class="math inline">\(\alpha\)</span> describes the shape of the hazard function of the Weibull distribution. The hazard function is a decreasing function when <span class="math inline">\(\alpha &lt; 1\)</span>, constant when <span class="math inline">\(\alpha = 1\)</span> and increasing when <span class="math inline">\(\alpha &gt; 1\)</span>. This behavior of the hazard function makes the Weibull distribution a suitable model for a wide variety of phenomena such as weather forecasting, electrical and industrial engineering, insurance modeling and financial risk analysis.</p>
<p>The <span class="math inline">\(k\)</span>-th moment of the Weibull distributed random variable is given by <span class="math display">\[\mathrm{E}\left( X^{k} \right) = \theta^{k}\Gamma\left( 1 + \frac{k}{\alpha} \right) .\]</span></p>
<p>The mean and variance are given by <span class="math display">\[\mathrm{E}\left( X \right) = \theta\Gamma\left( 1 + \frac{1}{\alpha} \right)\]</span> and <span class="math display">\[\mathrm{Var}(X)= \theta^{2}\left( \Gamma\left( 1 + \frac{2}{\alpha} \right)  - \left\lbrack \Gamma\left( 1 + \frac{1}{\alpha} \right) \right\rbrack  ^{2}\right),\]</span> respectively.</p>
<p><strong>Example 3.2.2.</strong> Suppose that the probability distribution of the lifetime of AIDS patients (in months) from the time of diagnosis is described by the Weibull distribution with shape parameter 1.2 and scale parameter 33.33.</p>
<ol type="a">
<li>
Find the probability that a randomly selected person from this population survives at least 12 months,
</li>
<li>
A random sample of 10 patients will be selected from this population. What is the probability that at most two will die within one year of diagnosis.
</li>
<li>
Find the 99-th percentile of the distribution of lifetimes.
</li>
</ol>
<h5 style="text-align: center;">
<a id="displayTextExampleLoss.2.2" href="javascript:toggleEX('toggleExampleLoss.2.2','displayTextExampleLoss.2.2');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExampleLoss.2.2" style="display: none">
<p><strong>Solution.</strong></p>
<p><strong>a.</strong> Let <span class="math inline">\(X \sim Wei \left( 1.2,33.33 \right)\)</span> be the lifetime of AIDS patients (in months). We have, <span class="math display">\[{\Pr\left( X \geq 12 \right) = S}_{X}\left( 12 \right) = e^{- \left( \frac{12}{33.33} \right)^{1.2}} = 0.746.\]</span> <strong>b.</strong> Let <span class="math inline">\(Y\)</span> be the number of patients who die within one year of diagnosis. Then, <span class="math inline">\(Y\sim Bin\left( 10,\ 0.254 \right)\)</span> and <span class="math inline">\(\Pr\left( Y \leq 2 \right) = 0.514.\)</span></p>
<p><strong>c.</strong> Let <span class="math inline">\(\pi_{0.99}\)</span> denote the 99-th percentile of this distribution. Then, <span class="math display">\[S_{X}\left( \pi_{0.99} \right) = \exp\left\{- \left( \frac{\pi_{0.99}}{33.33} \right)^{1.2}\right\} = 0.01.\]</span> Solving for <span class="math inline">\(\pi_{0.99}\)</span>, we get <span class="math inline">\(\pi_{0.99} = 118.99\)</span>.</p>
</div>
<hr />
</div>
<div id="the-generalized-beta-distribution-of-the-second-kind" class="section level3">
<h3><span class="header-section-number">3.2.4</span> The Generalized Beta Distribution of the Second Kind</h3>
<p>The Generalized Beta Distribution of the Second Kind (GB2) was introduced by <span class="citation">Venter (<a href="#ref-venter1983transformed">1983</a>)</span> in the context of insurance loss modeling and by <span class="citation">McDonald (<a href="#ref-mcdonald1984some">1984</a>)</span> as an income and wealth distribution. It is a four-parameter very flexible distribution that can model positively as well as negatively skewed distributions.</p>
<p>The continuous variable <span class="math inline">\(X\)</span> is said to have the GB2 distribution with parameters <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> if its probability density function is given by <span class="math display">\[f_{X}\left( x \right) = \frac{ax^{a \alpha - 1}}{b^{a \alpha}B\left( \alpha,\beta \right)\left\lbrack 1 + \left( x/b \right)^{a} \right\rbrack^{\alpha + \beta}} \ \ \ \text{for } x &gt; 0,\]</span> <span class="math inline">\(a,b,\alpha,\beta &gt; 0\)</span>, and where the beta function <span class="math inline">\(B\left( \alpha,\beta \right)\)</span> is defined as <span class="math display">\[B\left( \alpha,\beta \right) = \int_{0}^{1}{t^{\alpha - 1}\left( 1 - t \right)^{\beta - 1}}\text{dt}.\]</span></p>
<p>The GB2 provides a model for heavy as well as light tailed data. It includes the exponential, gamma, Weibull, Burr, Lomax, F, chi-square, Rayleigh, lognormal and log-logistic as special or limiting cases. For example, by setting the parameters <span class="math inline">\(a = \alpha = \beta = 1\)</span>, then the GB2 reduces to the log-logistic distribution. When <span class="math inline">\(a = 1\)</span> and <span class="math inline">\(\beta \rightarrow \infty\)</span>, it reduces to the gamma distribution and when <span class="math inline">\(\alpha = 1\)</span> and <span class="math inline">\(\beta \rightarrow \infty\)</span>, it reduces to the Weibull distribution.</p>
<p>The <span class="math inline">\(k\)</span>-th moment of the GB2 distributed random variable is given by <span class="math display">\[\mathrm{E}\left( X^{k} \right) = \frac{b^{k}\left( \alpha + \frac{k}{a},\beta - \frac{k}{a} \right)}{\left( \alpha,\beta \right)}, \ \ \ k &gt; 0.\]</span> Earlier applications of the GB2 were on income data and more recently have been used to model long-tailed claims data. GB2 was used to model different types of automobile insurance claims, severity of fire losses as well as medical insurance claim data.</p>
</div>
</div>
<div id="MethodsCreation" class="section level2">
<h2><span class="header-section-number">3.3</span> Methods of Creating New Distributions</h2>
<p>In this section we</p>
<ul>
<li>understand connections among the distributions;</li>
<li>give insights into when a distribution is preferred when compared to alternatives;</li>
<li>provide foundations for creating new distributions.</li>
</ul>
<div id="functions-of-random-variables-and-their-distributions" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Functions of Random Variables and their Distributions</h3>
<p>In Section <a href="C-Severity.html#S:ContinuousDistn">3.2</a> we discussed some elementary known distributions. In this section we discuss means of creating new parametric probability distributions from existing ones. Let <span class="math inline">\(X\)</span> be a continuous random variable with a known probability density function <span class="math inline">\(f_{X}(x)\)</span> and distribution function <span class="math inline">\(F_{X}(x)\)</span>. Consider the transformation <span class="math inline">\(Y = g\left( X \right)\)</span>, where <span class="math inline">\(g(X)\)</span> is a one-to-one transformation defining a new random variable <span class="math inline">\(Y\)</span>. We can use the distribution function technique, the change-of-variable technique or the moment-generating function technique to find the probability density function of the variable of interest <span class="math inline">\(Y\)</span>. In this section we apply the following techniques for creating new families of distributions: (a) multiplication by a constant (b) raising to a power, (c) exponentiation and (d) mixing.</p>
</div>
<div id="multiplication-by-a-constant" class="section level3">
<h3><span class="header-section-number">3.3.2</span> Multiplication by a Constant</h3>
<p>If claim data show change over time then such transformation can be useful to adjust for inflation. If the level of inflation is positive then claim costs are rising, and if it is negative then costs are falling. To adjust for inflation we multiply the cost <span class="math inline">\(X\)</span> by 1+ inflation rate (negative inflation is deflation). To account for currency impact on claim costs we also use a transformation to apply currency conversion from a base to a counter currency.</p>
Consider the transformation <span class="math inline">\(Y = cX\)</span>, where <span class="math inline">\(c &gt; 0\)</span>, then the distribution function of <span class="math inline">\(Y\)</span> is given by <span class="math display">\[F_{Y}\left( y \right) = \Pr\left( Y \leq y \right) = \Pr\left( cX \leq y \right) = \Pr\left( X \leq \frac{y}{c} \right) = F_{X}\left( \frac{y}{c} \right).\]</span> Hence, the probability density function of interest <span class="math inline">\(f_{Y}(y)\)</span> can be written as <span class="math display">\[f_{Y}\left( y \right) = \frac{1}{c}f_{X}\left( \frac{y}{c} \right).\]</span> Suppose that <span class="math inline">\(X\)</span> belongs to a certain set of parametric distributions and define a rescaled version <span class="math inline">\(Y\  = \ cX\)</span>, <span class="math inline">\(c\  &gt; \ 0\)</span>. If <span class="math inline">\(Y\)</span> is in the same set of distributions then the distribution is said to be a scale distribution. When a member of a scale distribution is multiplied by a constant <span class="math inline">\(c\)</span> (<span class="math inline">\(c &gt; 0\)</span>), the scale parameter for this scale distribution meets two conditions:
<ol>
<li>
The parameter is changed by multiplying by <span class="math inline">\(c\)</span>;
</li>
<li>
All other parameters remain unchanged.
</li>
</ol>
<p><strong>Example 3.3.1. SOA Exam Question.</strong> The aggregate losses of Eiffel Auto Insurance are denoted in Euro currency and follow a Lognormal distribution with <span class="math inline">\(\mu = 8\)</span> and <span class="math inline">\(\sigma = 2\)</span>. Given that 1 euro <span class="math inline">\(=\)</span> 1.3 dollars, find the set of lognormal parameters which describe the distribution of Eiffel’s losses in dollars.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleLoss.3.1" href="javascript:toggleEX('toggleExampleLoss.3.1','displayTextExampleLoss.3.1');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExampleLoss.3.1" style="display: none">
<p><strong>Solution.</strong></p>
<p>Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> denote the aggregate losses of Eiffel Auto Insurance in euro currency and dollars respectively. As <span class="math inline">\(Y = 1.3X\)</span>, we have, <span class="math display">\[F_{Y}\left( y \right) = \Pr\left( Y \leq y \right) = \Pr\left( 1.3X \leq y \right) = \Pr\left( X \leq \frac{y}{1.3} \right) = F_{X}\left( \frac{y}{1.3} \right).\]</span></p>
<p><span class="math inline">\(X\)</span> follows a lognormal distribution with parameters <span class="math inline">\(\mu = 8\)</span> and <span class="math inline">\(\sigma = 2\)</span>. The probability density function of <span class="math inline">\(X\)</span> is given by <span class="math display">\[f_{X}\left( x \right) = \frac{1}{x \sigma \sqrt{2\pi}}\exp \left\{- \frac{1}{2}\left( \frac{\ln x - \mu}{\sigma} \right)^{2}\right\} \ \ \ \text{for } x &gt; 0.\]</span> As <span class="math inline">\(\left| \frac{dx}{dy} \right| = \frac{1}{1.3}\)</span>, the probability density function of interest <span class="math inline">\(f_{Y}(y)\)</span> is <span class="math display">\[f_{Y}\left( y \right) = \frac{1}{1.3}f_{X}\left( \frac{y}{1.3} \right) \\
= \frac{1}{1.3}\frac{1.3}{y \sigma \sqrt{2\pi}}\exp \left\{- \frac{1}{2}\left( \frac{\ln\left( y/1.3 \right) - \mu}{\sigma} \right)^{2}\right\} \\
= \frac{1}{y \sigma\sqrt{2\pi}}\exp \left\{- \frac{1}{2}\left( \frac{\ln y - \left( \ln 1.3 + \mu \right)}{\sigma} \right)^{2}\right\}.\]</span> Then <span class="math inline">\(Y\)</span> follows a lognormal distribution with parameters <span class="math inline">\(\ln 1.3 + \mu = 8.26\)</span> and <span class="math inline">\(\sigma = 2.00\)</span>. If we let <span class="math inline">\(\mu = ln(m)\)</span> then it can be easily seen that <span class="math inline">\(m\)</span>=<span class="math inline">\(e^{\mu}\)</span> is the scale parameter which was multiplied by 1.3 while <span class="math inline">\(\sigma\)</span> is the shape parameter that remained unchanged.</p>
</div>
<hr />
<p><strong>Example 3.3.2. SOA Exam Question.</strong> Demonstrate that the gamma distribution is a scale distribution.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleLoss.3.2" href="javascript:toggleEX('toggleExampleLoss.3.2','displayTextExampleLoss.3.2');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExampleLoss.3.2" style="display: none">
<p><strong>Solution.</strong></p>
<p>Let <span class="math inline">\(X\sim Ga(\alpha,\theta)\)</span> and <span class="math inline">\(Y = cX\)</span>. As <span class="math inline">\(\left| \frac{dx}{dy} \right| = \frac{1}{c}\)</span>, then <span class="math display">\[f_{Y}\left( y \right) = \frac{1}{c}f_{X}\left( \frac{y}{c} \right) = \frac{\left( \frac{y}{c\theta} \right)^{\alpha}}{y\Gamma\left( \alpha \right)}\exp \left( - \frac{y}{c\theta} \right)  .\]</span> We can see that <span class="math inline">\(Y\sim Ga(\alpha,c\theta)\)</span> indicating that gamma is a scale distribution and <span class="math inline">\(\theta\)</span> is a scale parameter.</p>
<p>Using the same approach you can demonstrate that other distributions introduced in Section <a href="C-Severity.html#S:ContinuousDistn">3.2</a> are also scale distributions. In actuarial modeling, working with a scale distribution is very convenient because it allows to incorporate the effect of inflation and to accommodate changes in the currency unit.</p>
</div>
<hr />
</div>
<div id="raising-to-a-power" class="section level3">
<h3><span class="header-section-number">3.3.3</span> Raising to a Power</h3>
<p>In the previous section we talked about the flexibility of the Weibull distribution in fitting reliability data. Looking to the origins of the Weibull distribution, we recognize that the Weibull is a power transformation of the exponential distribution. This is an application of another type of transformation which involves raising the random variable to a power.</p>
<p>Consider the transformation <span class="math inline">\(Y = X^{\tau}\)</span>, where <span class="math inline">\(\tau &gt; 0\)</span>, then the distribution function of <span class="math inline">\(Y\)</span> is given by <span class="math display">\[F_{Y}\left( y \right) = \Pr\left( Y \leq y \right) = \Pr\left( X^{\tau} \leq y \right) = \Pr\left( X \leq y^{1/ \tau} \right) = F_{X}\left( y^{1/ \tau} \right).\]</span></p>
<p>Hence, the probability density function of interest <span class="math inline">\(f_{Y}(y)\)</span> can be written as <span class="math display">\[f_{Y}(y) = \frac{1}{\tau} y^{1/ \tau - 1} f_{X}\left( y^{1/ \tau} \right).\]</span> On the other hand, if <span class="math inline">\(\tau &lt; 0\)</span>, then the distribution function of <span class="math inline">\(Y\)</span> is given by <span class="math display">\[F_{Y}\left( y \right) = \Pr\left( Y \leq y \right) = \Pr\left( X^{\tau} \leq y \right) = \Pr\left( X \geq y^{1/ \tau} \right) = 1 - F_{X}\left( y^{1/ \tau} \right), \]</span> and <span class="math display">\[f_{Y}(y) = \left| \frac{1}{\tau} \right|{y^{1/ \tau - 1}f}_{X}\left( y^{1/ \tau} \right).\]</span></p>
<p><strong>Example 3.3.3.</strong> We assume that <span class="math inline">\(X\)</span> follows the exponential distribution with mean <span class="math inline">\(\theta\)</span> and consider the transformed variable <span class="math inline">\(Y = X^{\tau}\)</span>. Show that <span class="math inline">\(Y\)</span> follows the Weibull distribution when <span class="math inline">\(\tau\)</span> is positive and determine the parameters of the Weibull distribution.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleLoss.3.3" href="javascript:toggleEX('toggleExampleLoss.3.3','displayTextExampleLoss.3.3');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExampleLoss.3.3" style="display: none">
<p><strong>Solution.</strong></p>
<p>As <span class="math inline">\(\ X\sim Exp(\theta)\)</span>, we have <span class="math display">\[f_{X}(x) = \frac{1}{\theta}e^{- x/ \theta} \ \ \ \, x &gt; 0.\]</span> Solving for <em>x</em> yields <span class="math inline">\(x = y^{1/\tau}\)</span>. Taking the derivative, we have <span class="math display">\[\left| \frac{dx}{dy} \right| = \frac{1}{\tau}{y^{\frac{1}{\tau}-1}}.\]</span> Thus, <span class="math display">\[f_{Y}\left( y \right) = \frac{1}{\tau}{y^{\frac{1}{\tau} - 1}f}_{X}\left( y^{\frac{1}{\tau}} \right) \\
= \frac{1}{\tau \theta }y^{\frac{1}{\tau} - 1}e^{- \frac{y^{\frac{1}{\tau}}}{\theta}} = \frac{\alpha}{\beta}\left( \frac{y}{\beta} \right)^{\alpha - 1}e^{- \left( y/ \beta \right)^{\alpha}}.\]</span> where <span class="math inline">\(\alpha = \frac{1}{\tau}\)</span> and <span class="math inline">\(\beta = \theta^{\tau}\)</span>. Then, <span class="math inline">\(Y\)</span> follows the Weibull distribution with shape parameter <span class="math inline">\(\alpha\)</span> and scale parameter <span class="math inline">\(\beta\)</span>.</p>
</div>
<hr />
</div>
<div id="exponentiation" class="section level3">
<h3><span class="header-section-number">3.3.4</span> Exponentiation</h3>
<p>The normal distribution is a very popular model for a wide number of applications and when the sample size is large, it can serve as an approximate distribution for other models. If the random variable <span class="math inline">\(X\)</span> has a normal distribution with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^{2}\)</span>, then <span class="math inline">\(Y = e^{X}\)</span> has lognormal distribution with parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^{2}\)</span>. The lognormal random variable has a lower bound of zero, is positively skewed and has a long right tail. A lognormal distribution is commonly used to describe distributions of financial assets such as stock prices. It is also used in fitting claim amounts for automobile as well as health insurance. This is an example of another type of transformation which involves exponentiation.</p>
<p>Consider the transformation <span class="math inline">\(Y = e^{X}\)</span>, then the distribution function of <span class="math inline">\(Y\)</span> is given by <span class="math display">\[F_{Y}\left( y \right) = \Pr\left( Y \leq y \right) = \Pr\left( e^{X} \leq y \right) = \Pr\left( X \leq \ln y \right) = F_{X}\left( \ln y \right).\]</span> Hence, the probability density function of interest <span class="math inline">\(f_{Y}(y)\)</span> can be written as <span class="math display">\[f_{Y}(y) = \frac{1}{y}f_{X}\left( \ln y \right).\]</span></p>
<p><strong>Example 3.3.4. SOA Exam Question.</strong> <span class="math inline">\(X\)</span> has a uniform distribution on the interval <span class="math inline">\((0,\ c)\)</span>. <span class="math inline">\(Y = e^{X}\)</span>. Find the distribution of <span class="math inline">\(Y\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleLoss.3.4" href="javascript:toggleEX('toggleExampleLoss.3.4','displayTextExampleLoss.3.4');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExampleLoss.3.4" style="display: none">
<p><strong>Solution.</strong></p>
<p>We begin with the <em>cdf</em> of <span class="math inline">\(Y\)</span>, <span class="math display">\[F_{Y}\left( y \right) = \Pr\left( Y \leq y \right) = \Pr\left( e^{X} \leq y \right) = \Pr\left( X \leq \ln y \right) = F_{X}\left( \ln y \right).\]</span> Taking the derivative, we have, <span class="math display">\[f_{Y}\left( y \right) = \frac{1}{y}f_{X}\left(\ln y \right) = \frac{1}{\text{cy}}. \]</span> Since <span class="math inline">\(0 &lt; x &lt; c\)</span>, then <span class="math inline">\(1 &lt; y &lt; e^{c}\)</span>.</p>
</div>
<hr />
</div>
<div id="finite-mixtures" class="section level3">
<h3><span class="header-section-number">3.3.5</span> Finite Mixtures</h3>
<p>Mixture distributions represent a useful way of modelling data that are drawn from a heterogeneous population. This parent population can be thought to be divided into multiple subpopulations with distinct distributions.</p>
<div id="two-point-mixture" class="section level4">
<h4><span class="header-section-number">3.3.5.1</span> Two-point Mixture</h4>
<p>If the underlying phenomenon is diverse and can actually be described as two phenomena representing two subpopulations with different modes, we can construct the two point mixture random variable <span class="math inline">\(X\)</span>. Given random variables <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_{2}\)</span>, with probability density functions <span class="math inline">\(f_{X_{1}}\left( x \right)\)</span> and <span class="math inline">\(f_{X_{2}}\left( x \right)\)</span> respectively, the probability density function of <span class="math inline">\(X\)</span> is the weighted average of the component probability density function <span class="math inline">\(f_{X_{1}}\left( x \right)\)</span> and <span class="math inline">\(f_{X_{2}}\left( x \right)\)</span>. The probability density function and distribution function of <span class="math inline">\(X\)</span> are given by <span class="math display">\[f_{X}\left( x \right) = af_{X_{1}}\left( x \right) + \left( 1 - a \right)f_{X_{2}}\left( x \right),\]</span> and <span class="math display">\[F_{X}\left( x \right) = aF_{X_{1}}\left( x \right) + \left( 1 - a \right)F_{X_{2}}\left( x \right),\]</span></p>
<p>for <span class="math inline">\(0 &lt; a &lt;1\)</span>, where the mixing parameters <span class="math inline">\(a\)</span> and <span class="math inline">\((1 - a)\)</span> represent the proportions of data points that fall under each of the two subpopulations respectively. This weighted average can be applied to a number of other distribution related quantities. The <em>k</em>-th moment and moment generating function of <span class="math inline">\(X\)</span> are given by <span class="math inline">\(\mathrm{E}\left( X^{k} \right) = a\mathrm{E}\left( X_{1}^{K} \right) + \left( 1 - a \right)\mathrm{E}\left( X_{2}^{k} \right)\)</span>, and <span class="math display">\[M_{X}\left( t \right) = aM_{X_{1}}\left( t \right) + \left( 1 - a \right)M_{X_{2}}\left( t \right),\]</span> respectively.</p>
<p><strong>Example 3.3.5. SOA Exam Question.</strong> A collection of insurance policies consists of two types. 25% of policies are Type 1 and 75% of policies are Type 2. For a policy of Type 1, the loss amount per year follows an exponential distribution with mean 200, and for a policy of Type 2, the loss amount per year follows a Pareto distribution with parameters <span class="math inline">\(\alpha=3\)</span> and <span class="math inline">\(\theta=200\)</span>. For a policy chosen at random from the entire collection of both types of policies, find the probability that the annual loss will be less than 100, and find the average loss.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleLoss.3.5" href="javascript:toggleEX('toggleExampleLoss.3.5','displayTextExampleLoss.3.5');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExampleLoss.3.5" style="display: none">
<p><strong>Solution.</strong></p>
<p>The two types of losses are the random variables <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>. <span class="math inline">\(X_1\)</span> has an exponential distribution with mean 100, so <span class="math inline">\(F_{X_1}\left(100\right)=1-e^{-\frac{100}{200}}=0.393\)</span>. <span class="math inline">\(X_2\)</span> has a Pareto distribution with parameters <span class="math inline">\(\alpha=3\)</span> and <span class="math inline">\(\theta=200\)</span>, so <span class="math inline">\(F_{X_1}\left(100\right)=1-\left(\frac{200}{100+200}\right)^3=0.704\)</span>. Hence, <span class="math inline">\(F_X\left(100\right)=\left(0.25\times0.393\right)+\left(0.75\times0.704\right)=0.626\)</span>.</p>
<p>The average loss is given by <span class="math display">\[\mathrm{E}\left(X\right)=0.25\mathrm{E}\left(X_1\right)+0.75\mathrm{E}\left(X_2\right)=\left(0.25\times200\right)+\left(0.75\times100\right)=125\]</span>.</p>
</div>
<hr />
</div>
<div id="k-point-mixture" class="section level4">
<h4><span class="header-section-number">3.3.5.2</span> <em>k</em>-point Mixture</h4>
<p>In case of finite mixture distributions, the random variable of interest <span class="math inline">\(X\)</span> has a probability <span class="math inline">\(p_{i}\)</span> of being drawn from homogeneous subpopulation <span class="math inline">\(i\)</span>, where <span class="math inline">\(i = 1,2,\ldots,k\)</span> and <span class="math inline">\(k\)</span> is the initially specified number of subpopulations in our mixture. The mixing parameter <span class="math inline">\(p_{i}\)</span> represents the proportion of observations from subpopulation <span class="math inline">\(i\)</span>. Consider the random variable <span class="math inline">\(X\)</span> generated from <span class="math inline">\(k\)</span> distinct subpopulations, where subpopulation <span class="math inline">\(i\)</span> is modeled by the continuous distribution <span class="math inline">\(f_{X_{i}}\left( x \right)\)</span>. The probability distribution of <span class="math inline">\(X\)</span> is given by <span class="math display">\[f_{X}\left( x \right) = \sum_{i = 1}^{k}{p_{i}f_{X_{i}}\left( x \right)},\]</span> where <span class="math inline">\(0 &lt; p_{i} &lt; 1\)</span> and <span class="math inline">\(\sum_{i = 1}^{k} p_{i} = 1\)</span>.</p>
<p>This model is often referred to as a <em>finite mixture</em> or a <span class="math inline">\(k\)</span>-point mixture. The distribution function, <span class="math inline">\(r\)</span>-th moment and moment generating functions of the <span class="math inline">\(k\)</span>-th point mixture are given as</p>
<p><span class="math display">\[F_{X}\left( x \right) = \sum_{i = 1}^{k}{p_{i}F_{X_{i}}\left( x \right)},\]</span> <span class="math display">\[\mathrm{E}\left( X^{r} \right) = \sum_{i = 1}^{k}{p_{i}\mathrm{E}\left( X_{i}^{r} \right)}, \text{and}\]</span> <span class="math display">\[M_{X}\left( t \right) = \sum_{i = 1}^{k}{p_{i}M_{X_{i}}\left( t \right)},\]</span> respectively.</p>
<p><strong>Example 3.3.6. SOA Exam Question.</strong> <span class="math inline">\(Y_{1}\)</span> is a mixture of <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_{2}\)</span> with mixing weights <span class="math inline">\(a\)</span> and <span class="math inline">\((1 - a)\)</span>. <span class="math inline">\(Y_{2}\)</span> is a mixture of <span class="math inline">\(X_{3}\)</span> and <span class="math inline">\(X_{4}\)</span> with mixing weights <span class="math inline">\(b\)</span> and <span class="math inline">\((1 - b)\)</span>. <span class="math inline">\(Z\)</span> is a mixture of <span class="math inline">\(Y_{1}\)</span> and <span class="math inline">\(Y_{2}\)</span> with mixing weights <span class="math inline">\(c\)</span> and <span class="math inline">\((1 - c)\)</span>.</p>
<p>Show that <span class="math inline">\(Z\)</span> is a mixture of <span class="math inline">\(X_{1}\)</span>, <span class="math inline">\(X_{2}\)</span>, <span class="math inline">\(X_{3}\)</span> and <span class="math inline">\(X_{4}\)</span>, and find the mixing weights.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleLoss.3.6" href="javascript:toggleEX('toggleExampleLoss.3.6','displayTextExampleLoss.3.6');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExampleLoss.3.6" style="display: none">
<p><strong>Solution.</strong> Applying the formula for a mixed distribution, we get <span class="math display">\[f_{Y_{1}}\left( x \right) = af_{X_{1}}\left( x \right) + \left( 1 - a \right)f_{X_{2}}\left( x \right)\]</span></p>
<p><span class="math display">\[f_{Y_{2}}\left( x \right) = bf_{X_{3}}\left( x \right) + \left( 1 - b \right)f_{X_{4}}\left( x \right)\]</span></p>
<p><span class="math display">\[f_{Z}\left( x \right) = cf_{Y_{1}}\left( x \right) + \left( 1 - c \right)f_{Y_{2}}\left( x \right)\]</span></p>
<p>Substituting the first two equations into the third, we get</p>
<p><span class="math display">\[f_{Z}\left( x \right) = c\left\lbrack af_{X_{1}}\left( x \right) + \left( 1 - a \right)f_{X_{2}}\left( x \right) \right\rbrack + \left( 1 - c \right)\left\lbrack bf_{X_{3}}\left( x \right) + \left( 1 - b \right)f_{X_{4}}\left( x \right) \right\rbrack\]</span></p>
<p><span class="math display">\[= caf_{X_{1}}\left( x \right) + c\left( 1 - a \right)f_{X_{2}}\left( x \right) + \left( 1 - c \right)bf_{X_{3}}\left( x \right) + (1 - c)\left( 1 - b \right)f_{X_{4}}\left( x \right)\]</span>.</p>
<p>Then, <span class="math inline">\(Z\)</span> is a mixture of <span class="math inline">\(X_{1}\)</span>, <span class="math inline">\(X_{2}\)</span>, <span class="math inline">\(X_{3}\)</span> and <span class="math inline">\(X_{4}\)</span>, with mixing weights <span class="math inline">\(\text{ca}\)</span>, <span class="math inline">\(c\left( 1 - a \right)\)</span>, <span class="math inline">\(\left( 1 - c \right)b\)</span> and <span class="math inline">\((1 - c)\left( 1 - b \right)\)</span>, respectively. It can be easily seen that the mixing weights sum to one.</p>
</div>
<hr />
</div>
</div>
<div id="continuous-mixtures" class="section level3">
<h3><span class="header-section-number">3.3.6</span> Continuous Mixtures</h3>
<p>A mixture with a very large number of subpopulations (<span class="math inline">\(k\)</span> goes to infinity) is often referred to as a continuous mixture. In a continuous mixture, subpopulations are not distinguished by a discrete mixing parameter but by a continuous variable <span class="math inline">\(\theta\)</span>, where <span class="math inline">\(\theta\)</span> plays the role of <span class="math inline">\(p_{i}\)</span> in the finite mixture. Consider the random variable <span class="math inline">\(X\)</span> with a distribution depending on a parameter <span class="math inline">\(\theta\)</span>, where <span class="math inline">\(\theta\)</span> itself is a continuous random variable. This description yields the following model for <span class="math inline">\(X\)</span> <span class="math display">\[f_{X}\left( x \right) = \int_{0}^{\infty}{f_{X}\left( x\left| \theta \right.\  \right)g\left( \theta \right)} d \theta ,\]</span> where <span class="math inline">\(f_{X}\left( x\left| \theta \right.\  \right)\)</span> is the conditional distribution of <span class="math inline">\(X\)</span> at a particular value of <span class="math inline">\(\theta\)</span> and <span class="math inline">\(g\left( \theta \right)\)</span> is the probability statement made about the unknown parameter <span class="math inline">\(\theta\)</span>, known as the prior distribution of <span class="math inline">\(\theta\)</span> (the prior information or expert opinion to be used in the analysis).</p>
<p>The distribution function, <span class="math inline">\(k\)</span>-th moment and moment generating functions of the continuous mixture are given as <span class="math display">\[F_{X}\left( x \right) = \int_{-\infty}^{\infty}{F_{X}\left( x\left| \theta \right.\  \right)g\left( \theta \right)} d \theta,\]</span> <span class="math display">\[\mathrm{E}\left( X^{k} \right) = \int_{-\infty}^{\infty}{\mathrm{E}\left( X^{k}\left| \theta \right.\  \right)g\left( \theta \right)}d \theta,\]</span> <span class="math display">\[M_{X}\left( t \right) = \mathrm{E}\left( e^{t X} \right) = \int_{-\infty}^{\infty}{\mathrm{E}\left( e^{ tx}\left| \theta \right.\  \right)g\left( \theta \right)}d \theta, \]</span> respectively.</p>
<p>The <span class="math inline">\(k\)</span>-th moment of the mixture distribution can be rewritten as <span class="math display">\[\mathrm{E}\left( X^{k} \right) = \int_{-\infty}^{\infty}{\mathrm{E}\left( X^{k}\left| \theta \right.\  \right)g\left( \theta \right)}d\theta = \mathrm{E}\left\lbrack \mathrm{E}\left( X^{k}\left| \theta \right.\  \right) \right\rbrack .\]</span></p>
<p>Using the Double Expectation Theorem we can define the mean and variance of <span class="math inline">\(X\)</span> as <span class="math display">\[\mathrm{E}\left( X \right) = \mathrm{E}\left\lbrack \mathrm{E}\left( X\left| \theta \right.\  \right) \right\rbrack\]</span> and <span class="math display">\[\mathrm{Var}\left( X \right) = \mathrm{E}\left\lbrack \mathrm{Var}\left( X\left| \theta \right.\  \right) \right\rbrack + \mathrm{Var}\left\lbrack \mathrm{E}\left( X\left| \theta \right.\  \right) \right\rbrack .\]</span></p>
<p><strong>Example 3.3.7. SOA Exam Question.</strong> <span class="math inline">\(X\)</span> has a normal distribution with a mean of <span class="math inline">\(\Lambda\)</span> and variance of 1. <span class="math inline">\(\Lambda\)</span> has a normal distribution with a mean of 1 and variance of 1. Find the mean and variance of <span class="math inline">\(X\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleLoss.3.7" href="javascript:toggleEX('toggleExampleLoss.3.7','displayTextExampleLoss.3.7');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExampleLoss.3.7" style="display: none">
<p><strong>Solution.</strong></p>
<p>X is a continuous mixture with mean <span class="math display">\[\mathrm{E}\left(X\right)=\mathrm{E}\left[\mathrm{E}\left(X\middle|\Lambda\right)\right]=\mathrm{E}\left(\Lambda\right)=1 \text{ and } \mathrm{V}\left(X\right)=\mathrm{V}\left[\mathrm{E}\left(X\middle|\Lambda\right)\right]+\mathrm{E}\left[\mathrm{V}\left(X\middle|\Lambda\right)\right]=\mathrm{V}\left(\Lambda\right)+\mathrm{E}\left(1\right)=1+1=2.\]</span></p>
</div>
<hr />
<p><strong>Example 3.3.8. SOA Exam Question.</strong> Claim sizes, <span class="math inline">\(X\)</span>, are uniform on the interval <span class="math inline">\(\left(\theta,\theta+10\right)\)</span> for each policyholder. <span class="math inline">\(\theta\)</span> varies by policyholder according to an exponential distribution with mean 5. Find the unconditional distribution, mean and variance of <span class="math inline">\(X\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleLoss.3.8" href="javascript:toggleEX('toggleExampleLoss.3.8','displayTextExampleLoss.3.8');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExampleLoss.3.8" style="display: none">
<p><strong>Solution.</strong></p>
<p>The conditional distribution of <span class="math inline">\(X\)</span> is <span class="math inline">\(f_{X}\left( \left. \ x \right|\theta \right) = \frac{1}{10}\)</span> for <span class="math inline">\(\theta &lt; x &lt; \theta + 10\)</span>.</p>
<p>The prior distribution of <span class="math inline">\(\theta\)</span> is <span class="math inline">\(g\left( \theta \right) = \frac{1}{5}e^{- \frac{\theta}{5}}\)</span> for <span class="math inline">\(0 &lt; \theta &lt; \infty\)</span>.</p>
<p>The conditional mean and variance of <span class="math inline">\(X\)</span> are given by <span class="math display">\[\mathrm{E}\left( \left. \ X \right|\theta \right) = \frac{\theta + \theta + 10}{2} = \theta + 5\]</span> and <span class="math display">\[\mathrm{Var}\left( \left. \ X \right|\theta \right) = \frac{\left\lbrack \left( \theta + 10 \right) - \theta \right\rbrack^{2}}{12} = \frac{100}{12}, \]</span> respectively.</p>
<p>Hence, the unconditional mean and variance of <span class="math inline">\(X\)</span> are given by <span class="math display">\[\mathrm{E}\left( X \right) = \mathrm{E}\left\lbrack \mathrm{E}\left( X\left| \theta \right.\  \right) \right\rbrack = \mathrm{E}\left( \theta + 5 \right) = \mathrm{E}\left( \theta \right) + 5 = 5 + 5 = 10,\]</span> and <span class="math display">\[\mathrm{Var}\left( X \right) = \mathrm{E}\left\lbrack V\left( X\left| \theta \right.\  \right) \right\rbrack + \mathrm{Var}\left\lbrack \mathrm{E}\left( X\left| \theta \right.\  \right) \right\rbrack \\
= \mathrm{E}\left( \frac{100}{12} \right) + \mathrm{Var}\left( \theta + 5 \right) = 8.33 + \mathrm{Var}\left( \theta \right) = 33.33. \]</span> The unconditional distribution of <span class="math inline">\(X\)</span> is <span class="math display">\[f_{X}\left( x \right) = \int_{}^{}{f_{X}\left( x |\theta \right) ~g\left( \theta \right) d \theta} .\]</span></p>
<!-- ![](Figures/Fig3Exer.png) -->
<p><span class="math display">\[f_{X}\left( x \right) = \left\{ \begin{matrix}
\int_{0}^{x}{\frac{1}{50}e^{- \frac{\theta}{5}}d\theta = \frac{1}{10}\left( 1 - e^{- \frac{x}{5}} \right)} &amp; 0 \leq x \leq 10, \\
\int_{x - 10}^{x}{\frac{1}{50}e^{- \frac{\theta}{5}} d\theta} = \frac{1}{10}\left( e^{- \frac{\left( x - 10 \right)}{5}} - e^{- \frac{x}{5}} \right) &amp; 10 &lt; x &lt; \infty. \\
\end{matrix} \right.\ \]</span></p>
</div>
<hr />
</div>
</div>
<div id="S:CoverageModifications" class="section level2">
<h2><span class="header-section-number">3.4</span> Coverage Modifications</h2>
<p>In this section we evaluate the impacts of coverage modifications: a) deductibles, b) policy limit, c) coinsurance and inflation on insurer’s costs.</p>
<div id="S:PolicyDeduct" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Policy Deductibles</h3>
<p>Under an ordinary deductible policy, the insured (policyholder) agrees to cover a fixed amount of an insurance claim before the insurer starts to pay. This fixed expense paid out of pocket is called the deductible and often denoted by <span class="math inline">\(d\)</span>. If the loss exceeds <span class="math inline">\(d\)</span> then the insurer is responsible for covering the loss X less the deductible <span class="math inline">\(d\)</span>. Depending on the agreement, the deductible may apply to each covered loss or to the total losses during a defined benefit period (month, year, etc.)</p>
<p>Deductibles eliminate a large number of small claims, reduce costs of handling and processing these claims, reduce premiums for the policyholders and reduce moral hazard. Moral hazard occurs when the insured takes more risks, increasing the chances of loss due to perils insured against, knowing that the insurer will incur the cost (e.g. a policyholder with collision insurance may be encouraged to drive recklessly). The larger the deductible, the less the insured pays in premiums for an insurance policy.</p>
<p>Let <span class="math inline">\(X\)</span> denote the loss incurred to the insured and <span class="math inline">\(Y\)</span> denote the amount of paid claim by the insurer. Speaking of the benefit paid to the policyholder, we differentiate between two variables: The payment per loss and the payment per payment. The payment per loss variable, denoted by <span class="math inline">\(Y^{L}\)</span>, includes losses for which a payment is made as well as losses less than the deductible and hence is defined as <span class="math display">\[Y^{L} = \left( X - d \right)_{+} 
= \left\{ \begin{array}{cc}
0 &amp; X &lt; d, \\
X - d &amp; X &gt; d  
\end{array} \right. .\]</span> <span class="math inline">\(Y^{L}\)</span> is often referred to as left censored and shifted variable because the values below <span class="math inline">\(d\)</span> are not ignored and all losses are shifted by a value <span class="math inline">\(d\)</span>.</p>
<p>On the other hand, the payment per payment variable, denoted by <span class="math inline">\(Y^{P}\)</span>, is not defined when there is no payment and only includes losses for which a payment is made. The variable is defined as <span class="math display">\[Y^{P} = \left\{ \begin{matrix}
\text{Undefined} &amp; X \le d \\
X - d &amp; X &gt; d 
\end{matrix} \right. \]</span> <span class="math inline">\(Y^{P}\)</span> is often referred to as left truncated and shifted variable or excess loss variable because the claims smaller than <span class="math inline">\(d\)</span> are not reported and values above <span class="math inline">\(d\)</span> are shifted by <span class="math inline">\(d\)</span>.</p>
<p>Even when the distribution of <span class="math inline">\(X\)</span> is continuous, the distribution of <span class="math inline">\(Y^{L}\)</span> is partly discrete and partly continuous. The discrete part of the distribution is concentrated at <span class="math inline">\(Y = 0\)</span> (when <span class="math inline">\(X \leq d\)</span>) and the continuous part is spread over the interval <span class="math inline">\(Y &gt; 0\)</span> (when <span class="math inline">\(X &gt; d\)</span>). For the discrete part, the probability that no payment is made is the probability that losses fall below the deductible; that is, <span class="math display">\[\Pr\left( Y^{L} = 0 \right) = \Pr\left( X \leq d \right) = F_{X}\left( d \right).\]</span> Using the transformation <span class="math inline">\(Y^{L} = X - d\)</span> for the continuous part of the distribution, we can find the probability density function of <span class="math inline">\(Y^{L}\)</span> given by <span class="math display">\[f_{Y^{L}}\left( y \right) = \left\{ \begin{matrix}
F_{X}\left( d \right) &amp; y = 0, \\
f_{X}\left( y + d \right) &amp; y &gt; 0 
\end{matrix} \right. \]</span></p>
<p>We can see that the payment per payment variable is the payment per loss variable conditioned on the loss exceeding the deductible; that is, <span class="math inline">\(Y^{P} = \left. \ Y^{L} \right|X &gt; d\)</span>. Hence, the probability density function of <span class="math inline">\(Y^{P}\)</span> is given by <span class="math display">\[f_{Y^{P}}\left( y \right) = \frac{f_{X}\left( y + d \right)}{1 - F_{X}\left( d \right)},\]</span> for <span class="math inline">\(y &gt; 0\)</span>. Accordingly, the distribution functions of <span class="math inline">\(Y^{L}\)</span>and <span class="math inline">\(Y^{P}\)</span> are given by <span class="math display">\[F_{Y^{L}}\left( y \right) = \left\{ \begin{matrix}
F_{X}\left( d \right) &amp; y = 0, \\
F_{X}\left( y + d \right) &amp; y &gt; 0. \\
\end{matrix} \right.\ \]</span> and <span class="math display">\[F_{Y^{P}}\left( y \right) = \frac{F_{X}\left( y + d \right) - F_{X}\left( d \right)}{1 - F_{X}\left( d \right)},\]</span> for <span class="math inline">\(y &gt; 0\)</span>, respectively.</p>
<p>The raw moments of <span class="math inline">\(Y^{L}\)</span> and <span class="math inline">\(Y^{P}\)</span> can be found directly using the probability density function of <span class="math inline">\(X\)</span> as follows <span class="math display">\[\mathrm{E}\left\lbrack \left( Y^{L} \right)^{k} \right\rbrack = \int_{d}^{\infty}\left( x - d \right)^{k}f_{X}\left( x \right)dx ,\]</span> and <span class="math display">\[\mathrm{E}\left\lbrack \left( Y^{P} \right)^{k} \right\rbrack = \frac{\int_{d}^{\infty}\left( x - d \right)^{k}f_{X}\left( x \right) dx }{{1 - F}_{X}\left( d \right)} = \frac{\mathrm{E}\left\lbrack \left( Y^{L} \right)^{k} \right\rbrack}{{1 - F}_{X}\left( d \right)},\]</span> respectively.</p>
<p>We have seen that the deductible <span class="math inline">\(d\)</span> imposed on an insurance policy is the amount of loss that has to be paid out of pocket before the insurer makes any payment. The deductible <span class="math inline">\(d\)</span> imposed on an insurance policy reduces the insurer’s payment. The loss elimination ratio (<em>LER</em>) is the percentage decrease in the expected payment of the insurer as a result of imposing the deductible. <em>LER</em> is defined as <span class="math display">\[LER = \frac{\mathrm{E}\left( X \right) - \mathrm{E}\left( Y^{L} \right)}{\mathrm{E}\left( X \right)}.\]</span></p>
<p>A little less common type of policy deductible is the franchise deductible. The franchise deductible will apply to the policy in the same way as ordinary deductible except that when the loss exceeds the deductible <span class="math inline">\(d\)</span>, the full loss is covered by the insurer. The payment per loss and payment per payment variables are defined as <span class="math display">\[Y^{L} = \left\{ \begin{matrix}
0 &amp; X \leq d, \\
X &amp; X &gt; d, \\
\end{matrix} \right.\ \]</span> and <span class="math display">\[Y^{P} = \left\{ \begin{matrix}
\text{Undefined} &amp; X \leq d, \\
X &amp; X &gt; d, \\
\end{matrix} \right.\ \]</span> respectively.</p>
<p><strong>Example 3.4.1. SOA Exam Question.</strong> A claim severity distribution is exponential with mean 1000. An insurance company will pay the amount of each claim in excess of a deductible of 100. Calculate the variance of the amount paid by the insurance company for one claim, including the possibility that the amount paid is 0.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleLoss.4.1" href="javascript:toggleEX('toggleExampleLoss.4.1','displayTextExampleLoss.4.1');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExampleLoss.4.1" style="display: none">
<p><strong>Solution.</strong></p>
<p>Let <span class="math inline">\(Y^{L}\)</span> denote the amount paid by the insurance company for one claim. <span class="math display">\[Y^{L} = \left( X - 100 \right)_{+} = \left\{ \begin{matrix}
0 &amp; X \leq 100, \\
X - 100 &amp; X &gt; 100. \\
\end{matrix} \right.\ \]</span> The first and second moments of <span class="math inline">\(Y^{L}\)</span> are <span class="math display">\[E\left( Y^{L} \right) = \int_{100}^{\infty}\left( x - 100 \right)f_{X}\left( x \right)dx \\
= {\int_{100}^{\infty}{S_{X}\left( x \right)}dx = 1000e}^{- \frac{100}{1000}},\]</span> and <span class="math display">\[E\left\lbrack \left( Y^{L} \right)^{2} \right\rbrack = \int_{100}^{\infty}\left( x - 100 \right)^{2}f_{X}\left( x \right)dx \\\\
= 2 \times 1000^{2}e^{- \frac{100}{1000}}.\]</span> So, <span class="math display">\[\mathrm{Var}\left( Y^{L} \right) = \left( 2 \times 1000^{2}e^{- \frac{100}{1000}} \right) - \left( {1000e}^{- \frac{100}{1000}} \right)^{2} = 990,944.\]</span></p>
<p>An arguably simpler path to the solution is to make use of the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y^{P}\)</span>. If <span class="math inline">\(X\)</span> is exponentially distributed with mean 1000, then <span class="math inline">\(Y^{P}\)</span> is also exponentially distributed with the same mean, because of the memoryless property of the exponential distribution. Hence, <span class="math inline">\(E\left( Y^{P} \right)\)</span>=1000 and <span class="math display">\[E\left\lbrack \left( Y^{P} \right)^{2} \right\rbrack = 2 \times 1000^{2}.\]</span> Using the relationship between <span class="math inline">\(Y^{L}\)</span> and <span class="math inline">\(Y^{P}\)</span> we find <span class="math display">\[E\left( Y^{L} \right) = \ E\left( Y^{P} \right)S_{X}\left( 100 \right){= 1000e}^{- \frac{100}{1000}}\]</span></p>
<p><span class="math display">\[E\left\lbrack \left( Y^{L} \right)^{2} \right\rbrack = E\left\lbrack \left( Y^{P} \right)^{2} \right\rbrack S_{X}\left( 100 \right) = 2 \times 1000^{2}e^{- \frac{100}{1000}}.\]</span></p>
<p>The relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y^P\)</span> can also be used when dealing with the uniform or the Pareto distributions. You can easily show that if <span class="math inline">\(X\)</span> is uniform over the interval <span class="math inline">\(\left(0,\theta\right)\)</span> then <span class="math inline">\(Y^P\)</span> is uniform over the interval <span class="math inline">\(\left(0,\theta-d\right)\)</span> and if <span class="math inline">\(X\)</span> is Pareto with parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\theta\)</span> then <span class="math inline">\(Y^P\)</span> is Pareto with parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\theta+d\)</span>.</p>
</div>
<hr />
<strong>Example 3.4.2. SOA Exam Question.</strong> For an insurance:
<ul>
<li>
Losses have a density function <span class="math display">\[f_{X}\left( x \right) = \left\{ \begin{matrix}
    0.02x &amp; 0 &lt; x  &lt; 10, \\
    0 &amp; \text{elsewhere.} \\
    \end{matrix} \right. \]</span>
</li>
<li>
The insurance has an ordinary deductible of 4 per loss.
</li>
<li>
<span class="math inline">\(Y^{P}\)</span> is the claim payment per payment random variable.
</li>
</ul>
<p>Calculate <span class="math inline">\(\mathrm{E}\left( Y^{P} \right)\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleLoss.4.2" href="javascript:toggleEX('toggleExampleLoss.4.2','displayTextExampleLoss.4.2');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExampleLoss.4.2" style="display: none">
<p><strong>Solution.</strong></p>
<p>We define <span class="math inline">\(Y^P\)</span> as follows <span class="math display">\[Y^{P} = \left\{ \begin{matrix}
\text{Undefined} &amp; X \leq 4, \\
X - 4 &amp; X &gt; 4. \\
\end{matrix} \right.\ \]</span> So, <span class="math inline">\(E\left( Y^{P} \right) = \frac{\int_{4}^{10}\left( x - 4 \right)0.02xdx}{{1 - F}_{X}\left( 4 \right)} = \frac{2.88}{0.84} = 3.43\)</span>.</p>
<p>Note that we divide by <span class="math inline">\(S_X(4)=1-F_X(4)\)</span>, as this is the range where the variable <span class="math inline">\(Y^P\)</span> is defined.</p>
</div>
<hr />
<strong>Example 3.4.3. SOA Exam Question.</strong> You are given:
<ol>
<li>
Losses follow an exponential distribution with the same mean in all years.
</li>
<li>
The loss elimination ratio this year is 70%.
</li>
<li>
The ordinary deductible for the coming year is 4/3 of the current deductible.
</li>
</ol>
<p>Compute the loss elimination ratio for the coming year.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleLoss.4.3" href="javascript:toggleEX('toggleExampleLoss.4.3','displayTextExampleLoss.4.3');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExampleLoss.4.3" style="display: none">
<p><strong>Solution.</strong></p>
<p>Let the losses <span class="math inline">\(X\sim Exp(\theta)\)</span> and the deductible for the coming year <span class="math inline">\(d&#39; = \frac{4}{3}d\)</span>, the deductible of the current year. The <em>LER</em> for the current year is <span class="math display">\[\frac{E\left( X \right) - E\left( Y^{L} \right)}{E\left( X \right)} = \frac{\theta - \theta e^{- d / \theta}}{\theta} = 1 - e^{- d / \theta} = 0.7.\]</span> Then, <span class="math inline">\(e^{- d / \theta} = 0.3\)</span>.</p>
The <em>LER</em> for the coming year is
<span class="math display">\[\begin{align*}
&amp;\frac{\theta - \theta \exp(- \frac{d&#39;}{\theta})}{\theta}=\frac{\theta - \theta \exp(- \frac{\left( \frac{4}{3}d \right)}{\theta})}{\theta} \\
&amp;= 1 - \exp\left(- \frac{ \frac{4}{3} d }{\theta}\right) = 1 - \left( e^{-d /\theta} \right)^{4/3} = 1 - {0.3}^{4/3} = 0.8 .
\end{align*}\]</span>
</div>
<hr />
</div>
<div id="S:PolicyLimits" class="section level3">
<h3><span class="header-section-number">3.4.2</span> Policy Limits</h3>
<p>Under a limited policy, the insurer is responsible for covering the actual loss <span class="math inline">\(X\)</span> up to the limit of its coverage. This fixed limit of coverage is called the policy limit and often denoted by <span class="math inline">\(u\)</span>. If the loss exceeds the policy limit, the difference <span class="math inline">\(X - u\)</span> has to be paid by the policyholder. While a higher policy limit means a higher payout to the insured, it is associated with a higher premium.</p>
<p>Let <span class="math inline">\(X\)</span> denote the loss incurred to the insured and <span class="math inline">\(Y\)</span> denote the amount of paid claim by the insurer. Then <span class="math inline">\(Y\)</span> is defined as <span class="math display">\[Y = X \land u = \left\{ \begin{matrix}
X &amp; X \leq u, \\
u &amp; X &gt; u. \\
\end{matrix} \right.\ \]</span> It can be seen that the distinction between <span class="math inline">\(Y^{L}\)</span> and <span class="math inline">\(Y^{P}\)</span> is not needed under limited policy as the insurer will always make a payment.</p>
<p>Using the definitions of <span class="math inline">\(\left(X-d\right)_+ \text{ and } \left(X\land d\right)\)</span>, it can be easily seen that the expected payment without any coverage modification, <span class="math inline">\(X\)</span>, is equal to the sum of the expected payments with deductible <span class="math inline">\(d\)</span> and limit <span class="math inline">\(d\)</span>. That is, <span class="math inline">\({X=\left(X-d\right)}_++ \left(X\land d\right)\)</span>.</p>
<p>When a loss is subject to a deductible d a limit u, the per-loss variable <span class="math inline">\(Y^L\)</span> is defined as <span class="math display">\[Y^{L} = \left\{ \begin{matrix}
0 &amp; X \leq d, \\
\alpha\left( X - d \right) &amp; d &lt;  X \leq u, \\
\alpha\left( u - d \right) &amp; X &gt; u. \\
\end{matrix} \right.\ \]</span> Hence, <span class="math inline">\(Y^L\)</span> can be expressed as <span class="math inline">\(Y^L=\left(X\land u\right)-\left(X\land d\right)\)</span>.</p>
<p>Even when the distribution of <span class="math inline">\(X\)</span> is continuous, the distribution of <span class="math inline">\(Y\)</span> is partly discrete and partly continuous. The discrete part of the distribution is concentrated at <span class="math inline">\(Y = u\)</span> (when <span class="math inline">\(X &gt; u\)</span>), while the continuous part is spread over the interval <span class="math inline">\(Y &lt; u\)</span> (when <span class="math inline">\(X \leq u\)</span>). For the discrete part, the probability that the benefit paid is <span class="math inline">\(u\)</span>, is the probability that the loss exceeds the policy limit <span class="math inline">\(u\)</span>; that is, <span class="math display">\[\Pr \left( Y = u \right) = \Pr \left( X &gt; u \right) = {1 - F}_{X}\left( u \right).\]</span> For the continuous part of the distribution <span class="math inline">\(Y = X\)</span>, hence the probability density function of <span class="math inline">\(Y\)</span> is given by <span class="math display">\[f_{Y}\left( y \right) = \left\{ \begin{matrix}
f_{X}\left( y \right) &amp; 0 &lt; y &lt; u, \\
1 - F_{X}\left( u \right) &amp; y = u. \\
\end{matrix} \right.\ \]</span> Accordingly, the distribution function of <span class="math inline">\(Y\)</span> is given by <span class="math display">\[F_{Y}\left( y \right) = \left\{ \begin{matrix}
F_{X}\left( x \right) &amp; 0 &lt; y &lt; u, \\
1 &amp; y \geq u. \\
\end{matrix} \right.\ \]</span> The raw moments of <span class="math inline">\(Y\)</span> can be found directly using the probability density function of <span class="math inline">\(X\)</span> as follows <span class="math display">\[\mathrm{E}\left( Y^{k} \right) = \mathrm{E}\left\lbrack \left( X \land u \right)^{k} \right\rbrack = \int_{0}^{u}x^{k}f_{X}\left( x \right)dx + \int_{u}^{\infty}{u^{k}f_{X}\left( x \right)} dx \\ = \int_{0}^{u}x^{k}f_{X}\left( x \right)dx + u^{k}\left\lbrack {1 - F}_{X}\left( u \right) \right\rbrack .\]</span></p>
<p><strong>Example 3.4.4. SOA Exam Question.</strong> Under a group insurance policy, an insurer agrees to pay 100% of the medical bills incurred during the year by employees of a small company, up to a maximum total of one million dollars. The total amount of bills incurred, <span class="math inline">\(X\)</span>, has probability density function <span class="math display">\[f_{X}\left( x \right) = \left\{ \begin{matrix}
\frac{x\left( 4 - x \right)}{9} &amp; 0 &lt; x &lt; 3, \\
0 &amp; \text{elsewhere.} \\
\end{matrix} \right.\ \]</span> where <span class="math inline">\(x\)</span> is measured in millions. Calculate the total amount, in millions of dollars, the insurer would expect to pay under this policy.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleLoss.4.4" href="javascript:toggleEX('toggleExampleLoss.4.4','displayTextExampleLoss.4.4');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExampleLoss.4.4" style="display: none">

<p><strong>Solution.</strong></p>
<p>Define the total amount of bills paid by the insurer as <span class="math display">\[Y = X \land 1 = \left\{ \begin{matrix}
X &amp; X \leq 1, \\
1 &amp; X &gt; 1. \\
\end{matrix} \right.\ \]</span> So <span class="math inline">\(\mathrm{E}\left( Y \right) = \mathrm{E}\left( X \land 1 \right) = \int_{0}^{1}\frac{x^{2}(4 - x)}{9}dx + 1 * \int_{1}^{3}\frac{x\left( 4 - x \right)}{9}dx = 0.935\)</span>.</p>
<hr />
</div>
<div id="coinsurance" class="section level3">
<h3><span class="header-section-number">3.4.3</span> Coinsurance</h3>
<p>As we have seen in Section <a href="C-Severity.html#S:PolicyDeduct">3.4.1</a>, the amount of loss retained by the policyholder can be losses up to the deductible <span class="math inline">\(d\)</span>. The retained loss can also be a percentage of the claim. The percentage <span class="math inline">\(\alpha\)</span>, often referred to as the coinsurance factor, is the percentage of claim the insurance company is required to cover. If the policy is subject to an ordinary deductible and policy limit, coinsurance refers to the percentage of claim the insurer is required to cover, after imposing the ordinary deductible and policy limit. The payment per loss variable, <span class="math inline">\(Y^{L}\)</span>, is defined as <span class="math display">\[Y^{L} = \left\{ \begin{matrix}
0 &amp; X \leq d, \\
\alpha\left( X - d \right) &amp; d &lt;  X \leq u, \\
\alpha\left( u - d \right) &amp; X &gt; u. \\
\end{matrix} \right.\ \]</span> The policy limit (the maximum amount paid by the insurer) in this case is <span class="math inline">\(\alpha\left( u - d \right)\)</span>, while <span class="math inline">\(u\)</span> is the maximum covered loss.</p>
<p>We have seen in Section 3.4.2 that when a loss is subject to both a deductible <span class="math inline">\(d\)</span> and a limit <span class="math inline">\(u\)</span> the per-loss variable <span class="math inline">\(Y^L\)</span> can be expressed as <span class="math inline">\(Y^L=\left(X\land u\right)-\left(X\land d\right)\)</span>. With coinsurance, this becomes <span class="math inline">\(Y^L\)</span> can be expressed as <span class="math inline">\(Y^L=\alpha\left[(X\land u)-(X\land d)\right]\)</span>.</p>
<p>The <span class="math inline">\(k\)</span>-th moment of <span class="math inline">\(Y^{L}\)</span> is given by <span class="math display">\[\mathrm{E}\left\lbrack \left( Y^{L} \right)^{k} \right\rbrack = \int_{d}^{u}\left\lbrack \alpha\left( x - d \right) \right\rbrack^{k}f_{X}\left( x \right)dx + \int_{u}^{\infty}\left\lbrack \alpha\left( u - d \right) \right\rbrack^{k}f_{X}\left( x \right) dx .\]</span></p>
<p>A growth factor <span class="math inline">\(\left( 1 + r \right)\)</span> may be applied to <span class="math inline">\(X\)</span> resulting in an inflated loss random variable <span class="math inline">\(\left( 1 + r \right)X\)</span> (the prespecified <em>d</em> and <em>u</em> remain unchanged). The resulting per loss variable can be written as <span class="math display">\[Y^{L} = \left\{ \begin{matrix}
0 &amp; X \leq \frac{d}{1 + r}, \\
\alpha\left\lbrack \left( 1 + r \right)X - d \right\rbrack &amp; \frac{d}{1 + r} &lt;  X \leq \frac{u}{1 + r}, \\
\alpha\left( u - d \right) &amp; X &gt; \frac{u}{1 + r}. \\
\end{matrix} \right.\ \]</span> The first and second moments of <span class="math inline">\(Y^{L}\)</span> can be expressed as <span class="math display">\[\mathrm{E}\left( Y^{L} \right) = \alpha\left( 1 + r \right)\left\lbrack \mathrm{E}\left( X \land \frac{u}{1 + r} \right) - \mathrm{E}\left( X \land \frac{d}{1 + r} \right) \right\rbrack,\]</span> and <span class="math display">\[\mathrm{E}\left\lbrack \left( Y^{L} \right)^{2} 
\right\rbrack = \alpha^{2}\left( 1 + r \right)^{2}  \left\{ \mathrm{E}\left\lbrack \left( X \land \frac{u}{1 + r} \right)^{2} \right\rbrack - \mathrm{E}\left\lbrack \left( X \land \frac{d}{1 + r} \right)^{2} \right\rbrack  \right. \\
\left. \ \ \ \ \ - 2\left( \frac{d}{1 + r} \right)\left\lbrack \mathrm{E}\left( X \land \frac{u}{1 + r} \right) - \mathrm{E}\left( X \land \frac{d}{1 + r} \right) \right\rbrack \right\} ,\]</span> respectively.</p>
<p>The formulas given for the first and second moments of <span class="math inline">\(Y^{L}\)</span> are general. Under full coverage, <span class="math inline">\(\alpha = 1\)</span>, <span class="math inline">\(r = 0\)</span>, <span class="math inline">\(u = \infty\)</span>, <span class="math inline">\(d = 0\)</span> and <span class="math inline">\(\mathrm{E}\left( Y^{L} \right)\)</span> reduces to <span class="math inline">\(\mathrm{E}\left( X \right)\)</span>. If only an ordinary deductible is imposed, <span class="math inline">\(\alpha = 1\)</span>, <span class="math inline">\(r = 0\)</span>, <span class="math inline">\(u = \infty\)</span> and <span class="math inline">\(\mathrm{E}\left( Y^{L} \right)\)</span> reduces to <span class="math inline">\(\mathrm{E}\left( X \right) - \mathrm{E}\left( X \land d \right)\)</span>. If only a policy limit is imposed <span class="math inline">\(\alpha = 1\)</span>, <span class="math inline">\(r = 0\)</span>, <span class="math inline">\(d = 0\)</span> and <span class="math inline">\(\mathrm{E}\left( Y^{L} \right)\)</span> reduces to <span class="math inline">\(\mathrm{E}\left( X \land u \right)\)</span>.</p>
<p><strong>Example 3.4.5. SOA Exam Question.</strong> The ground up loss random variable for a health insurance policy in 2006 is modeled with <em>X</em>, an exponential distribution with mean 1000. An insurance policy pays the loss above an ordinary deductible of 100, with a maximum annual payment of 500. The ground up loss random variable is expected to be 5% larger in 2007, but the insurance in 2007 has the same deductible and maximum payment as in 2006. Find the percentage increase in the expected cost per payment from 2006 to 2007.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleLoss.4.5" href="javascript:toggleEX('toggleExampleLoss.4.5','displayTextExampleLoss.4.5');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExampleLoss.4.5" style="display: none">
<p><strong>Solution.</strong></p>
<p>We define the amount per loss <span class="math inline">\(Y^L\)</span> in both years as <span class="math display">\[Y_{2006}^{L} = \left\{ \begin{matrix}
0 &amp; X \leq 100, \\
X - 100 &amp; 100 &lt;  X \leq 600, \\
500 &amp; X &gt; 600. \\
\end{matrix} \right.\ \]</span></p>
<p><span class="math display">\[Y_{2007}^{L} = \left\{ \begin{matrix}
0 &amp; X \leq 95.24, \\
1.05X - 100 &amp; 95.24 &lt;  X \leq 571.43, \\
500 &amp; X &gt; 571.43. \\
\end{matrix} \right.\ \]</span></p>
<p>So,</p>
<p><span class="math display">\[E\left( Y_{2006}^{L} \right) = E\left( X \land 600 \right) - E\left( X \land 100 \right) = 1000\left( {1 - e}^{- \frac{600}{1000}} \right) - 1000\left( {1 - e}^{- \frac{100}{1000}} \right)\]</span></p>
<p><span class="math display">\[= 356.026\]</span>.</p>
<p><span class="math display">\[E\left( Y_{2007}^{L} \right) = 1.05\left\lbrack E\left( X \land 571.43 \right) - E\left( X \land 95.24 \right) \right\rbrack\]</span></p>
<p><span class="math display">\[= 1.05\left\lbrack 1000\left( {1 - e}^{- \frac{571.43}{1000}} \right) - 1000\left( {1 - e}^{- \frac{95.24}{1000}} \right) \right\rbrack\]</span></p>
<p><span class="math display">\[=361.659\]</span>.</p>
<p><span class="math inline">\(E\left( Y_{2006}^{P} \right) = \frac{356.026}{e^{- \frac{100}{1000}}} = 393.469\)</span>.</p>
<p><span class="math inline">\(E\left( Y_{2007}^{P} \right) = \frac{361.659}{e^{- \frac{95.24}{1000}}} = 397.797\)</span>.</p>
<p>Because <span class="math inline">\(\frac{E\left( Y_{2007}^{P} \right)}{E\left( Y_{2006}^{P} \right)} -1 = 0.011,\)</span> there is an increase of 1.1% from 2006 to 2007. Due to the policy limit, the cost per payment event grew by only 1.1% between 2006 and 2007 even though the ground up losses increased by 5% between the two years.</p>
</div>
<hr />
</div>
<div id="S:Chap3Reinsurance" class="section level3">
<h3><span class="header-section-number">3.4.4</span> Reinsurance</h3>
<p>In Section <a href="C-Severity.html#S:PolicyDeduct">3.4.1</a> we introduced the policy deductible, which is a contractual arrangement under which an insured transfers part of the risk by securing coverage from an insurer in return for an insurance premium. Under that policy, the insured must pay all losses up to the deductible, and the insurer only pays the amount (if any) above the deductible. We now introduce reinsurance, a mechanism of insurance for insurance companies. Reinsurance is a contractual arrangement under which an insurer transfers part of the underlying insured risk by securing coverage from another insurer (referred to as a reinsurer) in return for a reinsurance premium. Although reinsurance involves a relationship between three parties: the original insured, the insurer (often referred to as cedent or cedant) and the reinsurer, the parties of the reinsurance agreement are only the primary insurer and the reinsurer. There is no contractual agreement between the original insured and the reinsurer. Though many different types of reinsurance contracts exist, a common form is excess of loss coverage. In such contracts, the primary insurer must make all required payments to the insured until the primary insurer’s total payments reach a fixed reinsurance deducible. The reinsurer is then only responsible for paying losses above the reinsurance deductible. The maximum amount retained by the primary insurer in the reinsurance agreement (the reinsurance deductible) is called retention.</p>
<p>Reinsurance arrangements allow insurers with limited financial resources to increase the capacity to write insurance and meet client requests for larger insurance coverage while reducing the impact of potential losses and protecting the insurance company against catastrophic losses. Reinsurance also allows the primary insurer to benefit from underwriting skills, expertise and proficient complex claim file handling of the larger reinsurance companies.</p>
<p><strong>Example 3.4.6. SOA Exam Question.</strong> In 2005 a risk has a two-parameter Pareto distribution with <span class="math inline">\(\alpha = 2\)</span> and <span class="math inline">\(\theta = 3000\)</span>. In 2006 losses inflate by 20%. Insurance on the risk has a deductible of 600 in each year. <span class="math inline">\(P_{i}\)</span>, the premium in year <span class="math inline">\(i\)</span>, equals 1.2 times expected claims. The risk is reinsured with a deductible that stays the same in each year. <span class="math inline">\(R_{i}\)</span>, the reinsurance premium in year <span class="math inline">\(i\)</span>, equals 1.1 times the expected reinsured claims. <span class="math inline">\(\frac{R_{2005}}{P_{2005}} = 0.55\)</span>. Calculate <span class="math inline">\(\frac{R_{2006}}{P_{2006}}\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleLoss.4.6" href="javascript:toggleEX('toggleExampleLoss.4.6','displayTextExampleLoss.4.6');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExampleLoss.4.6" style="display: none">
<p><strong>Solution.</strong></p>
Let us use the following notation:
<ul>
<li>
<span class="math inline">\(X_{i}:\)</span> The risk in year <span class="math inline">\(i\)</span>
</li>
<li>
<span class="math inline">\(Y_{i}:\)</span> The insured claim in year <span class="math inline">\(i\)</span>
</li>
<li>
<span class="math inline">\(P_{i}:\)</span> The insurance premium in year <span class="math inline">\(i\)</span>
</li>
<li>
<span class="math inline">\(Y_{i}^{R}:\)</span> The reinsured claim in year <span class="math inline">\(i\)</span>
</li>
<li>
<span class="math inline">\(R_{i}:\)</span> The reinsurance premium in year <span class="math inline">\(i\)</span>
</li>
<li>
<span class="math inline">\(d:\)</span> The insurance deductible in year <span class="math inline">\(i\)</span> (the insurance deductible is fixed each year, equal to 600)
</li>
<li>
<span class="math inline">\(d^{R}:\)</span> The reinsurance deductible or retention in year <span class="math inline">\(i\)</span> (the reinsurance deductible is fixed each year, but unknown) where <span class="math inline">\(i = 2005,\ 2006\)</span>
</li>
</ul>
<p><span class="math display">\[Y_{i} = \left\{ \begin{matrix}
0 &amp; X_{i} \leq 600 \\
X_{i} - 600 &amp; X_{i} &gt; 600 \\
\end{matrix} \right.\ \]</span> where <span class="math inline">\(i = 2005,\ 2006\)</span></p>
<p><span class="math display">\[X_{2005}\sim Pa\left( 2,3000 \right)\]</span></p>
<p><span class="math display">\[\mathrm{E}\left( Y_{2005} \right) = \mathrm{E}\left( X_{2005} - 600 \right)_{+} = \mathrm{E}\left( X_{2005} \right) - \mathrm{E}\left( X_{2005} \land 600 \right)\]</span></p>
<p><span class="math display">\[= 3000 - 3000\left( 1 - \frac{3000}{3600} \right) = 2500\]</span></p>
<p><span class="math display">\[P_{2005} = 1.2\mathrm{E}\left( Y_{2005} \right) = 3000\]</span></p>
<p>Since <span class="math inline">\(X_{2006} = 1.2X_{2005}\)</span> and Pareto is a scale distribution with scale parameter <span class="math inline">\(\theta\)</span>, then <span class="math inline">\(X_{2006}\sim Pa\left( 2,3600 \right)\)</span></p>
<p><span class="math display">\[\mathrm{E}\left( Y_{2006} \right) = \mathrm{E}\left( X_{2006} - 600 \right)_{+} = \mathrm{E}\left( X_{2006} \right) - \mathrm{E}\left( X_{2006} \land 600 \right)\]</span></p>
<p><span class="math display">\[= 3600 - 3600\left( 1 - \frac{3600}{4200} \right) = 3085.714\]</span></p>
<p><span class="math display">\[P_{2006} = 1.2\mathrm{E}\left( Y_{2006} \right) = 3702.857\]</span></p>
<p><span class="math display">\[Y_{i}^{R} = \left\{ \begin{matrix}
0 &amp; X_{i} - 600 \leq d^{R} \\
X_{i} - 600 - d^{R} &amp; X_{i} - 600 &gt; d^{R} \\
\end{matrix} \right.\ \]</span></p>
<p>Since <span class="math inline">\(\frac{R_{2005}}{P_{2005}} = 0.55\)</span>, then <span class="math inline">\(R_{2005} = 3000 \times 0.55 = 1650\)</span></p>
<p>Since <span class="math inline">\(R_{2005} = 1.1\mathrm{E}\left( Y_{2005}^{R} \right)\)</span>, then <span class="math inline">\(\mathrm{E}\left( Y_{2005}^{R} \right) = \frac{1650}{1.1} = 1500\)</span></p>
<p><span class="math display">\[\mathrm{E}\left( Y_{2005}^{R} \right) = \mathrm{E}\left( X_{2005} - 600 - d^{R} \right)_{+} = \mathrm{E}\left( X_{2005} \right) - \mathrm{E}\left( X_{2005} \land \left( 600 + d^{R} \right) \right)\]</span></p>
<p><span class="math display">\[= 3000 - 3000\left( 1 - \frac{3000}{3600 + d^{R}} \right) = 1500 \Rightarrow d^{R} = 2400\]</span></p>
<p><span class="math display">\[\mathrm{E}\left( Y_{2006}^{R} \right) = \mathrm{E}\left( X_{2006} - 600 - d^{R} \right)_{+} = \mathrm{E}\left( X_{2006} - 3000 \right)_{+} = \mathrm{E}\left( X_{2006} \right) - \mathrm{E}\left( X_{2006} \land 3000 \right)\]</span></p>
<p><span class="math display">\[= 3600 - 3600\left( 1 - \frac{3600}{6600} \right) = 1963.636\]</span></p>
<p><span class="math display">\[R_{2006} = 1.1\mathrm{E}\left( Y_{2006}^{R} \right) = 1.1 \times 1963.636 = 2160\]</span></p>
<p>Therefore <span class="math inline">\(\frac{R_{2006}}{P_{2006}} = \frac{2160}{3702.857} = 0.583\)</span></p>
</div>
<hr />
</div>
</div>
<div id="S:MaxLikeEstimation" class="section level2">
<h2><span class="header-section-number">3.5</span> Maximum Likelihood Estimation</h2>
<p>In this section we estimate statistical parameters using the method of maximum likelihood. Maximum likelihood estimates in the presence of grouping, truncation or censoring are calculated.</p>
<div id="maximum-likelihood-estimators-for-complete-data" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Maximum Likelihood Estimators for Complete Data</h3>
<p>Pricing of insurance premiums and estimation of claim reserving are among many actuarial problems that involve modeling the severity of loss (claim size). Appendix Chapter <a href="C-AppC.html#C:AppC">17</a> reviews the definition of the likelihood function, introduces its properties, reviews the maximum likelihood estimators, extends their large-sample properties to the case where there are multiple parameters in the model, and reviews statistical inference based on maximum likelihood estimators. In this section, we present a few examples to illustrate how actuaries fit a parametric distribution model to a set of claim data using maximum likelihood. In these examples we derive the asymptotic variance of maximum-likelihood estimators of the model parameters. We use the delta method to derive the asymptotic variances of functions of these parameters.</p>
<strong>Example 3.5.1. SOA Exam Question.</strong> Consider a random sample of claim amounts: 8,000 10,000 12,000 15,000. You assume that claim amounts follow an inverse exponential distribution, with parameter <span class="math inline">\(\theta\)</span>.
<ol type="a">
<li>
Calculate the maximum likelihood estimator for <span class="math inline">\(\theta\)</span>.
</li>
<li>
Approximate the variance of the maximum likelihood estimator.
</li>
<li>
Determine an approximate 95% confidence interval for <span class="math inline">\(\theta\)</span>.
</li>
<li>
Determine an approximate 95% confidence interval for <span class="math inline">\(\Pr \left( X \leq 9,000 \right).\)</span>
</li>
</ol>
<h5 style="text-align: center;">
<a id="displayTextExampleLoss.5.1" href="javascript:toggleEX('toggleExampleLoss.5.1','displayTextExampleLoss.5.1');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExampleLoss.5.1" style="display: none">
<p><strong>Solution.</strong></p>
<p>The probability density function is <span class="math display">\[f_{X}\left( x \right) = \frac{\theta e^{- \frac{\theta}{x}}}{x^{2}}, \]</span> where <span class="math inline">\(x &gt; 0\)</span>.</p>
<p><strong>a.</strong> The likelihood function, <span class="math inline">\(L\left( \theta \right)\)</span>, can be viewed as the probability of the observed data, written as a function of the model’s parameter <span class="math inline">\(\theta\)</span> <span class="math display">\[L\left( \theta \right) = \prod_{i = 1}^{4}{f_{X_{i}}\left( x_{i} \right)} = \frac{\theta^{4}e^{- \theta\sum_{i = 1}^{4}\frac{1}{x_{i}}}}{\prod_{i = 1}^{4}x_{i}^{2}}.\]</span></p>
<p>The log-likelihood function, <span class="math inline">\(\ln L \left( \theta \right)\)</span>, is the sum of the individual logarithms. <span class="math display">\[\ln L \left( \theta \right) = 4ln\theta - \theta\sum_{i = 1}^{4}\frac{1}{x_{i}} - 2\sum_{i = 1}^{4}\ln x_{i} .\]</span></p>
<p><span class="math display">\[\frac{d \ln L \left( \theta \right)}{d \theta} = \frac{4}{\theta} - \sum_{i = 1}^{4}\frac{1}{x_{i}}.\]</span> The maximum likelihood estimator of <span class="math inline">\(\theta\)</span>, denoted by <span class="math inline">\(\hat{\theta}\)</span>, is the solution to the equation <span class="math display">\[\frac{4}{\hat{\theta}} - \sum_{i = 1}^{4}{\frac{1}{x_{i}} = 0}.\]</span> Thus, <span class="math inline">\(\hat{\theta} = \frac{4}{\sum_{i = 1}^{4}\frac{1}{x_{i}}} = 10,667\)</span></p>
<p>The second derivative of <span class="math inline">\(\ln L \left( \theta \right)\)</span> is given by <span class="math display">\[\frac{d^{2}\ln L\left( \theta \right)}{d\theta^{2}} = \frac{- 4}{\theta^{2}}.\]</span> Evaluating the second derivative of the loglikelihood function at <span class="math inline">\(\hat{\theta} = 10,667\)</span> gives a negative value, indicating <span class="math inline">\(\hat{\theta}\)</span> as the value that maximizes the loglikelihood function.</p>
<p><strong>b.</strong> Taking reciprocal of negative expectation of the second derivative of <span class="math inline">\(\ln L \left( \theta \right)\)</span>, we obtain an estimate of the variance of <span class="math inline">\(\hat{\theta}\)</span>, <span class="math inline">\(\widehat{Var}\left( \hat{\theta} \right) = \left. \ \left\lbrack E\left( \frac{d^{2}\ln L \left( \theta \right)}{d\theta^{2}} \right) \right\rbrack^{- 1} \right|_{\theta = \hat{\theta}} = \frac{{\hat{\theta}}^{2}}{4} = 28,446,222\)</span>.</p>
<p>It should be noted that as the sample size <span class="math inline">\(n \rightarrow \infty\)</span>, the distribution of the maximum likelihood estimator <span class="math inline">\(\hat{\theta}\)</span> converges to a normal distribution with mean <span class="math inline">\(\theta\)</span> and variance <span class="math inline">\(\hat{V}\left( \hat{\theta} \right)\)</span>. The approximate confidence interval in this example is based on the assumption of normality, despite the small sample size, only for the purpose of illustration.</p>
<p><strong>c.</strong> The 95% confidence interval for <span class="math inline">\(\theta\)</span> is given by <span class="math display">\[10,667 \pm 1.96\sqrt{28,446,222} = \left( 213.34,\ 21,120.66 \right).\]</span> <strong>d.</strong> The distribution function of <span class="math inline">\(X\)</span> is <span class="math inline">\(F\left( x \right) = 1 - e^{- \frac{x}{\theta}}\)</span>. Then, the maximum likelihood estimate of <span class="math inline">\(g\left( \theta \right) = F\left( 9,000 \right)\)</span> is <span class="math display">\[g\left( \hat{\theta} \right) = 1 - e^{- \frac{9,000}{10,667}} = 0.57.\]</span> We use the delta method to approximate the variance of <span class="math inline">\(g\left( \hat{\theta} \right)\)</span>. <span class="math display">\[\frac{\text{dg}\left( \theta \right)}{d \theta} = {- \frac{9,000}{\theta^{2}}e}^{- \frac{9,000}{\theta}}.\]</span></p>
<p><span class="math inline">\(\widehat{Var}\left\lbrack g\left( \hat{\theta} \right) \right\rbrack = \left( - {\frac{9,000}{{\hat{\theta}}^{2}}e}^{- \frac{9,000}{\hat{\theta}}} \right)^{2}\hat{V}\left( \hat{\theta} \right) = 0.0329\)</span>.</p>
<p>The 95% confidence interval for <span class="math inline">\(F\left( 9,000 \right)\)</span> is given by <span class="math display">\[0.57 \pm 1.96\sqrt{0.0329} = \left( 0.214,\ 0.926 \right).\]</span></p>
</div>
<hr />
<strong>Example 3.5.2. SOA Exam Question.</strong> A random sample of size 6 is from a lognormal distribution with parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>. The sample values are 200, 3,000, 8,000, 60,000, 60,000, 160,000.
<ol type="a">
<li>
Calculate the maximum likelihood estimator for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>.
</li>
<li>
Estimate the covariance matrix of the maximum likelihood estimator.
</li>
<li>
Determine approximate 95% confidence intervals for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>.
</li>
<li>
Determine an approximate 95% confidence interval for the mean of the lognormal distribution.
</li>
</ol>
<h5 style="text-align: center;">
<a id="displayTextExampleLoss.5.2" href="javascript:toggleEX('toggleExampleLoss.5.2','displayTextExampleLoss.5.2');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExampleLoss.5.2" style="display: none">
<p><strong>Solution.</strong></p>
<p>The probability density function is <span class="math display">\[f_{X}\left( x \right) = \frac{1}{x \sigma \sqrt{2\pi}}\exp - \frac{1}{2}\left( \frac{\ln x - \mu}{\sigma} \right)^{2},\]</span> where <span class="math inline">\(x &gt; 0\)</span>.</p>
<p><strong>a.</strong> The likelihood function, <span class="math inline">\(L\left( \mu,\sigma \right)\)</span>, is the product of the <em>pdf</em> for each data point. <span class="math display">\[L\left( \mu,\sigma \right) = \prod_{i = 1}^{6}{f_{X_{i}}\left( x_{i} \right)} = \frac{1}{\sigma^{6}\left( 2\pi \right)^{3}\prod_{i = 1}^{6}x_{i}}exp - \frac{1}{2}\sum_{i = 1}^{6}\left( \frac{\ln x_{i} - \mu}{\sigma} \right)^{2}.\]</span> The loglikelihood function, <span class="math inline">\(\ln L \left( \mu,\sigma \right)\)</span>, is the sum of the individual logarithms. <span class="math display">\[\ln \left( \mu,\sigma \right) = - 6ln\sigma - 3ln\left( 2\pi \right) - \sum_{i = 1}^{6}\ln x_{i} - \frac{1}{2}\sum_{i = 1}^{6}\left( \frac{\ln x_{i} - \mu}{\sigma} \right)^{2}.\]</span> The first partial derivatives are <span class="math display">\[\frac{\partial lnL\left( \mu,\sigma \right)}{\partial\mu} = \frac{1}{\sigma^{2}}\sum_{i = 1}^{6}\left( \ln x_{i} - \mu \right).\]</span> <span class="math display">\[\frac{\partial lnL\left( \mu,\sigma \right)}{\partial\sigma} = \frac{- 6}{\sigma} + \frac{1}{\sigma^{3}}\sum_{i = 1}^{6}\left( \ln x_{i} - \mu \right)^{2}.\]</span> The maximum likelihood estimators of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>, denoted by <span class="math inline">\(\hat{\mu}\)</span> and <span class="math inline">\(\hat{\sigma}\)</span>, are the solutions to the equations <span class="math display">\[\frac{1}{{\hat{\sigma}}^{2}}\sum_{i = 1}^{6}\left( \ln x_{i} - \hat{\mu} \right) = 0.\]</span> <span class="math display">\[\frac{- 6}{\hat{\sigma}} + \frac{1}{{\hat{\sigma}}^{3}}\sum_{i = 1}^{6}\left( \ln x_{i} - \hat{\mu} \right)^{2} = 0.\]</span> These yield the estimates</p>
<p><span class="math inline">\(\hat{\mu} = \frac{\sum_{i = 1}^{6}{\ln x_{i}}}{6} = 9.38\)</span> and <span class="math inline">\({\hat{\sigma}}^{2} = \frac{\sum_{i = 1}^{6}\left( \ln x_{i} - \hat{\mu} \right)^{2}}{6} = 5.12\)</span>.</p>
<p>The second partial derivatives are</p>
<p><span class="math inline">\(\frac{\partial^{2}\text{lnL}\left( \mu,\sigma \right)}{\partial\mu^{2}} = \frac{- 6}{\sigma^{2}}\)</span>, <span class="math inline">\(\frac{\partial^{2}\text{lnL}\left( \mu,\sigma \right)}{\partial\mu\partial\sigma} = \frac{- 2}{\sigma^{3}}\sum_{i = 1}^{6}\left( \ln x_{i} - \mu \right)\)</span> and <span class="math inline">\(\frac{\partial^{2}\text{lnL}\left( \mu,\sigma \right)}{\partial\sigma^{2}} = \frac{6}{\sigma^{2}} - \frac{3}{\sigma^{4}}\sum_{i = 1}^{6}\left( \ln x_{i} - \mu \right)^{2}\)</span>.</p>
<p><strong>b.</strong> To derive the covariance matrix of the <em>mle</em> we need to find the expectations of the second derivatives. Since the random variable <span class="math inline">\(X\)</span> is from a lognormal distribution with parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>, then <span class="math inline">\(\text{lnX}\)</span> is normally distributed with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^{2}\)</span>.</p>
<p><span class="math inline">\(\mathrm{E}\left( \frac{\partial^{2}\text{lnL}\left( \mu,\sigma \right)}{\partial\mu^{2}} \right) = \mathrm{E}\left( \frac{- 6}{\sigma^{2}} \right) = \frac{- 6}{\sigma^{2}}\)</span>,</p>
<p><span class="math inline">\(\mathrm{E}\left( \frac{\partial^{2}\text{lnL}\left( \mu,\sigma \right)}{\partial\mu\partial\sigma} \right) = \frac{- 2}{\sigma^{3}}\sum_{i = 1}^{6}{\mathrm{E}\left( \ln x_{i} - \mu \right)} = \frac{- 2}{\sigma^{3}}\sum_{i = 1}^{6}\left\lbrack \mathrm{E}\left( \ln x_{i} \right) - \mu \right\rbrack\)</span>=<span class="math inline">\(\frac{- 2}{\sigma^{3}}\sum_{i = 1}^{6}\left( \mu - \mu \right) = 0\)</span>,</p>
<p>and</p>
<p><span class="math inline">\(\mathrm{E}\left( \frac{\partial^{2}\text{lnL}\left( \mu,\sigma \right)}{\partial\sigma^{2}} \right) = \frac{6}{\sigma^{2}} - \frac{3}{\sigma^{4}}\sum_{i = 1}^{6}{\mathrm{E}\left( \ln x_{i} - \mu \right)}^{2} = \frac{6}{\sigma^{2}} - \frac{3}{\sigma^{4}}\sum_{i = 1}^{6}{\mathrm{V}\left( \ln x_{i} \right) = \frac{6}{\sigma^{2}} - \frac{3}{\sigma^{4}}\sum_{i = 1}^{6}{\sigma^{2} = \frac{- 12}{\sigma^{2}}}}\)</span>.</p>
<p>Using the negatives of these expectations we obtain the Fisher information matrix <span class="math display">\[\begin{bmatrix}
\frac{6}{\sigma^{2}} &amp; 0 \\
0 &amp; \frac{12}{\sigma^{2}} \\
\end{bmatrix}.\]</span></p>
<p>The covariance matrix, <span class="math inline">\(\Sigma\)</span>, is the inverse of the Fisher information matrix <span class="math display">\[\Sigma = \begin{bmatrix}
\frac{\sigma^{2}}{6} &amp; 0 \\
0 &amp; \frac{\sigma^{2}}{12} \\
\end{bmatrix}.\]</span></p>
<p>The estimated matrix is given by <span class="math display">\[\hat{\Sigma} = \begin{bmatrix}
0.8533 &amp; 0 \\
0 &amp; 0.4267 \\
\end{bmatrix}.\]</span></p>
<p><strong>c.</strong> The 95% confidence interval for <span class="math inline">\(\mu\)</span> is given by <span class="math inline">\(9.38 \pm 1.96\sqrt{0.8533} = \left( 7.57,\ 11.19 \right)\)</span>.</p>
<p>The 95% confidence interval for <span class="math inline">\(\sigma^{2}\)</span> is given by <span class="math inline">\(5.12 \pm 1.96\sqrt{0.4267} = \left( 3.84,\ 6.40 \right)\)</span>.</p>
<p><strong>d.</strong> The mean of <em>X</em> is <span class="math inline">\(\exp\left( \mu + \frac{\sigma^{2}}{2} \right)\)</span>. Then, the maximum likelihood estimate of <span class="math display">\[g\left( \mu,\sigma \right) = \exp\left( \mu + \frac{\sigma^{2}}{2} \right)\]</span> is <span class="math display">\[g\left( \hat{\mu},\hat{\sigma} \right) = \exp\left( \hat{\mu} + \frac{{\hat{\sigma}}^{2}}{2} \right) = 153,277.\]</span></p>
<p>We use the delta method to approximate the variance of the mle <span class="math inline">\(g\left( \hat{\mu},\hat{\sigma} \right)\)</span>.</p>
<p><span class="math inline">\(\frac{\partial g\left( \mu,\sigma \right)}{\partial\mu} = exp\left( \mu + \frac{\sigma^{2}}{2} \right)\)</span> and <span class="math inline">\(\frac{\partial g\left( \mu,\sigma \right)}{\partial\sigma} = \sigma exp\left( \mu + \frac{\sigma^{2}}{2} \right)\)</span>.</p>
<p>Using the delta method, the approximate variance of <span class="math inline">\(g\left( \hat{\mu},\hat{\sigma} \right)\)</span> is given by</p>
<p><span class="math display">\[\left. \ \hat{V}\left( g\left( \hat{\mu},\hat{\sigma} \right) \right) = \begin{bmatrix}
\frac{\partial g\left( \mu,\sigma \right)}{\partial\mu} &amp; \frac{\partial g\left( \mu,\sigma \right)}{\partial\sigma} \\
\end{bmatrix}\Sigma\begin{bmatrix}
\frac{\partial g\left( \mu,\sigma \right)}{\partial\mu} \\
\frac{\partial g\left( \mu,\sigma \right)}{\partial\sigma} \\
\end{bmatrix} \right|_{\mu = \hat{\mu},\sigma = \hat{\sigma}}\]</span></p>
<p><span class="math display">\[= \begin{bmatrix}
153,277 &amp; 346,826 \\
\end{bmatrix}\begin{bmatrix}
0.8533 &amp; 0 \\
0 &amp; 0.4267 \\
\end{bmatrix}\begin{bmatrix}
153,277 \\
346,826 \\
\end{bmatrix} =\]</span>71,374,380,000</p>
<p>The 95% confidence interval for <span class="math inline">\(\exp\left( \mu + \frac{\sigma^{2}}{2} \right)\)</span> is given by</p>
<p><span class="math inline">\(153,277 \pm 1.96\sqrt{71,374,380,000} = \left( - 370,356,\ 676,910 \right)\)</span>.</p>
<p>Since the mean of the lognormal distribution cannot be negative, we should replace the negative lower limit in the previous interval by a zero.</p>
</div>
<hr />
</div>
<div id="MLEGrouped" class="section level3">
<h3><span class="header-section-number">3.5.2</span> Maximum Likelihood Estimators for Grouped Data</h3>
<p>In the previous section we considered the maximum likelihood estimation of continuous models from complete (individual) data. Each individual observation is recorded, and its contribution to the likelihood function is the density at that value. In this section we consider the problem of obtaining maximum likelihood estimates of parameters from grouped data. The observations are only available in grouped form, and the contribution of each observation to the likelihood function is the probability of falling in a specific group (interval). Let <span class="math inline">\(n_{j}\)</span> represent the number of observations in the interval <span class="math inline">\(\left( \left. \ c_{j - 1},c_{j} \right\rbrack \right.\ \)</span> The grouped data likelihood function is thus given by <span class="math display">\[L\left( \theta \right) = \prod_{j = 1}^{k}\left\lbrack F\left( \left. \ c_{j} \right|\theta \right) - F\left( \left. \ c_{j - 1} \right|\theta \right) \right\rbrack^{n_{j}},\]</span> where <span class="math inline">\(c_{0}\)</span> is the smallest possible observation (often set to zero) and <span class="math inline">\(c_{k}\)</span> is the largest possible observation (often set to infinity).</p>
<p><strong>Example 3.5.3. SOA Exam Question.</strong> For a group of policies, you are given that losses follow the distribution function <span class="math inline">\(F\left( x \right) = 1 - \frac{\theta}{x}\)</span>, for <span class="math inline">\(\theta &lt; x &lt; \infty.\)</span> Further, a sample of 20 losses resulted in the following:</p>
<p><span class="math display">\[
{\small
\begin{matrix}\hline
\text{Interval} &amp; \text{Number of Losses}  \\ \hline
(\theta, 10] &amp; 9 \\
(10, 25] &amp; 6 \\
(25, \infty) &amp; 5  \\ \hline
\end{matrix}
}
\]</span></p>
<p>Calculate the maximum likelihood estimate of <span class="math inline">\(\theta\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleLoss.5.3" href="javascript:toggleEX('toggleExampleLoss.5.3','displayTextExampleLoss.5.3');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExampleLoss.5.3" style="display: none">
<p><strong>Solution.</strong></p>
<p>The contribution of each of the 9 observations in the first interval to the likelihood function is the probability of <span class="math inline">\(X \leq 10\)</span>; that is, <span class="math inline">\(\Pr\left( X \leq 10 \right) = F\left( 10 \right)\)</span>. Similarly, the contributions of each of 6 and 5 observations in the second and third intervals are <span class="math inline">\(\Pr\left( 10 &lt; X \leq 25 \right) = F\left( 25 \right) - F(10)\)</span> and <span class="math inline">\(P\left( X &gt; 25 \right) = 1 - F(25)\)</span>, respectively. The likelihood function is thus given by <span class="math display">\[L\left( \theta \right) = \left\lbrack F\left( 10 \right) \right\rbrack^{9}\left\lbrack F\left( 25 \right) - F(10) \right\rbrack^{6}\left\lbrack 1 - F(25) \right\rbrack^{5}\]</span> <span class="math display">\[{= \left( 1 - \frac{\theta}{10} \right)}^{9}\left( \frac{\theta}{10} - \frac{\theta}{25} \right)^{6}\left( \frac{\theta}{25} \right)^{5}\]</span> <span class="math display">\[{= \left( \frac{10 - \theta}{10} \right)}^{9}\left( \frac{15\theta}{250} \right)^{6}\left( \frac{\theta}{25} \right)^{5}.\]</span> Then, <span class="math inline">\(\ln L \left( \theta \right) = 9ln\left( 10 - \theta \right) + 6ln\theta + 5ln\theta - 9ln10 + 6ln15 - 6ln250 - 5ln25\)</span>. <span class="math display">\[\frac{d \ln L \left( \theta \right)}{d \theta} = \frac{- 9}{\left( 10 - \theta \right)} + \frac{6}{\theta} + \frac{5}{\theta}.\]</span> The maximum likelihood estimator, <span class="math inline">\(\hat{\theta}\)</span>, is the solution to the equation <span class="math display">\[\frac{- 9}{\left( 10 - \hat{\theta} \right)} + \frac{11}{\hat{\theta}} = 0\]</span> and <span class="math inline">\(\hat{\theta} = 5.5\)</span>.</p>
</div>
<hr />
</div>
<div id="maximum-likelihood-estimators-for-censored-data" class="section level3">
<h3><span class="header-section-number">3.5.3</span> Maximum Likelihood Estimators for Censored Data</h3>
<p>Another possible distinguishing feature of a data gathering mechanism is censoring. While for some events of interest (losses, claims, lifetimes, etc.) the complete data maybe available, for others only partial information is available; all that may be known is that the observation exceeds a specific value. The limited policy introduced in Section <a href="C-Severity.html#S:PolicyLimits">3.4.2</a> is an example of right censoring. Any loss greater than or equal to the policy limit is recorded at the limit. The contribution of the censored observation to the likelihood function is the probability of the random variable exceeding this specific limit. Note that contributions of both complete and censored data share the survivor function, for a complete point this survivor function is multiplied by the hazard function, but for a censored observation it is not.</p>
<p><strong>Example 3.5.4. SOA Exam Question.</strong> The random variable <span class="math inline">\(X\)</span> has survival function: <span class="math display">\[S_{X}\left( x \right) = \frac{\theta^{4}}{\left( \theta^{2} + x^{2} \right)^{2}}.\]</span> Two values of <span class="math inline">\(X\)</span> are observed to be 2 and 4. One other value exceeds 4. Calculate the maximum likelihood estimate of <span class="math inline">\(\theta\)</span>.</p>
<h5 style="text-align: center;">
<a id="displayTextExampleLoss.5.4" href="javascript:toggleEX('toggleExampleLoss.5.4','displayTextExampleLoss.5.4');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExampleLoss.5.4" style="display: none">
<p><strong>Solution.</strong></p>
<p>The contributions of the two observations 2 and 4 are <span class="math inline">\(f_{X}\left( 2 \right)\)</span> and <span class="math inline">\(f_{X}\left( 4 \right)\)</span> respectively. The contribution of the third observation, which is only known to exceed 4 is <span class="math inline">\(S_{X}\left( 4 \right)\)</span>. The likelihood function is thus given by <span class="math display">\[L\left( \theta \right) = f_{X}\left( 2 \right)f_{X}\left( 4 \right)S_{X}\left( 4 \right).\]</span> The probability density function of <span class="math inline">\(X\)</span> is given by <span class="math display">\[f_{X}\left( x \right) = \frac{4x\theta^{4}}{\left( \theta^{2} + x^{2} \right)^{3}}.\]</span> Thus, <span class="math display">\[L\left( \theta \right) = \frac{8\theta^{4}}{\left( \theta^{2} + 4 \right)^{3}}\frac{16\theta^{4}}{\left( \theta^{2} + 16 \right)^{3}}\frac{\theta^{4}}{\left( \theta^{2} + 16 \right)^{2}} = \\
\frac{128\theta^{12}}{\left( \theta^{2} + 4 \right)^{3}\left( \theta^{2} + 16 \right)^{5}},\]</span></p>
<p>So, <span class="math display">\[\ln L\left( \theta \right) = ln128 + 12ln\theta - 3ln\left( \theta^{2} + 4 \right) - 5ln\left( \theta^{2} + 16 \right)\]</span>,</p>
<p>and</p>
<p><span class="math inline">\(\frac{\text{dlnL}\left( \theta \right)}{d \theta} = \frac{12}{\theta} - \frac{6\theta}{\left( \theta^{2} + 4 \right)} - \frac{10\theta}{\left( \theta^{2} + 16 \right)}\)</span>.</p>
<p>The maximum likelihood estimator, <span class="math inline">\(\hat{\theta}\)</span>, is the solution to the equation <span class="math display">\[\frac{12}{\hat{\theta}} - \frac{6\hat{\theta}}{\left( {\hat{\theta}}^{2} + 4 \right)} - \frac{10\hat{\theta}}{\left( {\hat{\theta}}^{2} + 16 \right)} = 0\]</span> or <span class="math display">\[12\left( {\hat{\theta}}^{2} + 4 \right)\left( {\hat{\theta}}^{2} + 16 \right) - 6{\hat{\theta}}^{2}\left( {\hat{\theta}}^{2} + 16 \right) - 10{\hat{\theta}}^{2}\left( {\hat{\theta}}^{2} + 4 \right) = \\
- 4{\hat{\theta}}^{4} + 104{\hat{\theta}}^{2} + 768 = 0,\]</span> which yields <span class="math inline">\({\hat{\theta}}^{2} = 32\)</span> and <span class="math inline">\(\hat{\theta} = 5.7\)</span>.</p>
</div>
<hr />
</div>
<div id="maximum-likelihood-estimators-for-truncated-data" class="section level3">
<h3><span class="header-section-number">3.5.4</span> Maximum Likelihood Estimators for Truncated Data</h3>
<p>This section is concerned with the maximum likelihood estimation of the continuous distribution of the random variable <span class="math inline">\(X\)</span> when the data is incomplete due to truncation. If the values of <span class="math inline">\(X\)</span> are truncated at <span class="math inline">\(d\)</span>, then it should be noted that we would not have been aware of the existence of these values had they not exceeded <span class="math inline">\(d\)</span>. The policy deductible introduced in Section <a href="C-Severity.html#S:PolicyDeduct">3.4.1</a> is an example of left truncation. Any loss less than or equal to the deductible is not recorded. The contribution to the likelihood function of an observation <span class="math inline">\(x\)</span> truncated at <span class="math inline">\(d\)</span> will be a conditional probability and the <span class="math inline">\(f_{X}\left( x \right)\)</span> will be replaced by <span class="math inline">\(\frac{f_{X}\left( x \right)}{S_{X}\left( d \right)}\)</span>.</p>
<strong>Example 3.5.5. SOA Exam Question.</strong> For the single parameter Pareto distribution with <span class="math inline">\(\theta = 2\)</span>, maximum likelihood estimation is applied to estimate the parameter <span class="math inline">\(\alpha\)</span>. Find the estimated mean of the ground up loss distribution based on the maximum likelihood estimate of <span class="math inline">\(\alpha\)</span> for the following data set:
<ul>
<li>
Ordinary policy deductible of 5, maximum covered loss of 25 (policy limit 20)
</li>
<li>
8 insurance payment amounts: 2, 4, 5, 5, 8, 10, 12, 15
</li>
<li>
2 limit payments: 20, 20.
</li>
</ul>
<h5 style="text-align: center;">
<a id="displayTextExampleLoss.5.5" href="javascript:toggleEX('toggleExampleLoss.5.5','displayTextExampleLoss.5.5');"><i><strong>Show Example Solution</strong></i></a>
</h5>
<div id="toggleExampleLoss.5.5" style="display: none">
<p><strong>Solution.</strong></p>
The contributions of the different observations can be summarized as follows:
<ul>
<li>
For the exact loss: <span class="math inline">\(f_{X}\left( x \right)\)</span>
</li>
<li>
For censored observations: <span class="math inline">\(S_{X}\left( 25 \right)\)</span>.
</li>
<li>
For truncated observations: <span class="math inline">\(\frac{f_{X}\left( x \right)}{S_{X}\left( 5 \right)}\)</span>.
</li>
</ul>
<p>Given that ground up losses smaller than 5 are omitted from the data set, the contribution of all observations should be conditional on exceeding 5. The likelihood function becomes <span class="math display">\[L\left( \alpha \right) = \frac{\prod_{i = 1}^{8}{f_{X}\left( x_{i} \right)}}{\left\lbrack S_{X}\left( 5 \right) \right\rbrack^{8}}\left\lbrack \frac{S_{X}\left( 25 \right)}{S_{X}\left( 5 \right)} \right\rbrack^{2}.\]</span> For the single parameter Pareto the probability density and distribution functions are given by</p>
<p><span class="math display">\[f_{X}\left( x \right) = \frac{\alpha\theta^{\alpha}}{x^{\alpha + 1}} \ \ \text{and} \ \ F_{X}\left( x \right) = 1 - \left( \frac{\theta}{x} \right)^{\alpha},\]</span> for <span class="math inline">\(x &gt; \theta\)</span>, respectively. Then, the likelihood and loglikelihood functions are given by <span class="math display">\[L\left( \alpha \right) = \frac{\alpha^{8}}{\prod_{i = 1}^{8}x_{i}^{\alpha + 1}}\frac{5^{10\alpha}}{25^{2\alpha}},\]</span> <span class="math display">\[\ln L \left( \alpha \right) = 8ln\alpha - \left( \alpha + 1 \right)\sum_{i = 1}^{8}{\ln x_{i}} + 10\alpha ln5 - 2\alpha ln25.\]</span></p>
<p><span class="math inline">\(\frac{\text{dlnL}\left( \alpha \right)}{d \theta} = \frac{8}{\alpha} - \sum_{i = 1}^{8}{\ln x_{i}} + 10ln5 - 2ln25\)</span>.</p>
<p>The maximum likelihood estimator, <span class="math inline">\(\hat{\alpha}\)</span>, is the solution to the equation <span class="math display">\[\frac{8}{\hat{\alpha}} - \sum_{i = 1}^{8}{\ln x_{i}} + 10ln5 - 2ln25 = 0,\]</span>which yields <span class="math display">\[\hat{\alpha} = \frac{8}{\sum_{i = 1}^{8}{\ln x_{i}} - 10ln5 + 2ln25} = \frac{8}{(ln7 + ln9 + \cdots + ln20) - 10ln5 + 2ln25} = 0.785.\]</span> The mean of the Pareto only exists for <span class="math inline">\(\alpha &gt; 1\)</span>. Since <span class="math inline">\(\hat{\alpha} = 0.785 &lt; 1\)</span>. Then, the mean does not exist.</p>
</div>
<hr />
</div>
</div>
<div id="LM-further-reading-and-resources" class="section level2">
<h2><span class="header-section-number">3.6</span> Further Resources and Contributors</h2>
<!-- In describing losses, actuaries fit appropriate parametric distribution models for the frequency and severity of loss. This involves finding appropriate statistical distributions that could efficiently model the data in hand. After fitting a distribution model to a data set, the model should be validated. Model validation is a crucial step in the model building sequence. It assesses how well these statistical distributions fit the data in hand and how well can we expect this model to perform in the future. If the selected model does not fit the data, another distribution is to be chosen. If more than one model seems to be a good fit for the data, we then have to make the choice on which model to use. It should be noted though that the same data should not serve for both purposes (fitting and validating the model). Additional data should be used to assess the performance of the model. There are many statistical tools for model validation. Alternative goodness of fit tests used to determine whether sample data are consistent with the candidate model, will be presented in a separate chapter. -->
<div id="contributors-2" class="section level4 unnumbered">
<h4>Contributors</h4>
<ul>
<li><strong>Zeinab Amin</strong>, The American University in Cairo, is the principal author of this chapter. Email: <a href="mailto:zeinabha@aucegypt.edu">zeinabha@aucegypt.edu</a> for chapter comments and suggested improvements.</li>
<li>Many helpful comments have been provided by Hirokazu (Iwahiro) Iwasawa, <a href="mailto:iwahiro@bb.mbn.or.jp">iwahiro@bb.mbn.or.jp</a> .</li>
</ul>
</div>
<div id="exercises-1" class="section level4 unnumbered">
<h4>Exercises</h4>
<p>Here are a set of exercises that guide the viewer through some of the theoretical foundations of <strong>Loss Data Analytics</strong>. Each tutorial is based on one or more questions from the professional actuarial examinations – typically the Society of Actuaries Exam C.</p>
<p style="text-align: center;">
<a href="http://www.ssc.wisc.edu/~jfrees/loss-data-analytics/chapter-3-modeling-loss-severity/loss-data-analytics-severity-problems/">Severity Distribution Guided Tutorials</a>
</p>
</div>
<div id="further-readings-and-references" class="section level4 unnumbered">
<h4>Further Readings and References</h4>
<p>Notable contributions include: <span class="citation">Cummins and Derrig (<a href="#ref-cummins1991managing">2012</a>)</span>, <span class="citation">Frees and Valdez (<a href="#ref-frees2008hierarchical">2008</a>)</span>, <span class="citation">Klugman, Panjer, and Willmot (<a href="#ref-klugman2012">2012</a>)</span>, <span class="citation">Kreer et al. (<a href="#ref-kreer2015goodness">2015</a>)</span>, <span class="citation">McDonald (<a href="#ref-mcdonald1984some">1984</a>)</span>, <span class="citation">McDonald and Xu (<a href="#ref-mcdonald1995generalization">1995</a>)</span>, <span class="citation">Tevet (<a href="#ref-tevet2016applying">2016</a>)</span>, and <span class="citation">Venter (<a href="#ref-venter1983transformed">1983</a>)</span>.</p>

</div>
</div>
</div>
<h3>Bibliography</h3>
<div id="refs" class="references">
<div id="ref-venter1983transformed">
<p>Venter, Gary. 1983. “Transformed Beta and Gamma Distributions and Aggregate Losses.” In <em>Proceedings of the Casualty Actuarial Society</em>, 70:289–308. 133 &amp; 134.</p>
</div>
<div id="ref-mcdonald1984some">
<p>McDonald, James B. 1984. “Some Generalized Functions for the Size Distribution of Income.” <em>Econometrica: Journal of the Econometric Society</em>. JSTOR, 647–63.</p>
</div>
<div id="ref-cummins1991managing">
<p>Cummins, J. David, and Richard A. Derrig. 2012. <em>Managing the Insolvency Risk of Insurance Companies: Proceedings of the Second International Conference on Insurance Solvency</em>. Vol. 12. Springer Science &amp; Business Media.</p>
</div>
<div id="ref-frees2008hierarchical">
<p>Frees, Edward W., and Emiliano A. Valdez. 1998. “Understanding Relationships Using Copulas.” <em>North American Actuarial Journal</em> 2 (01): 1–25.</p> 2008. “Hierarchical Insurance Claims Modeling.” <em>Journal of the American Statistical Association</em> 103 (484). Taylor &amp; Francis: 1457–69.</p>
</div>
<div id="ref-klugman2012">
<p>Klugman, Stuart A., Harry H. Panjer, and Gordon E. Willmot. 2012. <em>Loss Models: From Data to Decisions</em>. John Wiley &amp; Sons.</p>
</div>
<div id="ref-kreer2015goodness">
<p>Kreer, Markus, Ayşe Kizilersü, Anthony W Thomas, and Alfredo D Egídio dos Reis. 2015. “Goodness-of-Fit Tests and Applications for Left-Truncated Weibull Distributions to Non-Life Insurance.” <em>European Actuarial Journal</em> 5 (1). Springer: 139–63.</p>
</div>
<div id="ref-mcdonald1995generalization">
<p>McDonald, James B, and Yexiao J Xu. 1995. “A Generalization of the Beta Distribution with Applications.” <em>Journal of Econometrics</em> 66 (1-2). Elsevier: 133–52.</p>
</div>
<div id="ref-tevet2016applying">
<p>Tevet, Dan. 2016. “Applying Generalized Linear Models to Insurance Data.” <em>Predictive Modeling Applications in Actuarial Science: Volume 2, Case Studies in Insurance</em>. Cambridge University Press, 39.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="C-Frequency-Modeling.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="C-ModelSelection.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["LossDataAnalytics.pdf", "LossDataAnalytics.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
